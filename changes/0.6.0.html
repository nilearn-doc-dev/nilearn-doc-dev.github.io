<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="0.6.0" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://nilearn.github.io/changes/0.6.0.html" />
  
<meta property="og:site_name" content="Nilearn" />
  
<meta property="og:description" content="Released December 2019 HIGHLIGHTS: NEW: New method for NiftiMasker instances for generating reports viewable in a web browser, Jupyter Notebook, or VSCode (#2019 by Elizabeth DuPre)., New function ..." />
  
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
  
<meta property="og:image:alt" content="Nilearn" />
  <link rel="search" title="Search" href="../search.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><meta name="generator" content="sphinx-4.4.0, furo 2022.03.04"/>
        <title>0.6.0 - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=935aa2abcc5c1da4283d1dc201fb1f0add16d23a" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
      }
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../nistats_migration.html">A Quick Guide to Migrating Nistats Code to Nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">People</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html#citing-nilearn">Citing nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html#citing-scikit-learn">Citing scikit-learn</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../user_guide.html">User guide: table of contents</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">1. Introduction: nilearn in a nutshell</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../decoding/decoding_intro.html">2.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/estimator_choice.html">2.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/frem.html">2.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/space_net.html">2.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/searchlight.html">2.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/going_further.html">2.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../connectivity/index.html">3. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../developers/group_sparse_covariance.html">3.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/resting_state_networks.html">3.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/region_extraction.html">3.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/parcellating.html">3.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../plotting/index.html">4. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../glm/index.html">5. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/glm_intro.html">5.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/first_level_model.html">5.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/second_level_model.html">5.3. Second level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../manipulating_images/index.html">6. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/input_output.html">6.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/manipulating_images.html">6.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/masker_objects.html">6.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../building_blocks/index.html">7. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/manual_pipeline.html">7.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/neurovault.html">7.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../modules/reference.html">8. Reference documentation: all nilearn functions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/index.html">9. Examples</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../auto_examples/07_advanced/index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">9. Examples</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/07_advanced/index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#dev">0.9.1.dev</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id100">0.9.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id204">0.8.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id309">0.8.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id414">0.7.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id518">0.7.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id623">0.6.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id726">0.6.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id829">0.6.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#rc">0.6.0rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#b0">0.6.0b0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#a0">0.6.0a0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id948">0.5.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1051">0.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1155">0.5.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1159">0.5.0 rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#beta">0.5.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#alpha">0.5.0 alpha</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1272">0.4.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1374">0.4.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1476">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1581">0.3.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1685">0.3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1689">0.3.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1793">0.2.6</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1896">0.2.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id1900">0.2.5</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2002">0.2.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2104">0.2.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2205">0.2.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#v0-2-1">0.2.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2312">0.2.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2417">0.1.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2518">0.1.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2620">0.1.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2721">0.1.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="whats_new.html#id2822">0.1.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">Nilearn development process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintenance.html">Nilearn maintenance process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="id1">
<h1>0.6.0<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h1>
<p><strong>Released December 2019</strong></p>
<section id="highlights">
<h2>HIGHLIGHTS<a class="headerlink" href="#highlights" title="Permalink to this headline">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<div class="line-block">
<div class="line"><strong>Python2 and 3.4 are no longer supported. We recommend upgrading to Python 3.6 minimum.</strong> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2214">#2214</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</div>
<div class="line"><br/></div>
<div class="line"><strong>Support for Python3.5 will be removed in the 0.7.x release.</strong></div>
<div class="line">Users with a Python <code class="docutils literal notranslate"><span class="pre">3.5</span></code> environment will be warned at their first Nilearn import.</div>
<div class="line"><br/></div>
<div class="line"><strong>joblib is now a dependency</strong></div>
<div class="line"><br/></div>
<div class="line"><strong>Minimum supported versions of packages have been bumped up.</strong></div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Matplotlib</span> <span class="pre">--</span> <span class="pre">v2.0</span></code>.</div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Scikit-learn</span> <span class="pre">--</span> <span class="pre">v0.19</span></code>.</div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Scipy</span> <span class="pre">--</span> <span class="pre">v0.19</span></code>.</div>
</div>
</div>
</section>
<section id="new">
<h2>NEW<a class="headerlink" href="#new" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>New method for <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code> instances for generating reports viewable in a web browser, Jupyter Notebook, or VSCode (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2019">#2019</a> by <a class="reference external" href="https://elizabeth-dupre.com/#/">Elizabeth DuPre</a>).</p></li>
<li><p>New function <code class="xref py py-func docutils literal notranslate"><span class="pre">get_data</span></code> to replace the deprecated nibabel method <code class="docutils literal notranslate"><span class="pre">Nifti1Image.get_data</span></code>. Now use <code class="docutils literal notranslate"><span class="pre">nilearn.image.get_data(img)</span></code> rather than <code class="docutils literal notranslate"><span class="pre">img.get_data()</span></code>. This is because Nibabel is removing the <code class="docutils literal notranslate"><span class="pre">get_data</span></code> method. You may also consider using the Nibabel method <code class="docutils literal notranslate"><span class="pre">nibabel.nifti1.Nifti1Image.get_fdata</span></code>, which returns the data cast to floating-point. See <a class="reference external" href="https://github.com/nipy/nibabel/wiki/BIAP8">BIAP8</a>. As a benefit, the <code class="xref py py-func docutils literal notranslate"><span class="pre">get_data</span></code> function works on niimg-like objects such as filenames (see <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">input_output</a>) (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2172">#2172</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>New class <code class="xref py py-class docutils literal notranslate"><span class="pre">ReNA</span></code> implementing parcellation method <a class="reference internal" href="../glossary.html#term-ReNA"><span class="xref std std-term">ReNA</span></a>: Fast agglomerative clustering based on recursive nearest neighbor grouping. Yields very fast &amp; accurate models, without creation of giant clusters (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1336">#1336</a> by <a class="reference external" href="https://github.com/ahoyosid">Andrés Hoyos Idrobo</a>).</p></li>
<li><p>New function <code class="docutils literal notranslate"><span class="pre">nilearn.plotting.plot_connectome_strength</span></code> to plot the strength of a connectome on a glass brain.  Strength is absolute sum of the edges at a node (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2028">#2028</a> by <a class="reference external" href="https://glemaitre.github.io/">Guillaume Lemaitre</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">resample_img</span></code> has been optimized to pad rather than resample images in the special case when there is only a translation between two spaces. This is a common case in class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code> when using the <code class="docutils literal notranslate"><span class="pre">mask_strategy="template"</span></code> option for brains in <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> space (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2025">#2025</a> by <a class="reference external" href="https://gkiar.me/">Greg Kiar</a>).</p></li>
<li><p>New brain development <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> dataset fetcher <code class="xref py py-func docutils literal notranslate"><span class="pre">datasets.fetch_development_fmri</span></code> can be used to download movie-watching data in children and adults. A light-weight dataset implemented for teaching and usage in the examples. All the connectivity examples are changed from ADHD to brain development <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> dataset (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1953">#1953</a> by <a class="reference external" href="https://github.com/KamalakerDadi">Kamalakar Reddy Daddy</a>).</p></li>
</ul>
</section>
<section id="enhancements">
<h2>ENHANCEMENTS<a class="headerlink" href="#enhancements" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Functions <code class="xref py py-func docutils literal notranslate"><span class="pre">view_img_on_surf</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">view_surf</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">view_connectome</span></code> can display a title, and allow disabling the colorbar, and setting its height and the fontsize of its ticklabels (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1951">#1951</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Rework of the standardize-options of function <code class="xref py py-func docutils literal notranslate"><span class="pre">clean</span></code> and the various Maskers in <a class="reference internal" href="../modules/reference.html#module-nilearn.maskers" title="nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code></a>. You can now set <code class="docutils literal notranslate"><span class="pre">standardize</span></code> to <code class="docutils literal notranslate"><span class="pre">zscore</span></code> or <code class="docutils literal notranslate"><span class="pre">psc</span></code>. <code class="docutils literal notranslate"><span class="pre">psc</span></code> stands for <code class="docutils literal notranslate"><span class="pre">Percent</span> <span class="pre">Signal</span> <span class="pre">Change</span></code>, which can be a meaningful metric for <a class="reference internal" href="../glossary.html#term-BOLD"><span class="xref std std-term">BOLD</span></a> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1952">#1952</a> by <a class="reference external" href="https://github.com/Gilles86">Gilles de Hollander</a>).</p></li>
<li><p>Class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> now accepts an optional <code class="docutils literal notranslate"><span class="pre">strategy</span></code> parameter which allows it to change the function used to reduce values within each labelled ROI. Available functions include <code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">median</span></code>, <code class="docutils literal notranslate"><span class="pre">minimum</span></code>, <code class="docutils literal notranslate"><span class="pre">maximum</span></code>, <code class="docutils literal notranslate"><span class="pre">standard_deviation</span></code> and <code class="docutils literal notranslate"><span class="pre">variance</span></code>. This change is also introduced in function <code class="xref py py-func docutils literal notranslate"><span class="pre">img_to_signals_labels</span></code> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2221">#2221</a> by <a class="reference external" href="https://github.com/dangom">Daniel Gomez</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">view_surf</span></code> now accepts surface data provided as a file path (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2057">#2057</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
</ul>
</section>
<section id="changes">
<h2>CHANGES<a class="headerlink" href="#changes" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_img</span></code> now has explicit keyword arguments <code class="docutils literal notranslate"><span class="pre">bg_img</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin</span></code> and <code class="docutils literal notranslate"><span class="pre">vmax</span></code> to control the background image and the bounds of the colormap. These arguments were already accepted in <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> but not documented before (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2157">#2157</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
</ul>
</section>
<section id="fixes">
<h2>FIXES<a class="headerlink" href="#fixes" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> no longer truncates region means to their integral part when input images are of integer type (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2195">#2195</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>The argument <code class="docutils literal notranslate"><span class="pre">version='det'</span></code> in function <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_atlas_pauli_2017</span></code> now works as expected (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2235">#2235</a> by <a class="reference external" href="https://github.com/ryanhammonds">Ryan Hammonds</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">nilearn</span></code> now installs the necessary dependencies (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2214">#2214</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
</ul>
<p><strong>Lots of other fixes in documentation and examples.</strong> More detailed change list follows:</p>
</section>
</section>
<section id="rc">
<h1>0.6.0rc<a class="headerlink" href="#rc" title="Permalink to this headline">#</a></h1>
<section id="id2">
<h2>NEW<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">view_connectome</span></code> no longer accepts old parameter names. Instead of <code class="docutils literal notranslate"><span class="pre">coords</span></code>, <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, <code class="docutils literal notranslate"><span class="pre">cmap</span></code>, and <code class="docutils literal notranslate"><span class="pre">marker_size</span></code>, use <code class="docutils literal notranslate"><span class="pre">node_coords</span></code>, <code class="docutils literal notranslate"><span class="pre">edge_threshold</span></code>, <code class="docutils literal notranslate"><span class="pre">edge_cmap</span></code>, and <code class="docutils literal notranslate"><span class="pre">node_size</span></code> respectively (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2255">#2255</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">view_markers</span></code> no longer accepts old parameter names. Instead of <code class="docutils literal notranslate"><span class="pre">coord</span></code> and <code class="docutils literal notranslate"><span class="pre">color</span></code>, use <code class="docutils literal notranslate"><span class="pre">marker_coords</span></code> and <code class="docutils literal notranslate"><span class="pre">marker_color</span></code> respectively (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2255">#2255</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p><strong>Support for Python3.5 will be removed in the 0.7.x release.</strong> Users with a Python3.5 environment will be warned at their first Nilearn import (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2214">#2214</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
</ul>
</div>
</section>
<section id="id3">
<h2>Changes<a class="headerlink" href="#id3" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Add a warning to <code class="xref py py-class docutils literal notranslate"><span class="pre">Parcellations</span></code> if the generated number of parcels does not match the requested number of parcels (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2240">#2240</a> by <a class="reference external" href="https://elizabeth-dupre.com/#/">Elizabeth DuPre</a>).</p></li>
<li><p>Class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> now accepts an optional <code class="docutils literal notranslate"><span class="pre">strategy</span></code> parameter which allows it to change the function used to reduce values within each labelled ROI. Available functions include <code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">median</span></code>, <code class="docutils literal notranslate"><span class="pre">minimum</span></code>, <code class="docutils literal notranslate"><span class="pre">maximum</span></code>, <code class="docutils literal notranslate"><span class="pre">standard_deviation</span></code> and <code class="docutils literal notranslate"><span class="pre">variance</span></code>. This change is also introduced in function <code class="xref py py-func docutils literal notranslate"><span class="pre">img_to_signals_labels</span></code> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2221">#2221</a> by <a class="reference external" href="https://github.com/dangom">Daniel Gomez</a>).</p></li>
</ul>
</section>
<section id="id4">
<h2>Fixes<a class="headerlink" href="#id4" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> no longer truncates region means to their integral part when input images are of integer type (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2195">#2195</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">smooth_img</span></code> no longer fails if <code class="docutils literal notranslate"><span class="pre">fwhm</span></code> is a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2107">#2107</a> by <a class="reference external" href="https://github.com/pausz">Paula Sanz-Leon</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">nilearn</span></code> now installs the necessary dependencies (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2214">#2214</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">new_img_like</span></code> no longer attempts to copy non-iterable headers (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2212">#2212</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>Nilearn no longer raises <code class="docutils literal notranslate"><span class="pre">ImportError</span></code> for nose when Matplotlib is not installed (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2231">#2231</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
<li><p>The argument <code class="docutils literal notranslate"><span class="pre">version='det'</span></code> in function <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_atlas_pauli_2017</span></code> now works as expected (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2235">#2235</a> by <a class="reference external" href="https://github.com/ryanhammonds">Ryan Hammonds</a>).</p></li>
<li><p>Method <code class="xref py py-meth docutils literal notranslate"><span class="pre">inverse_transform</span></code> now works without the need to call <code class="docutils literal notranslate"><span class="pre">transform</span></code> first (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2248">#2248</a> by <a class="reference external" href="http://gael-varoquaux.info/">Gael Varoquaux</a>).</p></li>
</ul>
</section>
<section id="contributors">
<h2>Contributors<a class="headerlink" href="#contributors" title="Permalink to this headline">#</a></h2>
<p>The following people contributed to this release (in alphabetical order):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/effigies">Chris Markiewicz</a></p></li>
<li><p><a class="reference external" href="https://danjgale.github.io/">Dan Gale</a></p></li>
<li><p><a class="reference external" href="https://github.com/dangom">Daniel Gomez</a></p></li>
<li><p><a class="reference external" href="https://github.com/dPys">Derek Pisner</a></p></li>
<li><p><a class="reference external" href="https://elizabeth-dupre.com/#/">Elizabeth DuPre</a></p></li>
<li><p><a class="reference external" href="https://larsoner.com/">Eric Larson</a></p></li>
<li><p><a class="reference external" href="http://gael-varoquaux.info/">Gael Varoquaux</a></p></li>
<li><p><a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a></p></li>
<li><p><a class="reference external" href="https://github.com/JohannesWiesner">Johannes Wiesner</a></p></li>
<li><p><a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a></p></li>
<li><p><a class="reference external" href="https://github.com/pausz">Paula Sanz-Leon</a></p></li>
<li><p><a class="reference external" href="https://ltetrel.github.io/">Loic Tetrel</a></p></li>
<li><p><a class="reference external" href="https://github.com/ryanhammonds">Ryan Hammonds</a></p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="b0">
<h1>0.6.0b0<a class="headerlink" href="#b0" title="Permalink to this headline">#</a></h1>
<p><strong>Released November 2019</strong></p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<div class="line-block">
<div class="line"><strong>Python2 and 3.4 are no longer supported. Pip will raise an error in these environments.</strong></div>
<div class="line"><strong>Minimum supported version of Python is now 3.5 .</strong></div>
<div class="line"><strong>We recommend upgrading to Python 3.6 .</strong></div>
</div>
</div>
<section id="id5">
<h2>NEW<a class="headerlink" href="#id5" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>New function <code class="xref py py-func docutils literal notranslate"><span class="pre">get_data</span></code> to replace the deprecated nibabel method <code class="docutils literal notranslate"><span class="pre">Nifti1Image.get_data</span></code>. Now use <code class="docutils literal notranslate"><span class="pre">nilearn.image.get_data(img)</span></code> rather than <code class="docutils literal notranslate"><span class="pre">img.get_data()</span></code>. This is because Nibabel is removing the <code class="docutils literal notranslate"><span class="pre">get_data</span></code> method. You may also consider using the Nibabel method <code class="docutils literal notranslate"><span class="pre">nibabel.nifti1.Nifti1Image.get_fdata</span></code>, which returns the data cast to floating-point. See <a class="reference external" href="https://github.com/nipy/nibabel/wiki/BIAP8">BIAP8</a>. As a benefit, the <code class="xref py py-func docutils literal notranslate"><span class="pre">get_data</span></code> function works on niimg-like objects such as filenames (see <a class="reference external" href="http://nilearn.github.io/manipulating_images/input_output.html">input_output</a>) (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2172">#2172</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
</ul>
</section>
<section id="id8">
<h2>Changes<a class="headerlink" href="#id8" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>All functions and examples now use function <code class="xref py py-func docutils literal notranslate"><span class="pre">get_data</span></code> rather than the deprecated method <code class="docutils literal notranslate"><span class="pre">nibabel.Nifti1Image.get_data</span></code> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2172">#2172</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_neurovault</span></code> now does not filter out images that have their metadata field <code class="docutils literal notranslate"><span class="pre">is_valid</span></code> cleared by default (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2169">#2169</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Users can now specify fetching data for adults, children, or both from <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_development_fmri</span></code>.</p></li>
</ul>
</section>
<section id="id9">
<h2>Fixes<a class="headerlink" href="#id9" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_connectome</span></code> now correctly displays marker size on ‘l’ and ‘r’ orientations, if an array or a list is passed to the function.</p></li>
</ul>
</section>
<section id="id10">
<h2>Contributors<a class="headerlink" href="#id10" title="Permalink to this headline">#</a></h2>
<p>The following people contributed to this release (in alphabetical order):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://github.com/illdopejake">Jake Vogel</a></p></li>
<li><p><a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a></p></li>
<li><p><a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a></p></li>
<li><p><a class="reference external" href="https://github.com/robbisg">Roberto Guidotti</a></p></li>
</ul>
</div></blockquote>
</section>
</section>
<section id="a0">
<h1>0.6.0a0<a class="headerlink" href="#a0" title="Permalink to this headline">#</a></h1>
<p><strong>Released October 2019</strong></p>
<section id="id11">
<h2>NEW<a class="headerlink" href="#id11" title="Permalink to this headline">#</a></h2>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<div class="line-block">
<div class="line"><strong>Python2 and 3.4 are no longer supported. We recommend upgrading to Python 3.6 minimum.</strong></div>
<div class="line"><br/></div>
<div class="line"><strong>Minimum supported versions of packages have been bumped up.</strong></div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Matplotlib</span> <span class="pre">--</span> <span class="pre">v2.0</span></code>.</div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Scikit-learn</span> <span class="pre">--</span> <span class="pre">v0.19</span></code>.</div>
<div class="line">- <code class="docutils literal notranslate"><span class="pre">Scipy</span> <span class="pre">--</span> <span class="pre">v0.19</span></code>.</div>
</div>
</div>
<ul class="simple">
<li><p>A new method for <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code> instances for generating reports viewable in a web browser, Jupyter Notebook, or VSCode (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2019">#2019</a> by <a class="reference external" href="https://elizabeth-dupre.com/#/">Elizabeth DuPre</a>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">joblib</span></code> is now a dependency (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2090">#2090</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>New class <code class="xref py py-class docutils literal notranslate"><span class="pre">ReNA</span></code> implementing parcellation method <a class="reference internal" href="../glossary.html#term-ReNA"><span class="xref std std-term">ReNA</span></a>: Fast agglomerative clustering based on recursive nearest neighbor grouping. Yields very fast &amp; accurate models, without creation of giant clusters (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1336">#1336</a> by <a class="reference external" href="https://github.com/ahoyosid">Andrés Hoyos Idrobo</a>).</p></li>
<li><p>New function <code class="docutils literal notranslate"><span class="pre">nilearn.plotting.plot_connectome_strength</span></code> to plot the strength of a connectome on a glass brain.  Strength is absolute sum of the edges at a node (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2028">#2028</a> by <a class="reference external" href="https://glemaitre.github.io/">Guillaume Lemaitre</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">resample_img</span></code> has been optimized to pad rather than resample images in the special case when there is only a translation between two spaces. This is a common case in class <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code> when using the <code class="docutils literal notranslate"><span class="pre">mask_strategy="template"</span></code> option for brains in <a class="reference internal" href="../glossary.html#term-MNI"><span class="xref std std-term">MNI</span></a> space (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2025">#2025</a> by <a class="reference external" href="https://gkiar.me/">Greg Kiar</a>).</p></li>
<li><p>New brain development <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> dataset fetcher <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_development_fmri</span></code> can be used to download movie-watching data in children and adults; a light-weight dataset implemented for teaching and usage in the examples.</p></li>
<li><p>New example in <code class="docutils literal notranslate"><span class="pre">examples/05_advanced/plot_age_group_prediction_cross_val.py</span></code> to compare methods for classifying subjects into age groups based on functional connectivity. Similar example in <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_group_level_connectivity.py</span></code> simplified (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2063">#2063</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Merged <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_adhd_spheres.py</span></code> and <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_sphere_based_connectome.py</span></code> to remove duplication across examples. The improved <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_sphere_based_connectome.py</span></code> contains concepts previously reviewed in both examples (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2013">#2013</a> by <a class="reference external" href="https://github.com/illdopejake">Jake Vogel</a>).</p></li>
<li><p>Merged <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_compare_decomposition.py</span></code> and <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_canica_analysis.py</span></code> into an improved <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_compare_decomposition.py</span></code> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2013">#2013</a> by <a class="reference external" href="https://github.com/illdopejake">Jake Vogel</a>).</p></li>
<li><p>The Localizer dataset now follows the <a class="reference internal" href="../glossary.html#term-BIDS"><span class="xref std std-term">BIDS</span></a> organization.</p></li>
</ul>
</section>
<section id="id12">
<h2>Changes<a class="headerlink" href="#id12" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>All the connectivity examples are changed from ADHD to brain development <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> dataset.</p></li>
<li><p>Examples <code class="docutils literal notranslate"><span class="pre">plot_decoding_tutorial</span></code>, <code class="docutils literal notranslate"><span class="pre">plot_haxby_decoder</span></code>, <code class="docutils literal notranslate"><span class="pre">plot_haxby_different_estimators</span></code>, <code class="docutils literal notranslate"><span class="pre">plot_haxby_full_analysis</span></code>, <code class="docutils literal notranslate"><span class="pre">plot_oasis_vbm</span></code> now use <code class="xref py py-class docutils literal notranslate"><span class="pre">Decoder</span></code> and <code class="xref py py-class docutils literal notranslate"><span class="pre">DecoderRegressor</span></code> instead of sklearn SVC and SVR (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2000">#2000</a> by <a class="reference external" href="https://www.imo.universite-paris-saclay.fr/~tbnguyen/">Binh Nguyen</a>).</p></li>
<li><p>Functions <code class="xref py py-func docutils literal notranslate"><span class="pre">view_img_on_surf</span></code>, <code class="xref py py-func docutils literal notranslate"><span class="pre">view_surf</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">view_connectome</span></code> can display a title, and allow disabling the colorbar, and setting its height and the fontsize of its ticklabels (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1951">#1951</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Rework of the standardize-options of function <code class="xref py py-func docutils literal notranslate"><span class="pre">clean</span></code> and the various Maskers in <a class="reference internal" href="../modules/reference.html#module-nilearn.maskers" title="nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code></a>. You can now set <code class="docutils literal notranslate"><span class="pre">standardize</span></code> to <code class="docutils literal notranslate"><span class="pre">zscore</span></code> or <code class="docutils literal notranslate"><span class="pre">psc</span></code>. <code class="docutils literal notranslate"><span class="pre">psc</span></code> stands for <code class="docutils literal notranslate"><span class="pre">Percent</span> <span class="pre">Signal</span> <span class="pre">Change</span></code>, which can be a meaningful metric for <a class="reference internal" href="../glossary.html#term-BOLD"><span class="xref std std-term">BOLD</span></a> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1952">#1952</a> by <a class="reference external" href="https://github.com/Gilles86">Gilles de Hollander</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_img</span></code> now has explicit keyword arguments <code class="docutils literal notranslate"><span class="pre">bg_img</span></code>, <code class="docutils literal notranslate"><span class="pre">vmin</span></code> and <code class="docutils literal notranslate"><span class="pre">vmax</span></code> to control the background image and the bounds of the colormap. These arguments were already accepted in <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> but not documented before (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2157">#2157</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">view_connectome</span></code> now converts <code class="docutils literal notranslate"><span class="pre">NaNs</span></code> in the adjacency matrix to 0 (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2166">#2166</a> by <a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a>).</p></li>
<li><p>Removed the plotting connectomes example which used the Seitzman atlas from <code class="docutils literal notranslate"><span class="pre">examples/03_connectivity/plot_sphere_based_connectome.py</span></code>. The atlas data is unsuitable for the method &amp; the example is redundant (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2177">#2177</a> by <a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a>).</p></li>
</ul>
</section>
<section id="id13">
<h2>Fixes<a class="headerlink" href="#id13" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code> with <code class="docutils literal notranslate"><span class="pre">colorbar=True</span></code> does not crash when images have <code class="docutils literal notranslate"><span class="pre">NaNs</span></code> (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1953">#1953</a> by <a class="reference external" href="https://github.com/KamalakerDadi">Kamalakar Reddy Daddy</a>).</p></li>
<li><p>Function <code class="docutils literal notranslate"><span class="pre">add_contours</span></code> now accepts <code class="docutils literal notranslate"><span class="pre">threshold</span></code> argument for <code class="docutils literal notranslate"><span class="pre">filled=False</span></code>. Now <code class="docutils literal notranslate"><span class="pre">threshold</span></code> is equally applied when asked for fillings in the contours.</p></li>
<li><p>Functions <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_surf</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_surf_stat_map</span></code> no longer threshold zero values when no threshold is given (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1997">#1997</a> by <a class="reference external" href="https://github.com/juhuntenburg">Julia Huntenburg</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_surf_stat_map</span></code> used with a thresholded map but without a background map results in the surface mesh being displayed in half-transparent grey to maintain a 3D perception (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1997">#1997</a> by <a class="reference external" href="https://github.com/juhuntenburg">Julia Huntenburg</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">view_surf</span></code> now accepts surface data provided as a file path.</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code> now correctly displays the left ‘l’ orientation even when the given images are completely masked (empty images) (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/1888">#1888</a> by <a class="reference external" href="https://github.com/KamalakerDadi">Kamalakar Reddy Daddy</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_matrix</span></code> with providing <code class="docutils literal notranslate"><span class="pre">labels=None</span></code>, <code class="docutils literal notranslate"><span class="pre">False</span></code>, or an empty list now correctly disables labels (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2083">#2083</a> by <a class="reference external" href="https://github.com/mjboos">Moritz Boos</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_surf_roi</span></code> now takes <code class="docutils literal notranslate"><span class="pre">vmin</span></code>, and <code class="docutils literal notranslate"><span class="pre">vmax</span></code> parameters (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2052">#2052</a> by <a class="reference external" href="https://github.com/boredStats">Ian Abenes</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_surf_nki_enhanced</span></code> is now downloading the correct left and right functional surface data for each subject (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2118">#2118</a> by <a class="reference external" href="https://github.com/juhuntenburg">Julia Huntenburg</a>).</p></li>
<li><p>Function <code class="xref py py-func docutils literal notranslate"><span class="pre">fetch_atlas_schaefer_2018</span></code> now downloads from release version <code class="docutils literal notranslate"><span class="pre">0.14.3</span></code> (instead of <code class="docutils literal notranslate"><span class="pre">0.8.1</span></code>) by default, which includes corrected region label names along with 700 and 900 region parcelations (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2138">#2138</a> by <a class="reference external" href="https://danjgale.github.io/">Dan Gale</a>).</p></li>
<li><p>Colormap creation functions have been updated to avoid matplotlib deprecation warnings about colormap reversal (<a class="reference external" href="https://github.com/nilearn/nilearn/issues/2131">#2131</a> by <a class="reference external" href="https://larsoner.com/">Eric Larson</a>).</p></li>
<li><p>Neurovault fetcher no longer fails if unable to update dataset metadata file due to faulty permissions.</p></li>
</ul>
</section>
<section id="id14">
<h2>Contributors<a class="headerlink" href="#id14" title="Permalink to this headline">#</a></h2>
<p>The following people contributed to this release (in alphabetical order):</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://twinee.fr/">Alexandre Abraham</a></p></li>
<li><p><a class="reference external" href="http://alexandre.gramfort.net/">Alexandre Gramfort</a></p></li>
<li><p><a class="reference external" href="https://github.com/alpinho">Ana Luisa Pinho</a></p></li>
<li><p><a class="reference external" href="https://github.com/ahoyosid">Andrés Hoyos Idrobo</a></p></li>
<li><p><a class="reference external" href="https://github.com/thomasbazeille">Thomas Bazeille</a></p></li>
<li><p><a class="reference external" href="https://pages.saclay.inria.fr/bertrand.thirion/">Bertrand Thirion</a></p></li>
<li><p><a class="reference external" href="https://github.com/reiningc">Colin Reininger</a></p></li>
<li><p><a class="reference external" href="https://github.com/celinede">Céline Delettre</a></p></li>
<li><p><a class="reference external" href="https://danjgale.github.io/">Dan Gale</a></p></li>
<li><p><a class="reference external" href="https://github.com/dangom">Daniel Gomez</a></p></li>
<li><p><a class="reference external" href="https://elizabeth-dupre.com/#/">Elizabeth DuPre</a></p></li>
<li><p><a class="reference external" href="https://larsoner.com/">Eric Larson</a></p></li>
<li><p><a class="reference external" href="https://github.com/fliem">Franz Liem</a></p></li>
<li><p><a class="reference external" href="http://gael-varoquaux.info/">Gael Varoquaux</a></p></li>
<li><p><a class="reference external" href="https://github.com/Gilles86">Gilles de Hollander</a></p></li>
<li><p><a class="reference external" href="https://gkiar.me/">Greg Kiar</a></p></li>
<li><p><a class="reference external" href="https://glemaitre.github.io/">Guillaume Lemaitre</a></p></li>
<li><p><a class="reference external" href="https://github.com/boredStats">Ian Abenes</a></p></li>
<li><p><a class="reference external" href="https://github.com/illdopejake">Jake Vogel</a></p></li>
<li><p><a class="reference external" href="https://jeromedockes.github.io/">Jerome Dockes</a></p></li>
<li><p><a class="reference external" href="https://github.com/ja-che">Jerome-Alexis Chevalier</a></p></li>
<li><p><a class="reference external" href="https://github.com/juhuntenburg">Julia Huntenburg</a></p></li>
<li><p><a class="reference external" href="https://github.com/KamalakerDadi">Kamalakar Reddy Daddy</a></p></li>
<li><p><a class="reference external" href="https://github.com/kchawla-pi">Kshitij Chawla</a></p></li>
<li><p><a class="reference external" href="https://github.com/mrahim">Mehdi Rahim</a></p></li>
<li><p><a class="reference external" href="https://github.com/mjboos">Moritz Boos</a></p></li>
<li><p><a class="reference external" href="https://github.com/SylvainTakerkart">Sylvain Takerkart</a></p></li>
</ul>
</div></blockquote>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers 2010-2022
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">0.6.0</a><ul>
<li><a class="reference internal" href="#highlights">HIGHLIGHTS</a></li>
<li><a class="reference internal" href="#new">NEW</a></li>
<li><a class="reference internal" href="#enhancements">ENHANCEMENTS</a></li>
<li><a class="reference internal" href="#changes">CHANGES</a></li>
<li><a class="reference internal" href="#fixes">FIXES</a></li>
</ul>
</li>
<li><a class="reference internal" href="#rc">0.6.0rc</a><ul>
<li><a class="reference internal" href="#id2">NEW</a></li>
<li><a class="reference internal" href="#id3">Changes</a></li>
<li><a class="reference internal" href="#id4">Fixes</a></li>
<li><a class="reference internal" href="#contributors">Contributors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#b0">0.6.0b0</a><ul>
<li><a class="reference internal" href="#id5">NEW</a></li>
<li><a class="reference internal" href="#id8">Changes</a></li>
<li><a class="reference internal" href="#id9">Fixes</a></li>
<li><a class="reference internal" href="#id10">Contributors</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a0">0.6.0a0</a><ul>
<li><a class="reference internal" href="#id11">NEW</a></li>
<li><a class="reference internal" href="#id12">Changes</a></li>
<li><a class="reference internal" href="#id13">Fixes</a></li>
<li><a class="reference internal" href="#id14">Contributors</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/design-tabs.js"></script>
    </body>
</html>