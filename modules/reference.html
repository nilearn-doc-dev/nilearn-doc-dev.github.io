<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="API References" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://nilearn.github.io/modules/reference.html" />
  
<meta property="og:site_name" content="Nilearn" />
  
<meta property="og:description" content="This is the class and function reference of nilearn. Please refer to the user guide for more information and usage examples. nilearn.connectome: Functional Connectivity: Tools for computing functio..." />
  
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
  
<meta property="og:image:alt" content="Nilearn" />
  <link rel="search" title="Search" href="../search.html" />

    <link rel="shortcut icon" href="../_static/favicon.ico"/><meta name="generator" content="sphinx-4.4.0, furo 2022.03.04"/>
        <title>API References - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=935aa2abcc5c1da4283d1dc201fb1f0add16d23a" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #f0f3f3;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
      }
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../auto_examples/index.html">Examples</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/00_tutorials/index.html">Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_python_101.html">Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_nilearn_101.html">Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_decoding_tutorial.html">A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/00_tutorials/plot_single_subject_single_run.html">Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/01_plotting/index.html">Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain.html">Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_atlas.html">Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_multiscale_parcellations.html">Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_colormaps.html">Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html">Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_dim_plotting.html">Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_visualization.html">NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_carpet.html">Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_haxby_masks.html">Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surface_projection_strategies.html">Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_plotting.html">Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_prob_atlas.html">Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_stat_map.html">Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_surf_atlas.html">Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/01_plotting/plot_demo_more_plotting.html">More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/02_decoding/index.html">Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_stimuli.html">Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_mixed_gambles_frem.html">FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_frem.html">Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm_space_net.html">Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_anova_svm.html">Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight_surface.html">Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_multiclass.html">The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_searchlight.html">Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_glm_decoding.html">Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_grid_search.html">Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_full_analysis.html">ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_haxby_different_estimators.html">Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_oasis_vbm.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_simulated_data.html">Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_encoding.html">Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/02_decoding/plot_miyawaki_reconstruction.html">Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/03_connectivity/index.html">Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_simulated_connectome.html">Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_compare_decomposition.html">Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_multi_subject_connectome.html">Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_atlas_comparison.html">Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_group_level_connectivity.html">Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_signal_extraction.html">Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_data_driven_parcellations.html">Clustering methods to learn a brain parcellation from fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/03_connectivity/plot_sphere_based_connectome.html">Extract signals on spheres and plot a connectome</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/04_glm_first_level/index.html">GLM: First level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_write_events_file.html">Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fixed_effects.html">Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_adhd_dmn.html">Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_design_matrix.html">Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fir_model.html">Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_hrf.html">Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_fiac_analysis.html">Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_bids_features.html">First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_predictions_residuals.html">Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/04_glm_first_level/plot_first_level_details.html">Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/05_glm_second_level/index.html">GLM : Second level analysis</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_thresholding.html">Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_oasis.html">Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/05_glm_second_level/plot_second_level_association_test.html">Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/06_manipulating_images/index.html">Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_negate_image.html">Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_compare_mean_image.html">Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_smooth_mean_image.html">Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_resample_to_template.html">Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_simple.html">Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_mask_computation.html">Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_affine_transformation.html">Visualization of affine resamplings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/06_manipulating_images/plot_roi_extraction.html">Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../auto_examples/07_advanced/index.html">Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_resting_state.html">Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_simple_analysis.html">Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_bids_analysis.html">BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_neurovault_meta_analysis.html">NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_surface_bids_analysis.html">Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_ica_neurovault.html">NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_haxby_mass_univariate.html">Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../auto_examples/07_advanced/plot_advanced_decoding_scikit.html">Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../user_guide.html">User guide</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../decoding/index.html">Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../decoding/decoding_intro.html">An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/estimator_choice.html">Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/frem.html">FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/space_net.html">SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/searchlight.html">Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../decoding/going_further.html">Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../connectivity/index.html">Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/functional_connectomes.html">Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../connectivity/connectome_extraction.html">Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../developers/group_sparse_covariance.html">Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/resting_state_networks.html">Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/region_extraction.html">Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../connectivity/parcellating.html">Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../plotting/index.html">Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../glm/index.html">Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../glm/glm_intro.html">An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/first_level_model.html">First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../glm/second_level_model.html">Second level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../manipulating_images/index.html">Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/input_output.html">Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/manipulating_images.html">Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../manipulating_images/masker_objects.html">From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../building_blocks/index.html">Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/manual_pipeline.html">Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../building_blocks/neurovault.html">Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="index.html">API References</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="connectome.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.ConnectivityMeasure.html">nilearn.connectome.ConnectivityMeasure</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.GroupSparseCovariance.html">nilearn.connectome.GroupSparseCovariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.GroupSparseCovarianceCV.html">nilearn.connectome.GroupSparseCovarianceCV</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.sym_matrix_to_vec.html">nilearn.connectome.sym_matrix_to_vec</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.vec_to_sym_matrix.html">nilearn.connectome.vec_to_sym_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.group_sparse_covariance.html">nilearn.connectome.group_sparse_covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.cov_to_corr.html">nilearn.connectome.cov_to_corr</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.connectome.prec_to_partial.html">nilearn.connectome.prec_to_partial</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="datasets.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_craddock_2012.html">nilearn.datasets.fetch_atlas_craddock_2012</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_destrieux_2009.html">nilearn.datasets.fetch_atlas_destrieux_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_harvard_oxford.html">nilearn.datasets.fetch_atlas_harvard_oxford</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_juelich.html">nilearn.datasets.fetch_atlas_juelich</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_msdl.html">nilearn.datasets.fetch_atlas_msdl</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_difumo.html">nilearn.datasets.fetch_atlas_difumo</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_power_2011.html">nilearn.datasets.fetch_coords_power_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_seitzman_2018.html">nilearn.datasets.fetch_coords_seitzman_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_smith_2009.html">nilearn.datasets.fetch_atlas_smith_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_yeo_2011.html">nilearn.datasets.fetch_atlas_yeo_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_aal.html">nilearn.datasets.fetch_atlas_aal</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html">nilearn.datasets.fetch_atlas_basc_multiscale_2015</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_allen_2011.html">nilearn.datasets.fetch_atlas_allen_2011</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_pauli_2017.html">nilearn.datasets.fetch_atlas_pauli_2017</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_dosenbach_2010.html">nilearn.datasets.fetch_coords_dosenbach_2010</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_abide_pcp.html">nilearn.datasets.fetch_abide_pcp</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_adhd.html">nilearn.datasets.fetch_adhd</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_development_fmri.html">nilearn.datasets.fetch_development_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_haxby.html">nilearn.datasets.fetch_haxby</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_icbm152_2009.html">nilearn.datasets.fetch_icbm152_2009</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html">nilearn.datasets.fetch_icbm152_brain_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_button_task.html">nilearn.datasets.fetch_localizer_button_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_contrasts.html">nilearn.datasets.fetch_localizer_contrasts</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_calculation_task.html">nilearn.datasets.fetch_localizer_calculation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_miyawaki2008.html">nilearn.datasets.fetch_miyawaki2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_surf_nki_enhanced.html">nilearn.datasets.fetch_surf_nki_enhanced</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_surf_fsaverage.html">nilearn.datasets.fetch_surf_fsaverage</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn.datasets.fetch_atlas_surf_destrieux</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_talairach.html">nilearn.datasets.fetch_atlas_talairach</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_schaefer_2018.html">nilearn.datasets.fetch_atlas_schaefer_2018</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_oasis_vbm.html">nilearn.datasets.fetch_oasis_vbm</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_megatrawls_netmats.html">nilearn.datasets.fetch_megatrawls_netmats</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault.html">nilearn.datasets.fetch_neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_ids.html">nilearn.datasets.fetch_neurovault_ids</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html">nilearn.datasets.fetch_neurovault_auditory_computation_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_motor_task.html">nilearn.datasets.fetch_neurovault_motor_task</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.get_data_dirs.html">nilearn.datasets.get_data_dirs</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_template.html">nilearn.datasets.load_mni152_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_gm_template.html">nilearn.datasets.load_mni152_gm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_wm_template.html">nilearn.datasets.load_mni152_wm_template</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_brain_mask.html">nilearn.datasets.load_mni152_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_gm_mask.html">nilearn.datasets.load_mni152_gm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.load_mni152_wm_mask.html">nilearn.datasets.load_mni152_wm_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html">nilearn.datasets.fetch_language_localizer_demo_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_bids_langloc_dataset.html">nilearn.datasets.fetch_bids_langloc_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_openneuro_dataset_index.html">nilearn.datasets.fetch_openneuro_dataset_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.select_from_index.html">nilearn.datasets.select_from_index</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.patch_openneuro_dataset.html">nilearn.datasets.patch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_openneuro_dataset.html">nilearn.datasets.fetch_openneuro_dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_first_level.html">nilearn.datasets.fetch_localizer_first_level</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_spm_auditory.html">nilearn.datasets.fetch_spm_auditory</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_spm_multimodal_fmri.html">nilearn.datasets.fetch_spm_multimodal_fmri</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.datasets.fetch_fiac_first_level.html">nilearn.datasets.fetch_fiac_first_level</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="decoding.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.Decoder.html">nilearn.decoding.Decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.DecoderRegressor.html">nilearn.decoding.DecoderRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.FREMClassifier.html">nilearn.decoding.FREMClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.FREMRegressor.html">nilearn.decoding.FREMRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.SpaceNetClassifier.html">nilearn.decoding.SpaceNetClassifier</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.SpaceNetRegressor.html">nilearn.decoding.SpaceNetRegressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decoding.SearchLight.html">nilearn.decoding.SearchLight</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="decomposition.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decomposition.CanICA.html">nilearn.decomposition.CanICA</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.decomposition.DictLearning.html">nilearn.decomposition.DictLearning</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="glm.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.Contrast.html">nilearn.glm.Contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.FContrastResults.html">nilearn.glm.FContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.TContrastResults.html">nilearn.glm.TContrastResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.ARModel.html">nilearn.glm.ARModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.OLSModel.html">nilearn.glm.OLSModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.LikelihoodModelResults.html">nilearn.glm.LikelihoodModelResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.RegressionResults.html">nilearn.glm.RegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.SimpleRegressionResults.html">nilearn.glm.SimpleRegressionResults</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.compute_contrast.html">nilearn.glm.compute_contrast</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.compute_fixed_effects.html">nilearn.glm.compute_fixed_effects</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.expression_to_contrast_vector.html">nilearn.glm.expression_to_contrast_vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.fdr_threshold.html">nilearn.glm.fdr_threshold</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.cluster_level_inference.html">nilearn.glm.cluster_level_inference</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.threshold_stats_img.html">nilearn.glm.threshold_stats_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.FirstLevelModel.html">nilearn.glm.first_level.FirstLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.check_design_matrix.html">nilearn.glm.first_level.check_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.compute_regressor.html">nilearn.glm.first_level.compute_regressor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.first_level_from_bids.html">nilearn.glm.first_level.first_level_from_bids</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.glover_dispersion_derivative.html">nilearn.glm.first_level.glover_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.glover_hrf.html">nilearn.glm.first_level.glover_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.glover_time_derivative.html">nilearn.glm.first_level.glover_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.make_first_level_design_matrix.html">nilearn.glm.first_level.make_first_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.mean_scaling.html">nilearn.glm.first_level.mean_scaling</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.run_glm.html">nilearn.glm.first_level.run_glm</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.spm_dispersion_derivative.html">nilearn.glm.first_level.spm_dispersion_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.spm_hrf.html">nilearn.glm.first_level.spm_hrf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.first_level.spm_time_derivative.html">nilearn.glm.first_level.spm_time_derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.second_level.SecondLevelModel.html">nilearn.glm.second_level.SecondLevelModel</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.second_level.make_second_level_design_matrix.html">nilearn.glm.second_level.make_second_level_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.glm.second_level.non_parametric_inference.html">nilearn.glm.second_level.non_parametric_inference</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="image.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.binarize_img.html">nilearn.image.binarize_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.clean_img.html">nilearn.image.clean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.concat_imgs.html">nilearn.image.concat_imgs</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.coord_transform.html">nilearn.image.coord_transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.copy_img.html">nilearn.image.copy_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.crop_img.html">nilearn.image.crop_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.get_data.html">nilearn.image.get_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.high_variance_confounds.html">nilearn.image.high_variance_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.index_img.html">nilearn.image.index_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.iter_img.html">nilearn.image.iter_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.largest_connected_component_img.html">nilearn.image.largest_connected_component_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.load_img.html">nilearn.image.load_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.math_img.html">nilearn.image.math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.mean_img.html">nilearn.image.mean_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.new_img_like.html">nilearn.image.new_img_like</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.resample_img.html">nilearn.image.resample_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.resample_to_img.html">nilearn.image.resample_to_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.reorder_img.html">nilearn.image.reorder_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.smooth_img.html">nilearn.image.smooth_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.swap_img_hemispheres.html">nilearn.image.swap_img_hemispheres</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.image.threshold_img.html">nilearn.image.threshold_img</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="interfaces.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.interfaces.fmriprep.load_confounds.html">nilearn.interfaces.fmriprep.load_confounds</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html">nilearn.interfaces.fmriprep.load_confounds_strategy</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="input_data.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.input_data</span></code>: Loading and Processing Files Easily</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.input_data.NiftiMasker.html">nilearn.input_data.NiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.input_data.MultiNiftiMasker.html">nilearn.input_data.MultiNiftiMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.input_data.NiftiLabelsMasker.html">nilearn.input_data.NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.input_data.NiftiMapsMasker.html">nilearn.input_data.NiftiMapsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.input_data.NiftiSpheresMasker.html">nilearn.input_data.NiftiSpheresMasker</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="masking.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a><input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" role="switch" type="checkbox"/><label for="toctree-checkbox-26"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_epi_mask.html">nilearn.masking.compute_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_multi_epi_mask.html">nilearn.masking.compute_multi_epi_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_brain_mask.html">nilearn.masking.compute_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_multi_brain_mask.html">nilearn.masking.compute_multi_brain_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_background_mask.html">nilearn.masking.compute_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.compute_multi_background_mask.html">nilearn.masking.compute_multi_background_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.intersect_masks.html">nilearn.masking.intersect_masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.apply_mask.html">nilearn.masking.apply_mask</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.masking.unmask.html">nilearn.masking.unmask</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="mass_univariate.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" role="switch" type="checkbox"/><label for="toctree-checkbox-27"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.mass_univariate.permuted_ols.html">nilearn.mass_univariate.permuted_ols</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="plotting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" role="switch" type="checkbox"/><label for="toctree-checkbox-28"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.find_cut_slices.html">nilearn.plotting.find_cut_slices</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.find_xyz_cut_coords.html">nilearn.plotting.find_xyz_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.find_parcellation_cut_coords.html">nilearn.plotting.find_parcellation_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html">nilearn.plotting.find_probabilistic_atlas_cut_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_anat.html">nilearn.plotting.plot_anat</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_img.html">nilearn.plotting.plot_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_epi.html">nilearn.plotting.plot_epi</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_matrix.html">nilearn.plotting.plot_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_roi.html">nilearn.plotting.plot_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_stat_map.html">nilearn.plotting.plot_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html">nilearn.plotting.plot_glass_brain</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_connectome.html">nilearn.plotting.plot_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_markers.html">nilearn.plotting.plot_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_prob_atlas.html">nilearn.plotting.plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_carpet.html">nilearn.plotting.plot_carpet</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_surf.html">nilearn.plotting.plot_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_surf_roi.html">nilearn.plotting.plot_surf_roi</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_surf_contours.html">nilearn.plotting.plot_surf_contours</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_surf_stat_map.html">nilearn.plotting.plot_surf_stat_map</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_img_on_surf.html">nilearn.plotting.plot_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_img_comparison.html">nilearn.plotting.plot_img_comparison</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_design_matrix.html">nilearn.plotting.plot_design_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_event.html">nilearn.plotting.plot_event</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.plot_contrast_matrix.html">nilearn.plotting.plot_contrast_matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.view_surf.html">nilearn.plotting.view_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.view_img_on_surf.html">nilearn.plotting.view_img_on_surf</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.view_connectome.html">nilearn.plotting.view_connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.view_markers.html">nilearn.plotting.view_markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.view_img.html">nilearn.plotting.view_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.show.html">nilearn.plotting.show</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.get_projector.html">nilearn.plotting.displays.get_projector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.get_slicer.html">nilearn.plotting.displays.get_slicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.OrthoProjector.html">nilearn.plotting.displays.OrthoProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.XZProjector.html">nilearn.plotting.displays.XZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YZProjector.html">nilearn.plotting.displays.YZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YXProjector.html">nilearn.plotting.displays.YXProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.XProjector.html">nilearn.plotting.displays.XProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YProjector.html">nilearn.plotting.displays.YProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.ZProjector.html">nilearn.plotting.displays.ZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LZRYProjector.html">nilearn.plotting.displays.LZRYProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LYRZProjector.html">nilearn.plotting.displays.LYRZProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LYRProjector.html">nilearn.plotting.displays.LYRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LZRProjector.html">nilearn.plotting.displays.LZRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LRProjector.html">nilearn.plotting.displays.LRProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.LProjector.html">nilearn.plotting.displays.LProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.RProjector.html">nilearn.plotting.displays.RProjector</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.BaseAxes.html">nilearn.plotting.displays.BaseAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.CutAxes.html">nilearn.plotting.displays.CutAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.GlassBrainAxes.html">nilearn.plotting.displays.GlassBrainAxes</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.BaseSlicer.html">nilearn.plotting.displays.BaseSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.OrthoSlicer.html">nilearn.plotting.displays.OrthoSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.PlotlySurfaceFigure.html">nilearn.plotting.displays.PlotlySurfaceFigure</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.TiledSlicer.html">nilearn.plotting.displays.TiledSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.MosaicSlicer.html">nilearn.plotting.displays.MosaicSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.XZSlicer.html">nilearn.plotting.displays.XZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YZSlicer.html">nilearn.plotting.displays.YZSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YXSlicer.html">nilearn.plotting.displays.YXSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.XSlicer.html">nilearn.plotting.displays.XSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.YSlicer.html">nilearn.plotting.displays.YSlicer</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.plotting.displays.ZSlicer.html">nilearn.plotting.displays.ZSlicer</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="regions.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" role="switch" type="checkbox"/><label for="toctree-checkbox-29"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.connected_regions.html">nilearn.regions.connected_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.connected_label_regions.html">nilearn.regions.connected_label_regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.img_to_signals_labels.html">nilearn.regions.img_to_signals_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.signals_to_img_labels.html">nilearn.regions.signals_to_img_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.img_to_signals_maps.html">nilearn.regions.img_to_signals_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.signals_to_img_maps.html">nilearn.regions.signals_to_img_maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.RegionExtractor.html">nilearn.regions.RegionExtractor</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.Parcellations.html">nilearn.regions.Parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.regions.ReNA.html">nilearn.regions.ReNA</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="reporting.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a><input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" role="switch" type="checkbox"/><label for="toctree-checkbox-30"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.reporting.get_clusters_table.html">nilearn.reporting.get_clusters_table</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.reporting.make_glm_report.html">nilearn.reporting.make_glm_report</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="signal.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a><input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" role="switch" type="checkbox"/><label for="toctree-checkbox-31"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.signal.butterworth.html">nilearn.signal.butterworth</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.signal.clean.html">nilearn.signal.clean</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.signal.high_variance_confounds.html">nilearn.signal.high_variance_confounds</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="surface.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a><input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" role="switch" type="checkbox"/><label for="toctree-checkbox-32"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.surface.load_surf_data.html">nilearn.surface.load_surf_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.surface.load_surf_mesh.html">nilearn.surface.load_surf_mesh</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nilearn.surface.vol_to_surf.html">nilearn.surface.vol_to_surf</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">Glossary</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nistats_migration.html">Migrating from Nistats</a></li>
<li class="toctree-l1"><a class="reference internal" href="../development.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../maintenance.html">Maintenance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../whats_new.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../authors.html">Team</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/nilearn/nilearn">GitHub Repository</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="api-references">
<h1>API References<a class="headerlink" href="#api-references" title="Permalink to this headline">#</a></h1>
<div class="admonition danger">
<p class="admonition-title">Danger</p>
<p>This part of the documentation is no longer up to date
and was moved to <a class="reference internal" href="index.html#modules"><span class="std std-ref">the modules section</span></a>.</p>
</div>
<p>This is the class and function reference of nilearn. Please refer to
the <a class="reference internal" href="../user_guide.html#user-guide"><span class="std std-ref">user guide</span></a> for more information and usage examples.</p>
<section id="module-nilearn.connectome">
<span id="nilearn-connectome-functional-connectivity"></span><h2><a class="reference internal" href="#module-nilearn.connectome" title="nilearn.connectome"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code></a>: Functional Connectivity<a class="headerlink" href="#module-nilearn.connectome" title="Permalink to this headline">#</a></h2>
<p>Tools for computing functional connectivity matrices and also
implementation of algorithm for sparse multi subjects learning
of Gaussian graphical models.</p>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.connectome.ConnectivityMeasure.html#nilearn.connectome.ConnectivityMeasure" title="nilearn.connectome.ConnectivityMeasure"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ConnectivityMeasure</span></code></a>([cov_estimator, kind, ...])</p></td>
<td><p>A class that computes different kinds of functional connectivity matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.connectome.GroupSparseCovariance.html#nilearn.connectome.GroupSparseCovariance" title="nilearn.connectome.GroupSparseCovariance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupSparseCovariance</span></code></a>([alpha, tol, ...])</p></td>
<td><p>Covariance and precision matrix estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.connectome.GroupSparseCovarianceCV.html#nilearn.connectome.GroupSparseCovarianceCV" title="nilearn.connectome.GroupSparseCovarianceCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GroupSparseCovarianceCV</span></code></a>([alphas, ...])</p></td>
<td><p>Sparse inverse covariance w/ cross-validated choice of the parameter.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.connectome.sym_matrix_to_vec.html#nilearn.connectome.sym_matrix_to_vec" title="nilearn.connectome.sym_matrix_to_vec"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sym_matrix_to_vec</span></code></a>(symmetric[, discard_diagonal])</p></td>
<td><p>Return the flattened lower triangular part of an array.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.connectome.vec_to_sym_matrix.html#nilearn.connectome.vec_to_sym_matrix" title="nilearn.connectome.vec_to_sym_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vec_to_sym_matrix</span></code></a>(vec[, diagonal])</p></td>
<td><p>Return the symmetric matrix given its flattened lower triangular part.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.connectome.group_sparse_covariance.html#nilearn.connectome.group_sparse_covariance" title="nilearn.connectome.group_sparse_covariance"><code class="xref py py-obj docutils literal notranslate"><span class="pre">group_sparse_covariance</span></code></a>(subjects, alpha[, ...])</p></td>
<td><p>Compute sparse precision matrices and covariance matrices.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.connectome.cov_to_corr.html#nilearn.connectome.cov_to_corr" title="nilearn.connectome.cov_to_corr"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cov_to_corr</span></code></a>(covariance)</p></td>
<td><p>Return correlation matrix for a given covariance matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.connectome.prec_to_partial.html#nilearn.connectome.prec_to_partial" title="nilearn.connectome.prec_to_partial"><code class="xref py py-obj docutils literal notranslate"><span class="pre">prec_to_partial</span></code></a>(precision)</p></td>
<td><p>Return partial correlation matrix for a given precision matrix.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.datasets">
<span id="nilearn-datasets-automatic-dataset-fetching"></span><h2><a class="reference internal" href="#module-nilearn.datasets" title="nilearn.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code></a>: Automatic Dataset Fetching<a class="headerlink" href="#module-nilearn.datasets" title="Permalink to this headline">#</a></h2>
<p>Helper functions to download NeuroImaging datasets</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="../manipulating_images/input_output.html#datasets"><span class="std std-ref">Fetching open datasets from Internet</span></a> section for further details.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_craddock_2012.html#nilearn.datasets.fetch_atlas_craddock_2012" title="nilearn.datasets.fetch_atlas_craddock_2012"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_craddock_2012</span></code></a>([data_dir, url, ...])</p></td>
<td><p>Download and return file names for the Craddock 2012 parcellation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_destrieux_2009.html#nilearn.datasets.fetch_atlas_destrieux_2009" title="nilearn.datasets.fetch_atlas_destrieux_2009"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_destrieux_2009</span></code></a>([lateralized, ...])</p></td>
<td><p>Download and load the Destrieux cortical atlas (dated 2009).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_harvard_oxford.html#nilearn.datasets.fetch_atlas_harvard_oxford" title="nilearn.datasets.fetch_atlas_harvard_oxford"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_harvard_oxford</span></code></a>(atlas_name[, ...])</p></td>
<td><p>Load Harvard-Oxford parcellations from FSL.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_juelich.html#nilearn.datasets.fetch_atlas_juelich" title="nilearn.datasets.fetch_atlas_juelich"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_juelich</span></code></a>(atlas_name[, data_dir, ...])</p></td>
<td><p>Load Juelich parcellations from FSL.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_msdl.html#nilearn.datasets.fetch_atlas_msdl" title="nilearn.datasets.fetch_atlas_msdl"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_msdl</span></code></a>([data_dir, url, resume, ...])</p></td>
<td><p>Download and load the MSDL brain atlas.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_difumo.html#nilearn.datasets.fetch_atlas_difumo" title="nilearn.datasets.fetch_atlas_difumo"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_difumo</span></code></a>([dimension, ...])</p></td>
<td><p>Fetch DiFuMo brain atlas</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_power_2011.html#nilearn.datasets.fetch_coords_power_2011" title="nilearn.datasets.fetch_coords_power_2011"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_coords_power_2011</span></code></a>()</p></td>
<td><p>Download and load the Power et al. brain atlas composed of 264 ROIs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_seitzman_2018.html#nilearn.datasets.fetch_coords_seitzman_2018" title="nilearn.datasets.fetch_coords_seitzman_2018"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_coords_seitzman_2018</span></code></a>([ordered_regions])</p></td>
<td><p>Load the Seitzman et al. 300 ROIs.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_smith_2009.html#nilearn.datasets.fetch_atlas_smith_2009" title="nilearn.datasets.fetch_atlas_smith_2009"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_smith_2009</span></code></a>([data_dir, mirror, ...])</p></td>
<td><p>Download and load the Smith <a class="reference internal" href="../glossary.html#term-ICA"><span class="xref std std-term">ICA</span></a> and BrainMap atlas (2009).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_yeo_2011.html#nilearn.datasets.fetch_atlas_yeo_2011" title="nilearn.datasets.fetch_atlas_yeo_2011"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_yeo_2011</span></code></a>([data_dir, url, ...])</p></td>
<td><p>Download and return file names for the Yeo 2011 parcellation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_aal.html#nilearn.datasets.fetch_atlas_aal" title="nilearn.datasets.fetch_atlas_aal"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_aal</span></code></a>([version, data_dir, url, ...])</p></td>
<td><p>Downloads and returns the AAL template for SPM 12.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_basc_multiscale_2015.html#nilearn.datasets.fetch_atlas_basc_multiscale_2015" title="nilearn.datasets.fetch_atlas_basc_multiscale_2015"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_basc_multiscale_2015</span></code></a>([version, ...])</p></td>
<td><p>Downloads and loads multiscale functional brain parcellations.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_allen_2011.html#nilearn.datasets.fetch_atlas_allen_2011" title="nilearn.datasets.fetch_atlas_allen_2011"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_allen_2011</span></code></a>([data_dir, url, ...])</p></td>
<td><p>Download and return file names for the Allen and MIALAB <a class="reference internal" href="../glossary.html#term-ICA"><span class="xref std std-term">ICA</span></a> atlas (dated 2011).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_pauli_2017.html#nilearn.datasets.fetch_atlas_pauli_2017" title="nilearn.datasets.fetch_atlas_pauli_2017"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_pauli_2017</span></code></a>([version, data_dir, ...])</p></td>
<td><p>Download the Pauli et al. (2017) atlas.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_coords_dosenbach_2010.html#nilearn.datasets.fetch_coords_dosenbach_2010" title="nilearn.datasets.fetch_coords_dosenbach_2010"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_coords_dosenbach_2010</span></code></a>([ordered_regions])</p></td>
<td><p>Load the Dosenbach et al. 160 ROIs.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_abide_pcp.html#nilearn.datasets.fetch_abide_pcp" title="nilearn.datasets.fetch_abide_pcp"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_abide_pcp</span></code></a>([data_dir, n_subjects, ...])</p></td>
<td><p>Fetch ABIDE dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_adhd.html#nilearn.datasets.fetch_adhd" title="nilearn.datasets.fetch_adhd"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_adhd</span></code></a>([n_subjects, data_dir, url, ...])</p></td>
<td><p>Download and load the ADHD resting-state dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_development_fmri.html#nilearn.datasets.fetch_development_fmri" title="nilearn.datasets.fetch_development_fmri"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_development_fmri</span></code></a>([n_subjects, ...])</p></td>
<td><p>Fetch movie watching based brain development dataset (fMRI)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_haxby.html#nilearn.datasets.fetch_haxby" title="nilearn.datasets.fetch_haxby"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_haxby</span></code></a>([data_dir, subjects, ...])</p></td>
<td><p>Download and loads complete haxby dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_icbm152_2009.html#nilearn.datasets.fetch_icbm152_2009" title="nilearn.datasets.fetch_icbm152_2009"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_icbm152_2009</span></code></a>([data_dir, url, resume, ...])</p></td>
<td><p>Download and load the ICBM152 template (dated 2009).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_icbm152_brain_gm_mask.html#nilearn.datasets.fetch_icbm152_brain_gm_mask" title="nilearn.datasets.fetch_icbm152_brain_gm_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_icbm152_brain_gm_mask</span></code></a>([data_dir, ...])</p></td>
<td><p>Downloads ICBM152 template first, then loads the 'gm' mask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_button_task.html#nilearn.datasets.fetch_localizer_button_task" title="nilearn.datasets.fetch_localizer_button_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_localizer_button_task</span></code></a>([data_dir, url, ...])</p></td>
<td><p>Fetch left vs right button press contrast maps from the localizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_contrasts.html#nilearn.datasets.fetch_localizer_contrasts" title="nilearn.datasets.fetch_localizer_contrasts"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_localizer_contrasts</span></code></a>(contrasts[, ...])</p></td>
<td><p>Download and load Brainomics/Localizer dataset (94 subjects).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_calculation_task.html#nilearn.datasets.fetch_localizer_calculation_task" title="nilearn.datasets.fetch_localizer_calculation_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_localizer_calculation_task</span></code></a>([...])</p></td>
<td><p>Fetch calculation task contrast maps from the localizer.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_miyawaki2008.html#nilearn.datasets.fetch_miyawaki2008" title="nilearn.datasets.fetch_miyawaki2008"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_miyawaki2008</span></code></a>([data_dir, url, resume, ...])</p></td>
<td><p>Download and loads Miyawaki et al. 2008 dataset (153MB).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_surf_nki_enhanced.html#nilearn.datasets.fetch_surf_nki_enhanced" title="nilearn.datasets.fetch_surf_nki_enhanced"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_surf_nki_enhanced</span></code></a>([n_subjects, ...])</p></td>
<td><p>Download and load the NKI enhanced resting-state dataset, preprocessed and projected to the fsaverage5 space surface.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_surf_fsaverage.html#nilearn.datasets.fetch_surf_fsaverage" title="nilearn.datasets.fetch_surf_fsaverage"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_surf_fsaverage</span></code></a>([mesh, data_dir])</p></td>
<td><p>Download a Freesurfer fsaverage surface.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_surf_destrieux.html#nilearn.datasets.fetch_atlas_surf_destrieux" title="nilearn.datasets.fetch_atlas_surf_destrieux"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_surf_destrieux</span></code></a>([data_dir, url, ...])</p></td>
<td><p>Download and load Destrieux et al, 2010 cortical atlas.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_talairach.html#nilearn.datasets.fetch_atlas_talairach" title="nilearn.datasets.fetch_atlas_talairach"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_talairach</span></code></a>(level_name[, ...])</p></td>
<td><p>Download the Talairach atlas.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_atlas_schaefer_2018.html#nilearn.datasets.fetch_atlas_schaefer_2018" title="nilearn.datasets.fetch_atlas_schaefer_2018"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_atlas_schaefer_2018</span></code></a>([n_rois, ...])</p></td>
<td><p>Download and return file names for the Schaefer 2018 parcellation.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_oasis_vbm.html#nilearn.datasets.fetch_oasis_vbm" title="nilearn.datasets.fetch_oasis_vbm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_oasis_vbm</span></code></a>([n_subjects, ...])</p></td>
<td><p>Download and load Oasis "cross-sectional MRI" dataset (416 subjects).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_megatrawls_netmats.html#nilearn.datasets.fetch_megatrawls_netmats" title="nilearn.datasets.fetch_megatrawls_netmats"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_megatrawls_netmats</span></code></a>([dimensionality, ...])</p></td>
<td><p>Downloads and returns Network Matrices data from MegaTrawls release in HCP.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault.html#nilearn.datasets.fetch_neurovault" title="nilearn.datasets.fetch_neurovault"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_neurovault</span></code></a>([max_images, ...])</p></td>
<td><p>Download data from neurovault.org that match certain criteria.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_ids.html#nilearn.datasets.fetch_neurovault_ids" title="nilearn.datasets.fetch_neurovault_ids"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_neurovault_ids</span></code></a>([collection_ids, ...])</p></td>
<td><p>Download specific images and collections from neurovault.org.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_auditory_computation_task.html#nilearn.datasets.fetch_neurovault_auditory_computation_task" title="nilearn.datasets.fetch_neurovault_auditory_computation_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_neurovault_auditory_computation_task</span></code></a>([...])</p></td>
<td><p>Fetch a contrast map from NeuroVault showing the effect of mental subtraction upon auditory instructions</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_neurovault_motor_task.html#nilearn.datasets.fetch_neurovault_motor_task" title="nilearn.datasets.fetch_neurovault_motor_task"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_neurovault_motor_task</span></code></a>([data_dir, verbose])</p></td>
<td><p>Fetch left vs right button press group contrast map from NeuroVault.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.get_data_dirs.html#nilearn.datasets.get_data_dirs" title="nilearn.datasets.get_data_dirs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_data_dirs</span></code></a>([data_dir])</p></td>
<td><p>Returns the directories in which nilearn looks for data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_template.html#nilearn.datasets.load_mni152_template" title="nilearn.datasets.load_mni152_template"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_template</span></code></a>([resolution])</p></td>
<td><p>Load the MNI152 skullstripped T1 template.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_gm_template.html#nilearn.datasets.load_mni152_gm_template" title="nilearn.datasets.load_mni152_gm_template"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_gm_template</span></code></a>([resolution])</p></td>
<td><p>Load the MNI152 grey-matter template.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_wm_template.html#nilearn.datasets.load_mni152_wm_template" title="nilearn.datasets.load_mni152_wm_template"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_wm_template</span></code></a>([resolution])</p></td>
<td><p>Load the MNI152 white-matter template.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_brain_mask.html#nilearn.datasets.load_mni152_brain_mask" title="nilearn.datasets.load_mni152_brain_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_brain_mask</span></code></a>([resolution, threshold])</p></td>
<td><p>Load the MNI152 whole-brain mask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_gm_mask.html#nilearn.datasets.load_mni152_gm_mask" title="nilearn.datasets.load_mni152_gm_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_gm_mask</span></code></a>([resolution, threshold, ...])</p></td>
<td><p>Load the MNI152 grey-matter mask.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.load_mni152_wm_mask.html#nilearn.datasets.load_mni152_wm_mask" title="nilearn.datasets.load_mni152_wm_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_mni152_wm_mask</span></code></a>([resolution, threshold, ...])</p></td>
<td><p>Load the MNI152 white-matter mask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_language_localizer_demo_dataset.html#nilearn.datasets.fetch_language_localizer_demo_dataset" title="nilearn.datasets.fetch_language_localizer_demo_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_language_localizer_demo_dataset</span></code></a>([...])</p></td>
<td><p>Download language localizer demo dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_bids_langloc_dataset.html#nilearn.datasets.fetch_bids_langloc_dataset" title="nilearn.datasets.fetch_bids_langloc_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_bids_langloc_dataset</span></code></a>([data_dir, verbose])</p></td>
<td><p>Download language localizer example <a class="reference internal" href="../glossary.html#term-BIDS"><span class="xref std std-term">bids</span></a> dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_openneuro_dataset_index.html#nilearn.datasets.fetch_openneuro_dataset_index" title="nilearn.datasets.fetch_openneuro_dataset_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_openneuro_dataset_index</span></code></a>([data_dir, ...])</p></td>
<td><p>Download a file with OpenNeuro <a class="reference internal" href="../glossary.html#term-BIDS"><span class="xref std std-term">BIDS</span></a> dataset index.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.select_from_index.html#nilearn.datasets.select_from_index" title="nilearn.datasets.select_from_index"><code class="xref py py-obj docutils literal notranslate"><span class="pre">select_from_index</span></code></a>(urls[, inclusion_filters, ...])</p></td>
<td><p>Select subset of urls with given filters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.patch_openneuro_dataset.html#nilearn.datasets.patch_openneuro_dataset" title="nilearn.datasets.patch_openneuro_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">patch_openneuro_dataset</span></code></a>(file_list)</p></td>
<td><p>Add symlinks for files not named according to latest <a class="reference internal" href="../glossary.html#term-BIDS"><span class="xref std std-term">BIDS</span></a> conventions.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_openneuro_dataset.html#nilearn.datasets.fetch_openneuro_dataset" title="nilearn.datasets.fetch_openneuro_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_openneuro_dataset</span></code></a>([urls, data_dir, ...])</p></td>
<td><p>Download OpenNeuro <a class="reference internal" href="../glossary.html#term-BIDS"><span class="xref std std-term">BIDS</span></a> dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_localizer_first_level.html#nilearn.datasets.fetch_localizer_first_level" title="nilearn.datasets.fetch_localizer_first_level"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_localizer_first_level</span></code></a>([data_dir, verbose])</p></td>
<td><p>Download a first-level localizer fMRI dataset</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_spm_auditory.html#nilearn.datasets.fetch_spm_auditory" title="nilearn.datasets.fetch_spm_auditory"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_spm_auditory</span></code></a>([data_dir, data_name, ...])</p></td>
<td><p>Function to fetch SPM auditory single-subject data.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_spm_multimodal_fmri.html#nilearn.datasets.fetch_spm_multimodal_fmri" title="nilearn.datasets.fetch_spm_multimodal_fmri"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_spm_multimodal_fmri</span></code></a>([data_dir, ...])</p></td>
<td><p>Fetcher for Multi-modal Face Dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.datasets.fetch_fiac_first_level.html#nilearn.datasets.fetch_fiac_first_level" title="nilearn.datasets.fetch_fiac_first_level"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fetch_fiac_first_level</span></code></a>([data_dir, verbose])</p></td>
<td><p>Download a first-level fiac fMRI dataset (2 sessions)</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.decoding">
<span id="nilearn-decoding-decoding"></span><span id="decoding-ref"></span><h2><a class="reference internal" href="#module-nilearn.decoding" title="nilearn.decoding"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code></a>: Decoding<a class="headerlink" href="#module-nilearn.decoding" title="Permalink to this headline">#</a></h2>
<p>Decoding tools and algorithms.</p>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.decoding.Decoder.html#nilearn.decoding.Decoder" title="nilearn.decoding.Decoder"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Decoder</span></code></a>([estimator, mask, cv, param_grid, ...])</p></td>
<td><p>A wrapper for popular classification strategies in neuroimaging.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.decoding.DecoderRegressor.html#nilearn.decoding.DecoderRegressor" title="nilearn.decoding.DecoderRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DecoderRegressor</span></code></a>([estimator, mask, cv, ...])</p></td>
<td><p>A wrapper for popular regression strategies in neuroimaging.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.decoding.FREMClassifier.html#nilearn.decoding.FREMClassifier" title="nilearn.decoding.FREMClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FREMClassifier</span></code></a>([estimator, mask, cv, ...])</p></td>
<td><p>State of the art decoding scheme applied to usual classifiers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.decoding.FREMRegressor.html#nilearn.decoding.FREMRegressor" title="nilearn.decoding.FREMRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FREMRegressor</span></code></a>([estimator, mask, cv, ...])</p></td>
<td><p>State of the art decoding scheme applied to usual regression estimators.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.decoding.SpaceNetClassifier.html#nilearn.decoding.SpaceNetClassifier" title="nilearn.decoding.SpaceNetClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SpaceNetClassifier</span></code></a>([penalty, loss, ...])</p></td>
<td><p>Classification learners with sparsity and spatial priors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.decoding.SpaceNetRegressor.html#nilearn.decoding.SpaceNetRegressor" title="nilearn.decoding.SpaceNetRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SpaceNetRegressor</span></code></a>([penalty, l1_ratios, ...])</p></td>
<td><p>Regression learners with sparsity and spatial priors.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.decoding.SearchLight.html#nilearn.decoding.SearchLight" title="nilearn.decoding.SearchLight"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SearchLight</span></code></a>(mask_img[, process_mask_img, ...])</p></td>
<td><p>Implement search_light analysis using an arbitrary type of classifier.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.decomposition">
<span id="nilearn-decomposition-multivariate-decompositions"></span><span id="decomposition-ref"></span><h2><a class="reference internal" href="#module-nilearn.decomposition" title="nilearn.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code></a>: Multivariate Decompositions<a class="headerlink" href="#module-nilearn.decomposition" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="#module-nilearn.decomposition" title="nilearn.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code></a> module includes a subject level
variant of the ICA called Canonical ICA.</p>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.decomposition.CanICA.html#nilearn.decomposition.CanICA" title="nilearn.decomposition.CanICA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CanICA</span></code></a>([mask, n_components, smoothing_fwhm, ...])</p></td>
<td><p>Perform Canonical Independent Component Analysis <a class="reference internal" href="generated/nilearn.decomposition.CanICA.html#r637c2563345c-1" id="id1"><span>[R637c2563345c-1]</span></a> <a class="reference internal" href="generated/nilearn.decomposition.CanICA.html#r637c2563345c-2" id="id2"><span>[R637c2563345c-2]</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.decomposition.DictLearning.html#nilearn.decomposition.DictLearning" title="nilearn.decomposition.DictLearning"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DictLearning</span></code></a>([n_components, n_epochs, ...])</p></td>
<td><p>Perform a map learning algorithm based on spatial component sparsity, over a <a class="reference internal" href="../glossary.html#term-CanICA"><span class="xref std std-term">CanICA</span></a> initialization <a class="reference internal" href="generated/nilearn.decomposition.DictLearning.html#rd0eec3116114-1" id="id3"><span>[Rd0eec3116114-1]</span></a>.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.image">
<span id="nilearn-image-image-processing-and-resampling-utilities"></span><span id="image-ref"></span><h2><a class="reference internal" href="#module-nilearn.image" title="nilearn.image"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code></a>: Image Processing and Resampling Utilities<a class="headerlink" href="#module-nilearn.image" title="Permalink to this headline">#</a></h2>
<p>Mathematical operations working on Niimg-like objects like a (3+)D block of
data, and an affine.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.binarize_img.html#nilearn.image.binarize_img" title="nilearn.image.binarize_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">binarize_img</span></code></a>(img[, threshold, mask_img])</p></td>
<td><p>Binarize an image such that its values are either 0 or 1.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.clean_img.html#nilearn.image.clean_img" title="nilearn.image.clean_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clean_img</span></code></a>(imgs[, runs, detrend, ...])</p></td>
<td><p>Improve SNR on masked fMRI signals.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.concat_imgs.html#nilearn.image.concat_imgs" title="nilearn.image.concat_imgs"><code class="xref py py-obj docutils literal notranslate"><span class="pre">concat_imgs</span></code></a>(niimgs[, dtype, ensure_ndim, ...])</p></td>
<td><p>Concatenate a list of 3D/4D niimgs of varying lengths.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.coord_transform.html#nilearn.image.coord_transform" title="nilearn.image.coord_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">coord_transform</span></code></a>(x, y, z, affine)</p></td>
<td><p>Convert the x, y, z coordinates from one image space to another</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.copy_img.html#nilearn.image.copy_img" title="nilearn.image.copy_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">copy_img</span></code></a>(img)</p></td>
<td><p>Copy an image to a nibabel.Nifti1Image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.crop_img.html#nilearn.image.crop_img" title="nilearn.image.crop_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">crop_img</span></code></a>(img[, rtol, copy, pad, return_offset])</p></td>
<td><p>Crops an image as much as possible.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.get_data.html#nilearn.image.get_data" title="nilearn.image.get_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_data</span></code></a>(img)</p></td>
<td><p>Get the image data as a <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.high_variance_confounds.html#nilearn.image.high_variance_confounds" title="nilearn.image.high_variance_confounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">high_variance_confounds</span></code></a>(imgs[, n_confounds, ...])</p></td>
<td><p>Return confounds signals extracted from input signals with highest variance.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.index_img.html#nilearn.image.index_img" title="nilearn.image.index_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">index_img</span></code></a>(imgs, index)</p></td>
<td><p>Indexes into a 4D Niimg-like object in the fourth dimension.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.iter_img.html#nilearn.image.iter_img" title="nilearn.image.iter_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">iter_img</span></code></a>(imgs)</p></td>
<td><p>Iterates over a 4D Niimg-like object in the fourth dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.largest_connected_component_img.html#nilearn.image.largest_connected_component_img" title="nilearn.image.largest_connected_component_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">largest_connected_component_img</span></code></a>(imgs)</p></td>
<td><p>Return the largest connected component of an image or list of images.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.load_img.html#nilearn.image.load_img" title="nilearn.image.load_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_img</span></code></a>(img[, wildcards, dtype])</p></td>
<td><p>Load a Niimg-like object from filenames or list of filenames.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.math_img.html#nilearn.image.math_img" title="nilearn.image.math_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">math_img</span></code></a>(formula, **imgs)</p></td>
<td><p>Interpret a numpy based string formula using niimg in named parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.mean_img.html#nilearn.image.mean_img" title="nilearn.image.mean_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mean_img</span></code></a>(imgs[, target_affine, ...])</p></td>
<td><p>Compute the mean of the images over time or the 4th dimension.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.new_img_like.html#nilearn.image.new_img_like" title="nilearn.image.new_img_like"><code class="xref py py-obj docutils literal notranslate"><span class="pre">new_img_like</span></code></a>(ref_niimg, data[, affine, ...])</p></td>
<td><p>Create a new image of the same class as the reference image</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.resample_img.html#nilearn.image.resample_img" title="nilearn.image.resample_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resample_img</span></code></a>(img[, target_affine, ...])</p></td>
<td><p>Resample a Niimg-like object</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.resample_to_img.html#nilearn.image.resample_to_img" title="nilearn.image.resample_to_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">resample_to_img</span></code></a>(source_img, target_img[, ...])</p></td>
<td><p>Resample a Niimg-like source image on a target Niimg-like image (no registration is performed: the image should already be aligned).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.reorder_img.html#nilearn.image.reorder_img" title="nilearn.image.reorder_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reorder_img</span></code></a>(img[, resample])</p></td>
<td><p>Returns an image with the affine diagonal (by permuting axes).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.smooth_img.html#nilearn.image.smooth_img" title="nilearn.image.smooth_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">smooth_img</span></code></a>(imgs, fwhm)</p></td>
<td><p>Smooth images by applying a Gaussian filter.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.image.swap_img_hemispheres.html#nilearn.image.swap_img_hemispheres" title="nilearn.image.swap_img_hemispheres"><code class="xref py py-obj docutils literal notranslate"><span class="pre">swap_img_hemispheres</span></code></a>(img)</p></td>
<td><p>Performs swapping of hemispheres in the indicated NIfTI image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.image.threshold_img.html#nilearn.image.threshold_img" title="nilearn.image.threshold_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_img</span></code></a>(img, threshold[, ...])</p></td>
<td><p>Threshold the given input image, mostly statistical or atlas images.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.interfaces">
<span id="nilearn-interfaces-loading-components-from-interfaces"></span><span id="interfaces-ref"></span><h2><a class="reference internal" href="#module-nilearn.interfaces" title="nilearn.interfaces"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code></a>: Loading components from interfaces<a class="headerlink" href="#module-nilearn.interfaces" title="Permalink to this headline">#</a></h2>
<p>Interfaces for Nilearn.</p>
<section id="module-nilearn.interfaces.fmriprep">
<span id="nilearn-interfaces-fmriprep"></span><h3><a class="reference internal" href="#module-nilearn.interfaces.fmriprep" title="nilearn.interfaces.fmriprep"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.fmriprep</span></code></a><a class="headerlink" href="#module-nilearn.interfaces.fmriprep" title="Permalink to this headline">#</a></h3>
<p>The <a class="reference internal" href="#module-nilearn.interfaces.fmriprep" title="nilearn.interfaces.fmriprep"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.fmriprep</span></code></a> module includes tools to preprocess
neuroimaging data and access <a class="reference internal" href="../glossary.html#term-fMRIPrep"><span class="xref std std-term">fMRIPrep</span></a> generated confounds.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.interfaces.fmriprep.load_confounds.html#nilearn.interfaces.fmriprep.load_confounds" title="nilearn.interfaces.fmriprep.load_confounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_confounds</span></code></a>(img_files[, strategy, ...])</p></td>
<td><p>Use confounds from <a class="reference internal" href="../glossary.html#term-fMRIPrep"><span class="xref std std-term">fMRIPrep</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.interfaces.fmriprep.load_confounds_strategy.html#nilearn.interfaces.fmriprep.load_confounds_strategy" title="nilearn.interfaces.fmriprep.load_confounds_strategy"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_confounds_strategy</span></code></a>(img_files[, ...])</p></td>
<td><p>Use preset strategy to load confounds from <a class="reference internal" href="../glossary.html#term-fMRIPrep"><span class="xref std std-term">fMRIPrep</span></a>.</p></td>
</tr>
</tbody>
</table></div>
</section>
</section>
<section id="module-nilearn.maskers">
<span id="nilearn-maskers-extracting-signals-from-brain-images"></span><span id="maskers-ref"></span><h2><a class="reference internal" href="#module-nilearn.maskers" title="nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code></a>: Extracting Signals from Brain Images<a class="headerlink" href="#module-nilearn.maskers" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="#module-nilearn.maskers" title="nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code></a> contains masker objects.</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="../manipulating_images/masker_objects.html#nifti-masker"><span class="std std-ref">NiftiMasker: applying a mask to load time-series</span></a> section for further details.</p>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.maskers.BaseMasker.html#nilearn.maskers.BaseMasker" title="nilearn.maskers.BaseMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseMasker</span></code></a>()</p></td>
<td><p>Base class for NiftiMaskers.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.maskers.NiftiMasker.html#nilearn.maskers.NiftiMasker" title="nilearn.maskers.NiftiMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NiftiMasker</span></code></a>([mask_img, runs, ...])</p></td>
<td><p>Applying a mask to extract time-series from Niimg-like objects.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.maskers.MultiNiftiMasker.html#nilearn.maskers.MultiNiftiMasker" title="nilearn.maskers.MultiNiftiMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiNiftiMasker</span></code></a>([mask_img, smoothing_fwhm, ...])</p></td>
<td><p>Class for masking of Niimg-like objects.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.maskers.NiftiLabelsMasker.html#nilearn.maskers.NiftiLabelsMasker" title="nilearn.maskers.NiftiLabelsMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code></a>(labels_img[, labels, ...])</p></td>
<td><p>Class for masking of Niimg-like objects.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.maskers.NiftiMapsMasker.html#nilearn.maskers.NiftiMapsMasker" title="nilearn.maskers.NiftiMapsMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a>(maps_img[, mask_img, ...])</p></td>
<td><p>Class for masking of Niimg-like objects.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.maskers.NiftiSpheresMasker.html#nilearn.maskers.NiftiSpheresMasker" title="nilearn.maskers.NiftiSpheresMasker"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a>(seeds[, radius, ...])</p></td>
<td><p>Class for masking of Niimg-like objects using seeds.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.masking">
<span id="nilearn-masking-data-masking-utilities"></span><span id="masking-ref"></span><h2><a class="reference internal" href="#module-nilearn.masking" title="nilearn.masking"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code></a>: Data Masking Utilities<a class="headerlink" href="#module-nilearn.masking" title="Permalink to this headline">#</a></h2>
<p>Utilities to compute and operate on brain masks</p>
<p><strong>User guide:</strong> See the <a class="reference internal" href="../building_blocks/manual_pipeline.html#masking"><span class="std std-ref">Masking the data: from 4D image to 2D array</span></a> section for further details.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_epi_mask.html#nilearn.masking.compute_epi_mask" title="nilearn.masking.compute_epi_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_epi_mask</span></code></a>(epi_img[, lower_cutoff, ...])</p></td>
<td><p>Compute a brain mask from <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> data in 3D or 4D <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.22)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_multi_epi_mask.html#nilearn.masking.compute_multi_epi_mask" title="nilearn.masking.compute_multi_epi_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_multi_epi_mask</span></code></a>(epi_imgs[, ...])</p></td>
<td><p>Compute a common mask for several sessions or subjects of <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_brain_mask.html#nilearn.masking.compute_brain_mask" title="nilearn.masking.compute_brain_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_brain_mask</span></code></a>(target_img[, threshold, ...])</p></td>
<td><p>Compute the whole-brain, grey-matter or white-matter mask.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_multi_brain_mask.html#nilearn.masking.compute_multi_brain_mask" title="nilearn.masking.compute_multi_brain_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_multi_brain_mask</span></code></a>(target_imgs[, ...])</p></td>
<td><p>Compute the whole-brain, grey-matter or white-matter mask for a list of images.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_background_mask.html#nilearn.masking.compute_background_mask" title="nilearn.masking.compute_background_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_background_mask</span></code></a>(data_imgs[, ...])</p></td>
<td><p>Compute a brain mask for the images by guessing the value of the background from the border of the image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.masking.compute_multi_background_mask.html#nilearn.masking.compute_multi_background_mask" title="nilearn.masking.compute_multi_background_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_multi_background_mask</span></code></a>(data_imgs[, ...])</p></td>
<td><p>Compute a common mask for several sessions or subjects of data.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.masking.intersect_masks.html#nilearn.masking.intersect_masks" title="nilearn.masking.intersect_masks"><code class="xref py py-obj docutils literal notranslate"><span class="pre">intersect_masks</span></code></a>(mask_imgs[, threshold, ...])</p></td>
<td><p>Compute intersection of several masks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.masking.apply_mask.html#nilearn.masking.apply_mask" title="nilearn.masking.apply_mask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply_mask</span></code></a>(imgs, mask_img[, dtype, ...])</p></td>
<td><p>Extract signals from images using specified mask.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.masking.unmask.html#nilearn.masking.unmask" title="nilearn.masking.unmask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">unmask</span></code></a>(X, mask_img[, order])</p></td>
<td><p>Take masked data and bring them back into 3D/4D.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.regions">
<span id="nilearn-regions-operating-on-regions"></span><h2><a class="reference internal" href="regions.html#module-nilearn.regions" title="nilearn.regions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code></a>: Operating on Regions<a class="headerlink" href="#module-nilearn.regions" title="Permalink to this headline">#</a></h2>
<p>The <a class="reference internal" href="regions.html#module-nilearn.regions" title="nilearn.regions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code></a> class module includes region extraction
procedure on a 4D statistical/atlas maps and its function.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.regions.connected_regions.html#nilearn.regions.connected_regions" title="nilearn.regions.connected_regions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">connected_regions</span></code></a>(maps_img[, ...])</p></td>
<td><p>Extraction of brain connected regions into separate regions.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.regions.connected_label_regions.html#nilearn.regions.connected_label_regions" title="nilearn.regions.connected_label_regions"><code class="xref py py-obj docutils literal notranslate"><span class="pre">connected_label_regions</span></code></a>(labels_img[, ...])</p></td>
<td><p>Extract connected regions from a brain atlas image defined by labels (integers).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.regions.img_to_signals_labels.html#nilearn.regions.img_to_signals_labels" title="nilearn.regions.img_to_signals_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">img_to_signals_labels</span></code></a>(imgs, labels_img[, ...])</p></td>
<td><p>Extract region signals from image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.regions.signals_to_img_labels.html#nilearn.regions.signals_to_img_labels" title="nilearn.regions.signals_to_img_labels"><code class="xref py py-obj docutils literal notranslate"><span class="pre">signals_to_img_labels</span></code></a>(signals, labels_img[, ...])</p></td>
<td><p>Create image from region signals defined as labels.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.regions.img_to_signals_maps.html#nilearn.regions.img_to_signals_maps" title="nilearn.regions.img_to_signals_maps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">img_to_signals_maps</span></code></a>(imgs, maps_img[, mask_img])</p></td>
<td><p>Extract region signals from image.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.regions.signals_to_img_maps.html#nilearn.regions.signals_to_img_maps" title="nilearn.regions.signals_to_img_maps"><code class="xref py py-obj docutils literal notranslate"><span class="pre">signals_to_img_maps</span></code></a>(region_signals, maps_img)</p></td>
<td><p>Create image from region signals defined as maps.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.regions.RegionExtractor.html#nilearn.regions.RegionExtractor" title="nilearn.regions.RegionExtractor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RegionExtractor</span></code></a>(maps_img[, mask_img, ...])</p></td>
<td><p>Class for brain region extraction.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.regions.Parcellations.html#nilearn.regions.Parcellations" title="nilearn.regions.Parcellations"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Parcellations</span></code></a>(method[, n_parcels, ...])</p></td>
<td><p>Learn <a class="reference internal" href="../glossary.html#term-parcellation"><span class="xref std std-term">parcellations</span></a> on <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> images.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.regions.ReNA.html#nilearn.regions.ReNA" title="nilearn.regions.ReNA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ReNA</span></code></a>(mask_img[, n_clusters, scaling, ...])</p></td>
<td><p>Recursive Neighbor Agglomeration (<a class="reference internal" href="../glossary.html#term-ReNA"><span class="xref std std-term">ReNA</span></a>): Recursively merges the pair of clusters according to 1-nearest neighbors criterion.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.mass_univariate">
<span id="nilearn-mass-univariate-mass-univariate-analysis"></span><h2><a class="reference internal" href="#module-nilearn.mass_univariate" title="nilearn.mass_univariate"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code></a>: Mass-Univariate Analysis<a class="headerlink" href="#module-nilearn.mass_univariate" title="Permalink to this headline">#</a></h2>
<p>Defines a Massively Univariate Linear Model estimated with OLS and permutation test</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.mass_univariate.permuted_ols.html#nilearn.mass_univariate.permuted_ols" title="nilearn.mass_univariate.permuted_ols"><code class="xref py py-obj docutils literal notranslate"><span class="pre">permuted_ols</span></code></a>(tested_vars, target_vars[, ...])</p></td>
<td><p>Massively univariate group analysis with permuted OLS.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.plotting">
<span id="nilearn-plotting-plotting-brain-data"></span><span id="plotting-ref"></span><h2><a class="reference internal" href="#module-nilearn.plotting" title="nilearn.plotting"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code></a>: Plotting Brain Data<a class="headerlink" href="#module-nilearn.plotting" title="Permalink to this headline">#</a></h2>
<p>Plotting code for nilearn</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.find_cut_slices.html#nilearn.plotting.find_cut_slices" title="nilearn.plotting.find_cut_slices"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_cut_slices</span></code></a>(img[, direction, n_cuts, ...])</p></td>
<td><p>Find 'good' cross-section slicing positions along a given axis.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.find_xyz_cut_coords.html#nilearn.plotting.find_xyz_cut_coords" title="nilearn.plotting.find_xyz_cut_coords"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_xyz_cut_coords</span></code></a>(img[, mask_img, ...])</p></td>
<td><p>Find the center of the largest activation connected component.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.find_parcellation_cut_coords.html#nilearn.plotting.find_parcellation_cut_coords" title="nilearn.plotting.find_parcellation_cut_coords"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_parcellation_cut_coords</span></code></a>(labels_img[, ...])</p></td>
<td><p>Return coordinates of center of mass of 3D parcellation atlas.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.find_probabilistic_atlas_cut_coords.html#nilearn.plotting.find_probabilistic_atlas_cut_coords" title="nilearn.plotting.find_probabilistic_atlas_cut_coords"><code class="xref py py-obj docutils literal notranslate"><span class="pre">find_probabilistic_atlas_cut_coords</span></code></a>(maps_img)</p></td>
<td><p>Return coordinates of center probabilistic atlas 4D image.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_anat.html#nilearn.plotting.plot_anat" title="nilearn.plotting.plot_anat"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_anat</span></code></a>([anat_img, cut_coords, ...])</p></td>
<td><p>Plot cuts of an anatomical image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_img</span></code></a>(img[, cut_coords, output_file, ...])</p></td>
<td><p>Plot cuts of a given image (by default Frontal, Axial, and Lateral)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_epi.html#nilearn.plotting.plot_epi" title="nilearn.plotting.plot_epi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_epi</span></code></a>([epi_img, cut_coords, output_file, ...])</p></td>
<td><p>Plot cuts of an EPI image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_matrix.html#nilearn.plotting.plot_matrix" title="nilearn.plotting.plot_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_matrix</span></code></a>(mat[, title, labels, figure, ...])</p></td>
<td><p>Plot the given matrix.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_roi.html#nilearn.plotting.plot_roi" title="nilearn.plotting.plot_roi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_roi</span></code></a>(roi_img[, bg_img, cut_coords, ...])</p></td>
<td><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_stat_map.html#nilearn.plotting.plot_stat_map" title="nilearn.plotting.plot_stat_map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_stat_map</span></code></a>(stat_map_img[, bg_img, ...])</p></td>
<td><p>Plot cuts of an ROI/mask image (by default 3 cuts: Frontal, Axial, and Lateral)</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>(stat_map_img[, ...])</p></td>
<td><p>Plot 2d projections of an ROI/mask image (by default 3 projections: Frontal, Axial, and Lateral).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_connectome.html#nilearn.plotting.plot_connectome" title="nilearn.plotting.plot_connectome"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_connectome</span></code></a>(adjacency_matrix, node_coords)</p></td>
<td><p>Plot connectome on top of the brain glass schematics.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_markers.html#nilearn.plotting.plot_markers" title="nilearn.plotting.plot_markers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_markers</span></code></a>(node_values, node_coords[, ...])</p></td>
<td><p>Plot network nodes (markers) on top of the brain glass schematics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_prob_atlas.html#nilearn.plotting.plot_prob_atlas" title="nilearn.plotting.plot_prob_atlas"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_prob_atlas</span></code></a>(maps_img[, bg_img, ...])</p></td>
<td><p>Plot the probabilistic atlases onto the anatomical image by default MNI template</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_carpet.html#nilearn.plotting.plot_carpet" title="nilearn.plotting.plot_carpet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_carpet</span></code></a>(img[, mask_img, mask_labels, ...])</p></td>
<td><p>Plot an image representation of voxel intensities across time.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_surf.html#nilearn.plotting.plot_surf" title="nilearn.plotting.plot_surf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_surf</span></code></a>(surf_mesh[, surf_map, bg_map, ...])</p></td>
<td><p>Plotting of surfaces with optional background and data</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_surf_roi.html#nilearn.plotting.plot_surf_roi" title="nilearn.plotting.plot_surf_roi"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_surf_roi</span></code></a>(surf_mesh, roi_map[, bg_map, ...])</p></td>
<td><p>Plotting ROI on a surface mesh with optional background</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_surf_contours.html#nilearn.plotting.plot_surf_contours" title="nilearn.plotting.plot_surf_contours"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_surf_contours</span></code></a>(surf_mesh, roi_map[, ...])</p></td>
<td><p>Plotting contours of ROIs on a surface, optionally over a statistical map.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_surf_stat_map.html#nilearn.plotting.plot_surf_stat_map" title="nilearn.plotting.plot_surf_stat_map"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_surf_stat_map</span></code></a>(surf_mesh, stat_map[, ...])</p></td>
<td><p>Plotting a stats map on a surface mesh with optional background</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_img_on_surf.html#nilearn.plotting.plot_img_on_surf" title="nilearn.plotting.plot_img_on_surf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_img_on_surf</span></code></a>(stat_map[, surf_mesh, ...])</p></td>
<td><p>Convenience function to plot multiple views of plot_surf_stat_map in a single figure.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_img_comparison.html#nilearn.plotting.plot_img_comparison" title="nilearn.plotting.plot_img_comparison"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_img_comparison</span></code></a>(ref_imgs, src_imgs, masker)</p></td>
<td><p>Creates plots to compare two lists of images and measure correlation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_design_matrix.html#nilearn.plotting.plot_design_matrix" title="nilearn.plotting.plot_design_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_design_matrix</span></code></a>(design_matrix[, rescale, ...])</p></td>
<td><p>Plot a design matrix provided as a DataFrame</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_event.html#nilearn.plotting.plot_event" title="nilearn.plotting.plot_event"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_event</span></code></a>(model_event[, cmap, output_file])</p></td>
<td><p>Creates plot for event visualization.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.plot_contrast_matrix.html#nilearn.plotting.plot_contrast_matrix" title="nilearn.plotting.plot_contrast_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">plot_contrast_matrix</span></code></a>(contrast_def, design_matrix)</p></td>
<td><p>Creates plot for contrast definition.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.view_surf.html#nilearn.plotting.view_surf" title="nilearn.plotting.view_surf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_surf</span></code></a>(surf_mesh[, surf_map, bg_map, ...])</p></td>
<td><p>Insert a surface plot of a surface map into an HTML page.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.view_img_on_surf.html#nilearn.plotting.view_img_on_surf" title="nilearn.plotting.view_img_on_surf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_img_on_surf</span></code></a>(stat_map_img[, surf_mesh, ...])</p></td>
<td><p>Insert a surface plot of a statistical map into an HTML page.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.view_connectome.html#nilearn.plotting.view_connectome" title="nilearn.plotting.view_connectome"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_connectome</span></code></a>(adjacency_matrix, node_coords)</p></td>
<td><p>Insert a 3d plot of a connectome into an HTML page.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.view_markers.html#nilearn.plotting.view_markers" title="nilearn.plotting.view_markers"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_markers</span></code></a>(marker_coords[, marker_color, ...])</p></td>
<td><p>Insert a 3d plot of markers in a brain into an HTML page.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.view_img.html#nilearn.plotting.view_img" title="nilearn.plotting.view_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">view_img</span></code></a>(stat_map_img[, bg_img, cut_coords, ...])</p></td>
<td><p>Interactive html viewer of a statistical map, with optional background.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.show.html#nilearn.plotting.show" title="nilearn.plotting.show"><code class="xref py py-obj docutils literal notranslate"><span class="pre">show</span></code></a>()</p></td>
<td><p>Show all the figures generated by nilearn and/or matplotlib.</p></td>
</tr>
</tbody>
</table></div>
<section id="module-nilearn.plotting.displays">
<span id="nilearn-plotting-displays-interacting-with-figures"></span><h3><a class="reference internal" href="#module-nilearn.plotting.displays" title="nilearn.plotting.displays"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting.displays</span></code></a>: Interacting with figures<a class="headerlink" href="#module-nilearn.plotting.displays" title="Permalink to this headline">#</a></h3>
<p>Display objects and utilities.</p>
<p>These objects are returned by plotting functions
from the <a class="reference internal" href="#module-nilearn.plotting" title="nilearn.plotting"><code class="xref py py-mod docutils literal notranslate"><span class="pre">plotting</span></code></a> module.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.get_projector.html#nilearn.plotting.displays.get_projector" title="nilearn.plotting.displays.get_projector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_projector</span></code></a>(display_mode)</p></td>
<td><p>Retrieve a projector from a given display mode.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.get_slicer.html#nilearn.plotting.displays.get_slicer" title="nilearn.plotting.displays.get_slicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_slicer</span></code></a>(display_mode)</p></td>
<td><p>Retrieve a slicer from a given display mode.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.OrthoProjector.html#nilearn.plotting.displays.OrthoProjector" title="nilearn.plotting.displays.OrthoProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrthoProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>A class to create linked axes for plotting orthogonal projections of 3D maps.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.XZProjector.html#nilearn.plotting.displays.XZProjector" title="nilearn.plotting.displays.XZProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">XZProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">XZProjector</span></code> class enables to combine sagittal and axial views on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YZProjector.html#nilearn.plotting.displays.YZProjector" title="nilearn.plotting.displays.YZProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YZProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YZProjector</span></code> class enables to combine coronal and axial views on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YXProjector.html#nilearn.plotting.displays.YXProjector" title="nilearn.plotting.displays.YXProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YXProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YXProjector</span></code> class enables to combine coronal and sagittal views on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.XProjector.html#nilearn.plotting.displays.XProjector" title="nilearn.plotting.displays.XProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">XProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">XProjector</span></code> class enables sagittal visualization through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YProjector.html#nilearn.plotting.displays.YProjector" title="nilearn.plotting.displays.YProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YProjector</span></code> class enables coronal visualization through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.ZProjector.html#nilearn.plotting.displays.ZProjector" title="nilearn.plotting.displays.ZProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ZProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">ZProjector</span></code> class enables axial visualization through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LZRYProjector.html#nilearn.plotting.displays.LZRYProjector" title="nilearn.plotting.displays.LZRYProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LZRYProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LZRYProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LYRZProjector.html#nilearn.plotting.displays.LYRZProjector" title="nilearn.plotting.displays.LYRZProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LYRZProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LYRZProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LYRProjector.html#nilearn.plotting.displays.LYRProjector" title="nilearn.plotting.displays.LYRProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LYRProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LYRProjector</span></code> class enables ? visualization on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LZRProjector.html#nilearn.plotting.displays.LZRProjector" title="nilearn.plotting.displays.LZRProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LZRProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LZRProjector</span></code> class enables hemispheric sagittal visualization on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LRProjector.html#nilearn.plotting.displays.LRProjector" title="nilearn.plotting.displays.LRProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LRProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LRProjector</span></code> class enables left-right visualization on the same figure through 2D projections with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.LProjector.html#nilearn.plotting.displays.LProjector" title="nilearn.plotting.displays.LProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">LProjector</span></code> class enables the visualization of left 2D projection with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.RProjector.html#nilearn.plotting.displays.RProjector" title="nilearn.plotting.displays.RProjector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RProjector</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">RProjector</span></code> class enables the visualization of right 2D projection with <a class="reference internal" href="generated/nilearn.plotting.plot_glass_brain.html#nilearn.plotting.plot_glass_brain" title="nilearn.plotting.plot_glass_brain"><code class="xref py py-func docutils literal notranslate"><span class="pre">plot_glass_brain</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.BaseAxes.html#nilearn.plotting.displays.BaseAxes" title="nilearn.plotting.displays.BaseAxes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseAxes</span></code></a>(ax, direction, coord)</p></td>
<td><p>An MPL axis-like object that displays a 2D view of 3D volumes.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.CutAxes.html#nilearn.plotting.displays.CutAxes" title="nilearn.plotting.displays.CutAxes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CutAxes</span></code></a>(ax, direction, coord)</p></td>
<td><p>An MPL axis-like object that displays a cut of 3D volumes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.GlassBrainAxes.html#nilearn.plotting.displays.GlassBrainAxes" title="nilearn.plotting.displays.GlassBrainAxes"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GlassBrainAxes</span></code></a>(ax, direction, coord[, plot_abs])</p></td>
<td><p>An MPL axis-like object that displays a 2D projection of 3D volumes with a schematic view of the brain.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.BaseSlicer.html#nilearn.plotting.displays.BaseSlicer" title="nilearn.plotting.displays.BaseSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BaseSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>BaseSlicer implementation which main purpose is to auto adjust the axes size to the data with different layout of cuts.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.OrthoSlicer.html#nilearn.plotting.displays.OrthoSlicer" title="nilearn.plotting.displays.OrthoSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OrthoSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>A class to create 3 linked axes for plotting orthogonal cuts of 3D maps.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.PlotlySurfaceFigure.html#nilearn.plotting.displays.PlotlySurfaceFigure" title="nilearn.plotting.displays.PlotlySurfaceFigure"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PlotlySurfaceFigure</span></code></a>([figure, output_file])</p></td>
<td><p>Implementation of a surface figure obtained with <cite>plotly</cite> engine.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.TiledSlicer.html#nilearn.plotting.displays.TiledSlicer" title="nilearn.plotting.displays.TiledSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TiledSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>A class to create 3 axes for plotting orthogonal cuts of 3D maps, organized in a 2x2 grid.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.MosaicSlicer.html#nilearn.plotting.displays.MosaicSlicer" title="nilearn.plotting.displays.MosaicSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MosaicSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>A class to create 3 <a class="reference external" href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes" title="(in Matplotlib v3.5.1)"><code class="xref py py-class docutils literal notranslate"><span class="pre">Axes</span></code></a> for plotting cuts of 3D maps, in multiple rows and columns.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.XZSlicer.html#nilearn.plotting.displays.XZSlicer" title="nilearn.plotting.displays.XZSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">XZSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">XZSlicer</span></code> class enables to combine sagittal and axial views on the same figure with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YZSlicer.html#nilearn.plotting.displays.YZSlicer" title="nilearn.plotting.displays.YZSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YZSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YZSlicer</span></code> class enables to combine coronal and axial views on the same figure with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YXSlicer.html#nilearn.plotting.displays.YXSlicer" title="nilearn.plotting.displays.YXSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YXSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YXSlicer</span></code> class enables to combine coronal and sagittal views on the same figure with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.XSlicer.html#nilearn.plotting.displays.XSlicer" title="nilearn.plotting.displays.XSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">XSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">XSlicer</span></code> class enables sagittal visualization with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.YSlicer.html#nilearn.plotting.displays.YSlicer" title="nilearn.plotting.displays.YSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">YSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">YSlicer</span></code> class enables coronal visualization with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.plotting.displays.ZSlicer.html#nilearn.plotting.displays.ZSlicer" title="nilearn.plotting.displays.ZSlicer"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ZSlicer</span></code></a>(cut_coords[, axes, black_bg, ...])</p></td>
<td><p>The <code class="docutils literal notranslate"><span class="pre">ZSlicer</span></code> class enables axial visualization with plotting functions of Nilearn like <a class="reference internal" href="generated/nilearn.plotting.plot_img.html#nilearn.plotting.plot_img" title="nilearn.plotting.plot_img"><code class="xref py py-func docutils literal notranslate"><span class="pre">nilearn.plotting.plot_img</span></code></a>.</p></td>
</tr>
</tbody>
</table></div>
</section>
</section>
<section id="module-nilearn.signal">
<span id="nilearn-signal-preprocessing-time-series"></span><span id="signal-ref"></span><h2><a class="reference internal" href="signal.html#module-nilearn.signal" title="nilearn.signal"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code></a>: Preprocessing Time Series<a class="headerlink" href="#module-nilearn.signal" title="Permalink to this headline">#</a></h2>
<p>Preprocessing functions for time series.</p>
<p>All functions in this module should take X matrices with samples x
features</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.signal.butterworth.html#nilearn.signal.butterworth" title="nilearn.signal.butterworth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">butterworth</span></code></a>(signals, sampling_rate[, ...])</p></td>
<td><p>Apply a low-pass, high-pass or band-pass <a class="reference external" href="https://en.wikipedia.org/wiki/Butterworth_filter">Butterworth filter</a>.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.signal.clean.html#nilearn.signal.clean" title="nilearn.signal.clean"><code class="xref py py-obj docutils literal notranslate"><span class="pre">clean</span></code></a>(signals[, runs, detrend, standardize, ...])</p></td>
<td><p>Improve <a class="reference internal" href="../glossary.html#term-SNR"><span class="xref std std-term">SNR</span></a> on masked <a class="reference internal" href="../glossary.html#term-fMRI"><span class="xref std std-term">fMRI</span></a> signals.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.signal.high_variance_confounds.html#nilearn.signal.high_variance_confounds" title="nilearn.signal.high_variance_confounds"><code class="xref py py-obj docutils literal notranslate"><span class="pre">high_variance_confounds</span></code></a>(series[, ...])</p></td>
<td><p>Return confounds time series extracted from series with highest variance.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.glm">
<span id="nilearn-glm-generalized-linear-models"></span><span id="stats-ref"></span><h2><a class="reference internal" href="#module-nilearn.glm" title="nilearn.glm"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code></a>: Generalized Linear Models<a class="headerlink" href="#module-nilearn.glm" title="Permalink to this headline">#</a></h2>
<p>Analysing fMRI data using GLMs.</p>
<dl class="simple">
<dt>Note that the nilearn.glm module is experimental.</dt><dd><p>It may change in any future (&gt;0.7.0) release of Nilearn.</p>
</dd>
</dl>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.Contrast.html#nilearn.glm.Contrast" title="nilearn.glm.Contrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Contrast</span></code></a>(effect, variance[, dim, dof, ...])</p></td>
<td><p>The contrast class handles the estimation of statistical contrasts on a given model: student (t) or Fisher (F).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.FContrastResults.html#nilearn.glm.FContrastResults" title="nilearn.glm.FContrastResults"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FContrastResults</span></code></a>(effect, covariance, F, df_num)</p></td>
<td><p>Results from an F contrast of coefficients in a parametric model.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.TContrastResults.html#nilearn.glm.TContrastResults" title="nilearn.glm.TContrastResults"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TContrastResults</span></code></a>(t, sd, effect[, df_den])</p></td>
<td><p>Results from a t contrast of coefficients in a parametric model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.ARModel.html#nilearn.glm.ARModel" title="nilearn.glm.ARModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ARModel</span></code></a>(design, rho)</p></td>
<td><p>A regression model with an AR(p) covariance structure.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.OLSModel.html#nilearn.glm.OLSModel" title="nilearn.glm.OLSModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OLSModel</span></code></a>(design)</p></td>
<td><p>A simple ordinary least squares model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.LikelihoodModelResults.html#nilearn.glm.LikelihoodModelResults" title="nilearn.glm.LikelihoodModelResults"><code class="xref py py-obj docutils literal notranslate"><span class="pre">LikelihoodModelResults</span></code></a>(theta, Y, model[, ...])</p></td>
<td><p>Class to contain results from likelihood models.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.RegressionResults.html#nilearn.glm.RegressionResults" title="nilearn.glm.RegressionResults"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RegressionResults</span></code></a>(theta, Y, model, ...[, ...])</p></td>
<td><p>This class summarizes the fit of a linear regression model.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.SimpleRegressionResults.html#nilearn.glm.SimpleRegressionResults" title="nilearn.glm.SimpleRegressionResults"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SimpleRegressionResults</span></code></a>(results)</p></td>
<td><p>This class contains only information of the model fit necessary for contrast computation.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.compute_contrast.html#nilearn.glm.compute_contrast" title="nilearn.glm.compute_contrast"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_contrast</span></code></a>(labels, regression_result, ...)</p></td>
<td><p>Compute the specified contrast given an estimated glm</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.compute_fixed_effects.html#nilearn.glm.compute_fixed_effects" title="nilearn.glm.compute_fixed_effects"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_fixed_effects</span></code></a>(contrast_imgs, ...[, ...])</p></td>
<td><p>Compute the fixed effects, given images of effects and variance</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.expression_to_contrast_vector.html#nilearn.glm.expression_to_contrast_vector" title="nilearn.glm.expression_to_contrast_vector"><code class="xref py py-obj docutils literal notranslate"><span class="pre">expression_to_contrast_vector</span></code></a>(expression, ...)</p></td>
<td><p>Converts a string describing a contrast to a contrast vector</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.fdr_threshold.html#nilearn.glm.fdr_threshold" title="nilearn.glm.fdr_threshold"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fdr_threshold</span></code></a>(z_vals, alpha)</p></td>
<td><p>Return the Benjamini-Hochberg FDR threshold for the input z_vals</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.cluster_level_inference.html#nilearn.glm.cluster_level_inference" title="nilearn.glm.cluster_level_inference"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cluster_level_inference</span></code></a>(stat_img[, ...])</p></td>
<td><p>Report the proportion of active voxels for all clusters defined by the input threshold.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img" title="nilearn.glm.threshold_stats_img"><code class="xref py py-obj docutils literal notranslate"><span class="pre">threshold_stats_img</span></code></a>([stat_img, mask_img, ...])</p></td>
<td><p>Compute the required threshold level and return the thresholded map</p></td>
</tr>
</tbody>
</table></div>
<section id="module-nilearn.glm.first_level">
<span id="nilearn-glm-first-level"></span><h3><a class="reference internal" href="#module-nilearn.glm.first_level" title="nilearn.glm.first_level"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.first_level</span></code></a><a class="headerlink" href="#module-nilearn.glm.first_level" title="Permalink to this headline">#</a></h3>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.FirstLevelModel.html#nilearn.glm.first_level.FirstLevelModel" title="nilearn.glm.first_level.FirstLevelModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FirstLevelModel</span></code></a>([t_r, slice_time_ref, ...])</p></td>
<td><p>Implementation of the General Linear Model for single session fMRI data.</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.check_design_matrix.html#nilearn.glm.first_level.check_design_matrix" title="nilearn.glm.first_level.check_design_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">check_design_matrix</span></code></a>(design_matrix)</p></td>
<td><p>Check that the provided DataFrame is indeed a valid design matrix descriptor, and returns a triplet of fields</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.compute_regressor.html#nilearn.glm.first_level.compute_regressor" title="nilearn.glm.first_level.compute_regressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_regressor</span></code></a>(exp_condition, hrf_model, ...)</p></td>
<td><p>This is the main function to convolve regressors with hrf model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.first_level_from_bids.html#nilearn.glm.first_level.first_level_from_bids" title="nilearn.glm.first_level.first_level_from_bids"><code class="xref py py-obj docutils literal notranslate"><span class="pre">first_level_from_bids</span></code></a>(dataset_path, task_label)</p></td>
<td><p>Create FirstLevelModel objects and fit arguments from a BIDS dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.glover_dispersion_derivative.html#nilearn.glm.first_level.glover_dispersion_derivative" title="nilearn.glm.first_level.glover_dispersion_derivative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">glover_dispersion_derivative</span></code></a>(tr[, ...])</p></td>
<td><p>Implementation of the Glover dispersion derivative hrf model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.glover_hrf.html#nilearn.glm.first_level.glover_hrf" title="nilearn.glm.first_level.glover_hrf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">glover_hrf</span></code></a>(tr[, oversampling, time_length, ...])</p></td>
<td><p>Implementation of the Glover hrf model</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.glover_time_derivative.html#nilearn.glm.first_level.glover_time_derivative" title="nilearn.glm.first_level.glover_time_derivative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">glover_time_derivative</span></code></a>(tr[, oversampling, ...])</p></td>
<td><p>Implementation of the Glover time derivative hrf (dhrf) model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.make_first_level_design_matrix.html#nilearn.glm.first_level.make_first_level_design_matrix" title="nilearn.glm.first_level.make_first_level_design_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_first_level_design_matrix</span></code></a>(frame_times)</p></td>
<td><p>Generate a design matrix from the input parameters</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.mean_scaling.html#nilearn.glm.first_level.mean_scaling" title="nilearn.glm.first_level.mean_scaling"><code class="xref py py-obj docutils literal notranslate"><span class="pre">mean_scaling</span></code></a>(Y[, axis])</p></td>
<td><p>Scaling of the data to have percent of baseline change along the specified axis</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.run_glm.html#nilearn.glm.first_level.run_glm" title="nilearn.glm.first_level.run_glm"><code class="xref py py-obj docutils literal notranslate"><span class="pre">run_glm</span></code></a>(Y, X[, noise_model, bins, n_jobs, ...])</p></td>
<td><p>GLM fit for an fMRI data matrix</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.spm_dispersion_derivative.html#nilearn.glm.first_level.spm_dispersion_derivative" title="nilearn.glm.first_level.spm_dispersion_derivative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spm_dispersion_derivative</span></code></a>(tr[, ...])</p></td>
<td><p>Implementation of the SPM dispersion derivative hrf model</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.spm_hrf.html#nilearn.glm.first_level.spm_hrf" title="nilearn.glm.first_level.spm_hrf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spm_hrf</span></code></a>(tr[, oversampling, time_length, onset])</p></td>
<td><p>Implementation of the SPM hrf model</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.first_level.spm_time_derivative.html#nilearn.glm.first_level.spm_time_derivative" title="nilearn.glm.first_level.spm_time_derivative"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spm_time_derivative</span></code></a>(tr[, oversampling, ...])</p></td>
<td><p>Implementation of the SPM time derivative hrf (dhrf) model</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.glm.second_level">
<span id="nilearn-glm-second-level"></span><h3><a class="reference internal" href="#module-nilearn.glm.second_level" title="nilearn.glm.second_level"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.second_level</span></code></a><a class="headerlink" href="#module-nilearn.glm.second_level" title="Permalink to this headline">#</a></h3>
<p><strong>Classes</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.second_level.SecondLevelModel.html#nilearn.glm.second_level.SecondLevelModel" title="nilearn.glm.second_level.SecondLevelModel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SecondLevelModel</span></code></a>([mask_img, target_affine, ...])</p></td>
<td><p>Implementation of the General Linear Model for multiple subject fMRI data</p></td>
</tr>
</tbody>
</table></div>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.glm.second_level.make_second_level_design_matrix.html#nilearn.glm.second_level.make_second_level_design_matrix" title="nilearn.glm.second_level.make_second_level_design_matrix"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_second_level_design_matrix</span></code></a>(subjects_label)</p></td>
<td><p>Sets up a second level design.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.glm.second_level.non_parametric_inference.html#nilearn.glm.second_level.non_parametric_inference" title="nilearn.glm.second_level.non_parametric_inference"><code class="xref py py-obj docutils literal notranslate"><span class="pre">non_parametric_inference</span></code></a>(second_level_input)</p></td>
<td><p>Generate p-values corresponding to the contrasts provided based on permutation testing.</p></td>
</tr>
</tbody>
</table></div>
</section>
</section>
<section id="module-nilearn.reporting">
<span id="nilearn-reporting-reporting-functions"></span><span id="reporting-ref"></span><h2><a class="reference internal" href="reporting.html#module-nilearn.reporting" title="nilearn.reporting"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code></a>: Reporting Functions<a class="headerlink" href="#module-nilearn.reporting" title="Permalink to this headline">#</a></h2>
<p>Reporting code for nilearn</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.reporting.get_clusters_table.html#nilearn.reporting.get_clusters_table" title="nilearn.reporting.get_clusters_table"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_clusters_table</span></code></a>(stat_img, stat_threshold)</p></td>
<td><p>Creates pandas dataframe with img cluster statistics.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.reporting.make_glm_report.html#nilearn.reporting.make_glm_report" title="nilearn.reporting.make_glm_report"><code class="xref py py-obj docutils literal notranslate"><span class="pre">make_glm_report</span></code></a>(model, contrasts[, title, ...])</p></td>
<td><p>Returns HTMLReport object for a report which shows all important aspects of a fitted GLM.</p></td>
</tr>
</tbody>
</table></div>
</section>
<section id="module-nilearn.surface">
<span id="nilearn-surface-manipulating-surface-data"></span><h2><a class="reference internal" href="surface.html#module-nilearn.surface" title="nilearn.surface"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code></a>: Manipulating Surface Data<a class="headerlink" href="#module-nilearn.surface" title="Permalink to this headline">#</a></h2>
<p>Functions for surface manipulation.</p>
<p><strong>Functions</strong>:</p>
<div class="table-wrapper"><table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%"/>
<col style="width: 90%"/>
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.surface.load_surf_data.html#nilearn.surface.load_surf_data" title="nilearn.surface.load_surf_data"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_surf_data</span></code></a>(surf_data)</p></td>
<td><p>Loading data to be represented on a surface mesh.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/nilearn.surface.load_surf_mesh.html#nilearn.surface.load_surf_mesh" title="nilearn.surface.load_surf_mesh"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_surf_mesh</span></code></a>(surf_mesh)</p></td>
<td><p>Loading a surface mesh geometry</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/nilearn.surface.vol_to_surf.html#nilearn.surface.vol_to_surf" title="nilearn.surface.vol_to_surf"><code class="xref py py-obj docutils literal notranslate"><span class="pre">vol_to_surf</span></code></a>(img, surf_mesh[, radius, ...])</p></td>
<td><p>Extract surface data from a Nifti image.</p></td>
</tr>
</tbody>
</table></div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers 2010-2021
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">API References</a><ul>
<li><a class="reference internal" href="#module-nilearn.connectome"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.datasets"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a></li>
<li><a class="reference internal" href="#module-nilearn.decoding"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a></li>
<li><a class="reference internal" href="#module-nilearn.decomposition"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a></li>
<li><a class="reference internal" href="#module-nilearn.image"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a></li>
<li><a class="reference internal" href="#module-nilearn.interfaces"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><ul>
<li><a class="reference internal" href="#module-nilearn.interfaces.fmriprep"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.fmriprep</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.maskers"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a></li>
<li><a class="reference internal" href="#module-nilearn.masking"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a></li>
<li><a class="reference internal" href="#module-nilearn.regions"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.mass_univariate"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a></li>
<li><a class="reference internal" href="#module-nilearn.plotting"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><ul>
<li><a class="reference internal" href="#module-nilearn.plotting.displays"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting.displays</span></code>: Interacting with figures</a><ul>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.signal"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a></li>
<li><a class="reference internal" href="#module-nilearn.glm"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><ul>
<li><a class="reference internal" href="#module-nilearn.glm.first_level"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.first_level</span></code></a><ul>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.glm.second_level"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.second_level</span></code></a><ul>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#module-nilearn.reporting"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a></li>
<li><a class="reference internal" href="#module-nilearn.surface"><code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/design-tabs.js"></script>
    </body>
</html>