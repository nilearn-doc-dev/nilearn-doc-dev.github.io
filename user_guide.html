<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="User guide: table of contents" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://nilearn.github.io/user_guide.html" />
  
<meta property="og:site_name" content="Nilearn" />
  
<meta property="og:description" content="Download for offline viewing: Download the user guide and examples. Introduction: nilearn in a nutshell- What is nilearn: MVPA, decoding, predictive models, functional connectivity- Why is machine ..." />
  
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
  
<meta property="og:image:alt" content="Nilearn" />
  <link rel="search" title="Search" href="search.html" /><link rel="next" title="1. Introduction: nilearn in a nutshell" href="introduction.html" /><link rel="prev" title="People" href="authors.html" />

    <link rel="shortcut icon" href="_static/favicon.ico"/><meta name="generator" content="sphinx-4.4.0, furo 2022.03.04"/>
        <title>User guide: table of contents - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=935aa2abcc5c1da4283d1dc201fb1f0add16d23a" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
      }
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="nistats_migration.html">A Quick Guide to Migrating Nistats Code to Nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html">People</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html#citing-nilearn">Citing nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="authors.html#citing-scikit-learn">Citing scikit-learn</a></li>
<li class="toctree-l1 current has-children current-page"><a class="current reference internal" href="#">User guide: table of contents</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html">1. Introduction: nilearn in a nutshell</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_intro.html">2.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html">2.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/frem.html">2.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/space_net.html">2.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html">2.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/going_further.html">2.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="connectivity/index.html">3. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="developers/group_sparse_covariance.html">3.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html">3.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html">3.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html">3.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html">4. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="glm/index.html">5. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="glm/glm_intro.html">5.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html">5.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html">5.3. Second level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="manipulating_images/index.html">6. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/input_output.html">6.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html">6.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html">6.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="building_blocks/index.html">7. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html">7.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html">7.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html">8. Reference documentation: all nilearn functions</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/index.html">9. Examples</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="auto_examples/07_advanced/index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_examples/07_advanced/plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="auto_examples/index.html">9. Examples</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="auto_examples/07_advanced/index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/07_advanced/plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#dev">0.9.1.dev</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id100">0.9.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id204">0.8.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id309">0.8.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id414">0.7.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id518">0.7.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id623">0.6.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id726">0.6.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id829">0.6.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#rc">0.6.0rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#b0">0.6.0b0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#a0">0.6.0a0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id948">0.5.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1051">0.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1155">0.5.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1159">0.5.0 rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#beta">0.5.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#alpha">0.5.0 alpha</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1272">0.4.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1374">0.4.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1476">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1581">0.3.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1685">0.3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1689">0.3.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1793">0.2.6</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1896">0.2.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id1900">0.2.5</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2002">0.2.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2104">0.2.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2205">0.2.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#v0-2-1">0.2.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2312">0.2.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2417">0.1.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2518">0.1.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2620">0.1.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2721">0.1.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes/whats_new.html#id2822">0.1.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="development.html">Nilearn development process</a></li>
<li class="toctree-l1"><a class="reference internal" href="maintenance.html">Nilearn maintenance process</a></li>
<li class="toctree-l1"><a class="reference internal" href="glossary.html">Glossary</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="user-guide-table-of-contents">
<span id="user-guide"></span><h1>User guide: table of contents<a class="headerlink" href="#user-guide-table-of-contents" title="Permalink to this headline">#</a></h1>
<aside class="sidebar">
<p class="sidebar-title"><strong>Download for offline viewing</strong></p>
<p>Download the <a class="reference external" href="https://github.com/nilearn/nilearn.github.io/archive/master.zip">user guide and examples</a>.</p>
</aside>
<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin-top: 0 ;
      margin-bottom: 0 ;
      padding-left: 10px ;
  }

  li.toctree-l1 {
      padding: 0 0 0.5em 0 ;
      list-style-type: none;
      font-size: 150% ;
      font-weight: bold;
      }

  li.toctree-l1 ul {
      padding-left: 40px ;
  }

  li.toctree-l2 {
      font-size: 75% ;
      list-style-type: square;
      font-weight: normal;
      }

  li.toctree-l3 {
      font-size: 85% ;
      list-style-type: circle;
      font-weight: normal;
      }

</style> <script>
 //Function to make the index toctree collapsible
 $(function () {
     $('.toctree-l2')
         .click(function(event){
             if (event.target.tagName.toLowerCase() != "a") {
                 if ($(this).children('ul').length > 0) {
                      $(this).attr('data-content',
                          (!$(this).children('ul').is(':hidden')) ? '\u25ba' : '\u25bc');
                     $(this).children('ul').toggle();
                 }
                 return true; //Makes links clickable
             }
         })
         .mousedown(function(event){ return false; }) //Firefox highlighting fix
         .children('ul').hide();
     // Initialize the values
     $('li.toctree-l2:not(:has(ul))').attr('data-content', '-');
     $('li.toctree-l2:has(ul)').attr('data-content', '\u25ba');
     $('li.toctree-l2:has(ul)').css('cursor', 'pointer');

     $('.toctree-l2').hover(
         function () {
             if ($(this).children('ul').length > 0) {
                 $(this).css('background-color', '#D0D0D0').children('ul').css('background-color', '#F0F0F0');
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
             else {
                 $(this).css('background-color', '#F9F9F9');
             }
         },
         function () {
             $(this).css('background-color', 'white').children('ul').css('background-color', 'white');
             if ($(this).children('ul').length > 0) {
                 $(this).attr('data-content',
                     (!$(this).children('ul').is(':hidden')) ? '\u25bc' : '\u25ba');
             }
         }
     );
 });

 </script>
<style type="text/css">
  div.bodywrapper blockquote {
      margin: 0 ;
  }

  div.toctree-wrapper ul {
      margin: 0 ;
      padding-left: 0px ;
  }

  li, ul {
      transition-duration: 0.2s;
  }

  li.toctree-l1 {
      padding: 5px 0 0;
      list-style-type: none;
      font-size: 150% ;
      font-family: Arial, sans-serif;
      background-color: #f2f2f2;
      font-weight: normal;
      color: #20435c;
      margin-left: 0;
      margin-bottom: 1.2em;
      font-weight: bold;
      }

  li.toctree-l1 a {
      padding: 0 0 0 10px ;
      color: #314F64 ;
  }

  li.toctree-l2 {
      padding: 0.25em 0 0.25em 0 ;
      list-style-type: none;
      background-color: #FFFFFF;
      font-size: 85% ;
      font-weight: normal;
  }

  li.toctree-l2 ul {
      padding-left: 40px ;
  }


  li.toctree-l2:before {
      content: attr(data-content) ;
      font-size: 85% ;
      color: #777 ;
      display: inline-block;
      width: 10px;
  }

  li.toctree-l3 {
      font-size: 88% ;
      list-style-type: square;
      font-weight: normal;
  }

  li.toctree-l4 {
      font-size: 93% ;
      list-style-type: circle;
      font-weight: normal;
  }

  div.topic li.toctree-l1 {
      font-size: 100% ;
      font-weight: bold;
      background-color: transparent;
      margin-bottom: 0;
      margin-left: 1.5em;
      display:inline;
  }

  div.topic p {
      font-size: 90% ;
      margin: 0.4ex;
  }

  div.topic p.topic-title {
      display:inline;
      font-size: 100% ;
      margin-bottom: 0;
  }

  div.sidebar {
      width: 25ex ;
  }

</style><div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="introduction.html">1. Introduction: nilearn in a nutshell</a><ul>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#what-is-nilearn-mvpa-decoding-predictive-models-functional-connectivity">1.1. What is nilearn: MVPA, decoding, predictive models, functional connectivity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#why-is-machine-learning-relevant-to-neuroimaging-a-few-examples">1.1.1. Why is machine learning relevant to NeuroImaging? A few examples!</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#installing-nilearn">1.2. Installing nilearn</a></li>
<li class="toctree-l2"><a class="reference internal" href="introduction.html#python-for-neuroimaging-a-quick-start">1.3. Python for NeuroImaging, a quick start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#your-first-steps-with-nilearn">1.3.1. Your first steps with nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#scientific-computing-with-python">1.3.2. Scientific computing with Python</a><ul>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#basic-numerics">1.3.2.1. Basic numerics</a></li>
<li class="toctree-l4"><a class="reference internal" href="introduction.html#scikit-learn-machine-learning-in-python">1.3.2.2. Scikit-learn: machine learning in Python</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="introduction.html#finding-help">1.3.3. Finding help</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="decoding/decoding_intro.html">2.1. An introduction to decoding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_intro.html#loading-and-preparing-the-data">2.1.1. Loading and preparing the data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#the-haxby-2001-experiment">2.1.1.1. The Haxby 2001 experiment</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#loading-the-data-into-nilearn">2.1.1.2. Loading the data into nilearn</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_intro.html#performing-a-simple-decoding-analysis">2.1.2. Performing a simple decoding analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#a-few-definitions">2.1.2.1. A few definitions</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#a-first-estimator">2.1.2.2. A first estimator</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#decoding-made-easy">2.1.2.3. Decoding made easy</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#measuring-prediction-performance">2.1.2.4. Measuring prediction performance</a><ul>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_intro.html#cross-validation">2.1.2.4.1. Cross-validation</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_intro.html#choosing-a-good-cross-validation-strategy">2.1.2.4.2. Choosing a good cross-validation strategy</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_intro.html#choice-of-the-prediction-accuracy-measure">2.1.2.4.3. Choice of the prediction accuracy measure</a></li>
<li class="toctree-l5"><a class="reference internal" href="decoding/decoding_intro.html#prediction-accuracy-at-chance-using-simple-strategies">2.1.2.4.4. Prediction accuracy at chance using simple strategies</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#visualizing-the-decoder-s-weights">2.1.2.5. Visualizing the decoder’s weights</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/decoding_intro.html#decoding-without-a-mask-anova-svm">2.1.3. Decoding without a mask: Anova-SVM</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#dimension-reduction-with-feature-selection">2.1.3.1. Dimension reduction with feature selection</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/decoding_intro.html#visualizing-the-results">2.1.3.2. Visualizing the results</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/estimator_choice.html">2.2. Choosing the right predictive model for neuroimaging</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#predictions-regression-classification-and-multi-class">2.2.1. Predictions: regression, classification and multi-class</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/estimator_choice.html#regression">2.2.1.1. Regression</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/estimator_choice.html#classification-two-classes-or-multi-class">2.2.1.2. Classification: two classes or multi-class</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#different-linear-models">2.2.2. Different linear models</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#setting-estimator-parameters">2.2.3. Setting estimator parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#bagging-several-models">2.2.4. Bagging several models</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/estimator_choice.html#references">2.2.5. References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/frem.html">2.3. FREM: fast ensembling of regularized models for robust decoding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/frem.html#frem-pipeline">2.3.1. FREM pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/frem.html#empirical-comparisons">2.3.2. Empirical comparisons</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/frem.html#decoding-performance-increase-on-haxby-dataset">2.3.2.1. Decoding performance increase on Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/frem.html#spatial-regularization-of-decoding-maps-on-mixed-gambles-study">2.3.2.2. Spatial regularization of decoding maps on mixed gambles study</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/frem.html#references">2.3.3. References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/space_net.html">2.4. SpaceNet: decoding with spatial structure for better maps</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/space_net.html#the-spacenet-decoder">2.4.1. The SpaceNet decoder</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/space_net.html#related-example">2.4.2. Related example</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/space_net.html#references">2.4.3. References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/searchlight.html">2.5. Searchlight : finding voxels containing information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#principle-of-the-searchlight">2.5.1. Principle of the Searchlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#preparing-the-data">2.5.2. Preparing the data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#masking">2.5.2.1. Masking</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#setting-up-the-searchlight">2.5.3. Setting up the searchlight</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#classifier">2.5.3.1. Classifier</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#score-function">2.5.3.2. Score function</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#cross-validation">2.5.3.3. Cross validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#sphere-radius">2.5.3.4. Sphere radius</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#visualization">2.5.4. Visualization</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#id6">2.5.4.1. Searchlight</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/searchlight.html#comparing-to-massively-univariate-analysis-f-score-or-spm">2.5.4.2. Comparing to massively univariate analysis: F_score or SPM</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/searchlight.html#references">2.5.5. References</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="decoding/going_further.html">2.6. Running scikit-learn functions for more control on the analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="decoding/going_further.html#performing-decoding-with-scikit-learn">2.6.1. Performing decoding with scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/going_further.html#using-scikit-learn-estimators">2.6.1.1. Using scikit-learn estimators</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/going_further.html#cross-validation-with-scikit-learn">2.6.1.2. Cross-validation with scikit-learn</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/going_further.html#measuring-the-chance-level">2.6.1.3. Measuring the chance level</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/going_further.html#going-further-with-scikit-learn">2.6.2. Going further with scikit-learn</a><ul>
<li class="toctree-l4"><a class="reference internal" href="decoding/going_further.html#decoding-without-a-mask-anova-svm-using-scikit-learn">2.6.2.1. Decoding without a mask: Anova-SVM using scikit-learn</a></li>
<li class="toctree-l4"><a class="reference internal" href="decoding/going_further.html#using-any-other-model-in-the-pipeline">2.6.2.2. Using any other model in the pipeline</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="decoding/going_further.html#setting-estimator-parameters">2.6.3. Setting estimator parameters</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="connectivity/index.html">3. Functional connectivity and resting state</a><ul>
<li class="toctree-l2"><a class="reference internal" href="connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#time-series-from-a-brain-parcellation-or-maxprob-atlas">3.1.1. Time-series from a brain parcellation or “MaxProb” atlas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#brain-parcellations">3.1.1.1. Brain parcellations</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#extracting-signals-on-a-parcellation">3.1.1.2. Extracting signals on a parcellation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#time-series-from-a-probabilistic-atlas">3.1.2. Time-series from a probabilistic atlas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#probabilistic-atlases">3.1.2.1. Probabilistic atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/functional_connectomes.html#extracting-signals-from-a-probabilistic-atlas">3.1.2.2. Extracting signals from a probabilistic atlas</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#a-functional-connectome-a-graph-of-interactions">3.1.3. A functional connectome: a graph of interactions</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/functional_connectomes.html#a-functional-connectome-extracting-coordinates-of-regions">3.1.4. A functional connectome: extracting coordinates of regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#sparse-inverse-covariance-for-functional-connectomes">3.2.1. Sparse inverse covariance for functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#sparse-inverse-covariance-on-multiple-subjects">3.2.2. Sparse inverse covariance on multiple subjects</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#comparing-the-different-approaches-on-simulated-data">3.2.3. Comparing the different approaches on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/connectome_extraction.html#linking-total-and-direct-interactions-at-the-group-level">3.2.4. Linking total and direct interactions at the group level</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/resting_state_networks.html">3.3. Extracting functional brain networks: ICA and related</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html#multi-subject-ica-canica">3.3.1. Multi-subject ICA: CanICA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/resting_state_networks.html#objective">3.3.1.1. Objective</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/resting_state_networks.html#fitting-canica-model-with-nilearn">3.3.1.2. Fitting CanICA model with nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/resting_state_networks.html#visualizing-results">3.3.1.3. Visualizing results</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/resting_state_networks.html#interpreting-such-components">3.3.1.4. Interpreting such components</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/resting_state_networks.html#an-alternative-to-ica-dictionary-learning">3.3.2. An alternative to <span class="xref std std-term">ICA</span>: <span class="xref std std-term">Dictionary learning</span></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/region_extraction.html">3.4. Region Extraction for better brain parcellations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#fetching-movie-watching-based-functional-datasets">3.4.1. Fetching movie-watching based functional datasets</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#brain-maps-using-dictionary-learning">3.4.2. Brain maps using <span class="xref std std-term">Dictionary learning</span></a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#visualization-of-dictionary-learning-maps">3.4.3. Visualization of <span class="xref std std-term">Dictionary learning</span> maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#region-extraction-with-dictionary-learning-maps">3.4.4. Region Extraction with <span class="xref std std-term">Dictionary learning</span> maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#visualization-of-region-extraction-results">3.4.5. Visualization of Region Extraction results</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#computing-functional-connectivity-matrices">3.4.6. Computing functional connectivity matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#visualization-of-functional-connectivity-matrices">3.4.7. Visualization of functional connectivity matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/region_extraction.html#validating-results">3.4.8. Validating results</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="connectivity/parcellating.html">3.5. Clustering to parcellate the brain in regions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#data-loading-movie-watching-data">3.5.1. Data loading: movie-watching data</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#applying-clustering">3.5.2. Applying clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="connectivity/parcellating.html#using-and-visualizing-the-resulting-parcellation">3.5.3. Using and visualizing the resulting parcellation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#visualizing-the-parcellation">3.5.3.1. Visualizing the parcellation</a></li>
<li class="toctree-l4"><a class="reference internal" href="connectivity/parcellating.html#compressed-representation">3.5.3.2. Compressed representation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="plotting/index.html">4. Plotting brain images</a><ul>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#different-plotting-functions">4.1. Different plotting functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#different-display-modes">4.2. Different display modes</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#available-colormaps">4.3. Available Colormaps</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#adding-overlays-edges-contours-contour-fillings-markers-scale-bar">4.4. Adding overlays, edges, contours, contour fillings, markers, scale bar</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#displaying-or-saving-to-an-image-file">4.5. Displaying or saving to an image file</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#surface-plotting">4.6. Surface plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="plotting/index.html#interactive-plots">4.7. Interactive plots</a><ul>
<li class="toctree-l3"><a class="reference internal" href="plotting/index.html#d-plots-of-statistical-maps-or-atlases-on-the-cortical-surface">4.7.1. 3D Plots of statistical maps or atlases on the cortical surface</a><ul>
<li class="toctree-l4"><a class="reference internal" href="plotting/index.html#view-img-on-surf-surface-plot-using-a-3d-statistical-map">4.7.1.1. <code class="xref py py-func docutils literal notranslate"><span class="pre">view_img_on_surf</span></code>: Surface plot using a 3D statistical map</a></li>
<li class="toctree-l4"><a class="reference internal" href="plotting/index.html#view-surf-surface-plot-using-a-surface-map-and-a-cortical-mesh">4.7.1.2. <code class="xref py py-func docutils literal notranslate"><span class="pre">view_surf</span></code>: Surface plot using a surface map and a cortical mesh</a></li>
<li class="toctree-l4"><a class="reference internal" href="plotting/index.html#plot-surf-stat-map-surface-plot-using-a-surface-map-and-a-cortical-mesh">4.7.1.3. <code class="xref py py-func docutils literal notranslate"><span class="pre">plot_surf_stat_map</span></code>: Surface plot using a surface map and a cortical mesh</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="plotting/index.html#d-plots-of-connectomes">4.7.2. 3D Plots of connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="plotting/index.html#d-plots-of-markers">4.7.3. 3D Plots of markers</a></li>
<li class="toctree-l3"><a class="reference internal" href="plotting/index.html#interactive-visualization-of-statistical-map-slices">4.7.4. Interactive visualization of statistical map slices</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="glm/index.html">5. Analyzing fMRI using GLMs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="glm/glm_intro.html">5.1. An introduction to GLMs in fMRI statistical analysis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="glm/glm_intro.html#a-primer-on-bold-fmri-data-analysis">5.1.1. A primer on BOLD-fMRI data analysis</a><ul>
<li class="toctree-l4"><a class="reference internal" href="glm/glm_intro.html#what-is-fmri">5.1.1.1. What is fMRI ?</a></li>
<li class="toctree-l4"><a class="reference internal" href="glm/glm_intro.html#fmri-data-modelling">5.1.1.2. fMRI data modelling</a></li>
<li class="toctree-l4"><a class="reference internal" href="glm/glm_intro.html#fmri-statistical-analysis">5.1.1.3. fMRI statistical analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="glm/glm_intro.html#multiple-comparisons">5.1.1.4. Multiple Comparisons</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="glm/first_level_model.html">5.2. First level models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html#hrf-models">5.2.1. HRF models</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html#design-matrix-event-based-and-time-series-based">5.2.2. Design matrix: event-based and time series-based</a><ul>
<li class="toctree-l4"><a class="reference internal" href="glm/first_level_model.html#event-based">5.2.2.1. Event-based</a></li>
<li class="toctree-l4"><a class="reference internal" href="glm/first_level_model.html#time-series-based">5.2.2.2. Time series-based</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html#fitting-a-first-level-model">5.2.3. Fitting a first level model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="glm/first_level_model.html#computing-contrasts">5.2.3.1. Computing contrasts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html#extracting-predicted-time-series-and-residuals">5.2.4. Extracting predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/first_level_model.html#surface-based-analysis">5.2.5. Surface-based analysis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="glm/second_level_model.html">5.3. Second level models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html#fitting-a-second-level-model">5.3.1. Fitting a second level model</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html#thresholding-statistical-maps">5.3.2. Thresholding statistical maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html#multiple-comparisons-correction">5.3.3. Multiple comparisons correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="glm/second_level_model.html#voxel-based-morphometry">5.3.4. Voxel based morphometry</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="manipulating_images/index.html">6. Manipulation brain volumes with nilearn</a><ul>
<li class="toctree-l2"><a class="reference internal" href="manipulating_images/input_output.html">6.1. Input and output: neuroimaging data representation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/input_output.html#inputing-data-file-names-or-image-objects">6.1.1. Inputing data: file names or image objects</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/input_output.html#file-names-and-objects-3d-and-4d-images">6.1.1.1. File names and objects, 3D and 4D images</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/input_output.html#file-name-matching-globbing-and-user-path-expansion">6.1.1.2. File name matching: “globbing” and user path expansion</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/input_output.html#fetching-open-datasets-from-internet">6.1.2. Fetching open datasets from Internet</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/input_output.html#understanding-neuroimaging-data">6.1.3. Understanding neuroimaging data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/input_output.html#nifti-and-analyze-data">6.1.3.1. Nifti and Analyze data</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/input_output.html#niimg-like-objects">6.1.3.2. Niimg-like objects</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/input_output.html#text-files-phenotype-or-behavior">6.1.3.3. Text files: phenotype or behavior</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manipulating_images/manipulating_images.html">6.2. Manipulating images: resampling, smoothing, masking, ROIs…</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html#functions-for-data-preparation-and-image-transformation">6.2.1. Functions for data preparation and image transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html#resampling-images">6.2.2. Resampling images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/manipulating_images.html#resampling-one-image-to-match-another-one">6.2.2.1. Resampling one image to match another one</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/manipulating_images.html#resampling-to-a-specific-target-affine-shape-or-resolution">6.2.2.2. Resampling to a specific target affine, shape, or resolution</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html#accessing-individual-volumes-in-4d-images">6.2.3. Accessing individual volumes in 4D images</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html#computing-and-applying-spatial-masks">6.2.4. Computing and applying spatial masks</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/manipulating_images.html#extracting-a-brain-mask">6.2.4.1. Extracting a brain mask</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/manipulating_images.html#masking-data-from-4d-nifti-images-to-2d-data-arrays">6.2.4.2. Masking data: from 4D Nifti images to 2D data arrays</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/manipulating_images.html#image-operations-creating-a-roi-mask-manually">6.2.5. Image operations: creating a ROI mask manually</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manipulating_images/masker_objects.html">6.3. From neuroimaging volumes to data matrices: the masker objects</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html#the-concept-of-masker-objects">6.3.1. The concept of “masker” objects</a></li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html#niftimasker-applying-a-mask-to-load-time-series">6.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMasker</span></code>: applying a mask to load time-series</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#custom-data-loading-loading-only-the-first-100-time-points">6.3.2.1. Custom data loading: loading only the first 100 time points</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#controlling-how-the-mask-is-computed-from-the-data">6.3.2.2. Controlling how the mask is computed from the data</a><ul>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#visualizing-the-computed-mask">6.3.2.2.1. Visualizing the computed mask</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#different-masking-strategies">6.3.2.2.2. Different masking strategies</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#extra-mask-parameters-opening-cutoff">6.3.2.2.3. Extra mask parameters: opening, cutoff…</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#common-data-preparation-steps-smoothing-filtering-resampling">6.3.2.3. Common data preparation steps: smoothing, filtering, resampling</a><ul>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#smoothing">6.3.2.3.1. Smoothing</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#temporal-filtering-and-confound-removal">6.3.2.3.2. Temporal Filtering and confound removal</a></li>
<li class="toctree-l5"><a class="reference internal" href="manipulating_images/masker_objects.html#resampling-resizing-and-changing-resolutions-of-images">6.3.2.3.3. Resampling: resizing and changing resolutions of images</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#inverse-transform-unmasking-data">6.3.2.4. Inverse transform: unmasking data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html#extraction-of-signals-from-regions-niftilabelsmasker-niftimapsmasker">6.3.3. Extraction of signals from regions: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#regions-definition">6.3.3.1. Regions definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#niftilabelsmasker-usage">6.3.3.2. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="manipulating_images/masker_objects.html#niftimapsmasker-usage">6.3.3.3. <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiMapsMasker</span></code> Usage</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manipulating_images/masker_objects.html#extraction-of-signals-from-seeds-niftispheresmasker">6.3.4. Extraction of signals from seeds: <code class="xref py py-class docutils literal notranslate"><span class="pre">NiftiSpheresMasker</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="building_blocks/index.html">7. Advanced usage: manual pipelines and scaling up</a><ul>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/manual_pipeline.html">7.1. Building your own neuroimaging machine-learning pipeline</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#data-loading-and-preprocessing">7.1.1. Data loading and preprocessing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#downloading-the-data">7.1.1.1. Downloading the data</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#loading-non-image-data-experiment-description">7.1.1.2. Loading non image data: experiment description</a></li>
<li class="toctree-l4"><a class="reference internal" href="building_blocks/manual_pipeline.html#masking-the-data-from-4d-image-to-2d-array">7.1.1.3. Masking the data: from 4D image to 2D array</a><ul>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/manual_pipeline.html#applying-a-mask">7.1.1.3.1. Applying a mask</a></li>
<li class="toctree-l5"><a class="reference internal" href="building_blocks/manual_pipeline.html#automatically-computing-a-mask">7.1.1.3.2. Automatically computing a mask</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#applying-a-scikit-learn-machine-learning-method">7.1.2. Applying a scikit-learn machine learning method</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#unmasking-inverse-transform">7.1.3. Unmasking (inverse_transform)</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#visualizing-results">7.1.4. Visualizing results</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/manual_pipeline.html#going-further">7.1.5. Going further</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="building_blocks/neurovault.html">7.2. Downloading statistical maps from the Neurovault repository</a><ul>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#specific-images-or-collections">7.2.1. Specific images or collections</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#selection-filters">7.2.2. Selection filters</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#output">7.2.3. Output</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#neurosynth-annotations">7.2.4. Neurosynth annotations</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#examples-using-neurovault">7.2.5. Examples using Neurovault</a></li>
<li class="toctree-l3"><a class="reference internal" href="building_blocks/neurovault.html#references">7.2.6. References</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="modules/reference.html">8. Reference documentation: all nilearn functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.connectome">8.1. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.connectome</span></code>: Functional Connectivity</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.datasets">8.2. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.datasets</span></code>: Automatic Dataset Fetching</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decoding">8.3. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decoding</span></code>: Decoding</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.decomposition">8.4. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.decomposition</span></code>: Multivariate Decompositions</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.image">8.5. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.image</span></code>: Image Processing and Resampling Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.interfaces">8.6. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces</span></code>: Loading components from interfaces</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.interfaces.bids">8.6.1. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.bids</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.interfaces.fmriprep">8.6.2. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.fmriprep</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.interfaces.fsl">8.6.3. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.interfaces.fsl</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.maskers">8.7. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.maskers</span></code>: Extracting Signals from Brain Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.masking">8.8. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.masking</span></code>: Data Masking Utilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.regions">8.9. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.regions</span></code>: Operating on Regions</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.mass_univariate">8.10. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.mass_univariate</span></code>: Mass-Univariate Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.plotting">8.11. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting</span></code>: Plotting Brain Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.plotting.displays">8.11.1. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.plotting.displays</span></code>: Interacting with figures</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.signal">8.12. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.signal</span></code>: Preprocessing Time Series</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.glm">8.13. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm</span></code>: Generalized Linear Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.glm.first_level">8.13.1. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.first_level</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="modules/reference.html#module-nilearn.glm.second_level">8.13.2. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.glm.second_level</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.reporting">8.14. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.reporting</span></code>: Reporting Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="modules/reference.html#module-nilearn.surface">8.15. <code class="xref py py-mod docutils literal notranslate"><span class="pre">nilearn.surface</span></code>: Manipulating Surface Data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">9. Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/index.html#basic-tutorials">9.1. Basic tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/index.html#visualization-of-brain-images">9.2. Visualization of brain images</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/index.html#decoding-and-predicting-from-brain-images">9.3. Decoding and predicting from brain images</a></li>
<li class="toctree-l2"><a class="reference internal" href="auto_examples/index.html#functional-connectivity">9.4. Functional connectivity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/index.html#glm-first-level-analysis-examples">9.4.1. GLM: First level analysis examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/index.html#glm-second-level-analysis-examples">9.4.2. GLM : Second level analysis examples</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/index.html#manipulating-brain-image-volumes">9.4.3. Manipulating brain image volumes</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_examples/index.html#advanced-statistical-analysis-of-brain-images">9.4.4. Advanced statistical analysis of brain images</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="introduction.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">1. </span>Introduction: nilearn in a nutshell</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="authors.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">People</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers 2010-2022
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    </body>
</html>