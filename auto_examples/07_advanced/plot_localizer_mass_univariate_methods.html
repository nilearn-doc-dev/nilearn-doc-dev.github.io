<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

<meta property="og:title" content="9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset" />
  
<meta property="og:type" content="website" />
  
<meta property="og:url" content="https://nilearn.github.io/auto_examples/07_advanced/plot_localizer_mass_univariate_methods.html" />
  
<meta property="og:site_name" content="Nilearn" />
  
<meta property="og:description" content="This example shows the results obtained in a massively univariate analysis performed at the inter-subject level with various methods. We use the [left button press (auditory cue)] task from the Loc..." />
  
<meta property="og:image" content="https://nilearn.github.io/_static/nilearn-logo.png" />
  
<meta property="og:image:alt" content="Nilearn" />
  <link rel="search" title="Search" href="../../search.html" /><link rel="next" title="9.4.4.8.8. NeuroVault cross-study ICA maps." href="plot_ica_neurovault.html" /><link rel="prev" title="9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset" href="plot_surface_bids_analysis.html" />

    <link rel="shortcut icon" href="../../_static/favicon.ico"/><meta name="generator" content="sphinx-4.4.0, furo 2022.03.04"/>
        <title>9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset - Nilearn</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo.css?digest=935aa2abcc5c1da4283d1dc201fb1f0add16d23a" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery-rendered-html.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/furo-extensions.css?digest=25ceb02ed1c46dc30f2321ff83e92799f69dfdb9" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" />
    
    


<style>
  body {
    --color-code-background: #ffffff;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #232629;
  --color-code-foreground: #cccccc;
  
      }
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../index.html"><div class="brand">Nilearn</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../../_static/nilearn-transparent.png" alt="Logo"/>
  </div>
  
  <span class="sidebar-brand-text">Nilearn</span>
  
</a><form class="sidebar-search-container" method="get" action="../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../nistats_migration.html">A Quick Guide to Migrating Nistats Code to Nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html">People</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html#citing-nilearn">Citing nilearn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../authors.html#citing-scikit-learn">Citing scikit-learn</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../../user_guide.html">User guide: table of contents</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html">1. Introduction: nilearn in a nutshell</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../decoding/index.html">2. Decoding and MVPA: predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/decoding_intro.html">2.1. An introduction to decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/estimator_choice.html">2.2. Choosing the right predictive model for neuroimaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/frem.html">2.3. FREM: fast ensembling of regularized models for robust decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/space_net.html">2.4. SpaceNet: decoding with spatial structure for better maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/searchlight.html">2.5. Searchlight : finding voxels containing information</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../decoding/going_further.html">2.6. Running scikit-learn functions for more control on the analysis</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../connectivity/index.html">3. Functional connectivity and resting state</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/functional_connectomes.html">3.1. Extracting times series to build a functional connectome</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../connectivity/connectome_extraction.html">3.2. Connectome extraction: inverse covariance for direct connections</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../developers/group_sparse_covariance.html">3.2.3.1. Group-sparse covariance estimation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/resting_state_networks.html">3.3. Extracting functional brain networks: ICA and related</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/region_extraction.html">3.4. Region Extraction for better brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../connectivity/parcellating.html">3.5. Clustering to parcellate the brain in regions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../plotting/index.html">4. Plotting brain images</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../glm/index.html">5. Analyzing fMRI using GLMs</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../glm/glm_intro.html">5.1. An introduction to GLMs in fMRI statistical analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/first_level_model.html">5.2. First level models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../glm/second_level_model.html">5.3. Second level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../manipulating_images/index.html">6. Manipulation brain volumes with nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/input_output.html">6.1. Input and output: neuroimaging data representation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/manipulating_images.html">6.2. Manipulating images: resampling, smoothing, masking, ROIs…</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../manipulating_images/masker_objects.html">6.3. From neuroimaging volumes to data matrices: the masker objects</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../building_blocks/index.html">7. Advanced usage: manual pipelines and scaling up</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/manual_pipeline.html">7.1. Building your own neuroimaging machine-learning pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../building_blocks/neurovault.html">7.2. Downloading statistical maps from the Neurovault repository</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../modules/reference.html">8. Reference documentation: all nilearn functions</a></li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="../index.html">9. Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3 has-children"><a class="reference internal" href="../00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l4"><a class="reference internal" href="../00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l4"><a class="reference internal" href="../00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l4"><a class="reference internal" href="../02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l4"><a class="reference internal" href="../03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" role="switch" type="checkbox"/><label for="toctree-checkbox-13"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" role="switch" type="checkbox"/><label for="toctree-checkbox-14"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l4"><a class="reference internal" href="../05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" role="switch" type="checkbox"/><label for="toctree-checkbox-15"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l4"><a class="reference internal" href="../06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l3 current has-children"><a class="reference internal" href="index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" role="switch" type="checkbox"/><label for="toctree-checkbox-16"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l4"><a class="reference internal" href="plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="../index.html">9. Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" role="switch" type="checkbox"/><label for="toctree-checkbox-17"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2 has-children"><a class="reference internal" href="../00_tutorials/index.html">9.4.4.1. Basic tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" role="switch" type="checkbox"/><label for="toctree-checkbox-18"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_python_101.html">9.4.4.1.1. Basic numerics and plotting with Python</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_nilearn_101.html">9.4.4.1.2. Basic nilearn example: manipulating and looking at data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_3d_and_4d_niimg.html">9.4.4.1.3. 3D and 4D niimgs: handling and visualizing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_decoding_tutorial.html">9.4.4.1.4. A introduction tutorial to fMRI decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../00_tutorials/plot_single_subject_single_run.html">9.4.4.1.5. Intro to GLM Analysis: a single-session, single-subject fMRI dataset</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../01_plotting/index.html">9.4.4.2. Visualization of brain images</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" role="switch" type="checkbox"/><label for="toctree-checkbox-19"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain.html">9.4.4.2.1. Glass brain plotting in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualize_megatrawls_netmats.html">9.4.4.2.2. Visualizing Megatrawls Network Matrices from Human Connectome Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_atlas.html">9.4.4.2.3. Basic Atlas plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_multiscale_parcellations.html">9.4.4.2.4. Visualizing multiscale functional brain parcellations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_colormaps.html">9.4.4.2.5. Matplotlib colormaps in Nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_overlay.html">9.4.4.2.6. Visualizing a probabilistic atlas: the default mode in the MSDL atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_overlay.html#visualizing-a-probabilistic-atlas-with-plot-prob-atlas">9.4.4.2.7. Visualizing a probabilistic atlas with plot_prob_atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_dim_plotting.html">9.4.4.2.8. Controlling the contrast of the background when plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_visualization.html">9.4.4.2.9. NeuroImaging volumes visualization</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_carpet.html">9.4.4.2.10. Visualizing global patterns with a carpet plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_haxby_masks.html">9.4.4.2.11. Plot Haxby masks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surface_projection_strategies.html">9.4.4.2.12. Technical point: Illustration of the volume to surface sampling schemes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_plotting.html">9.4.4.2.13. Plotting tools in nilearn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_prob_atlas.html">9.4.4.2.14. Visualizing 4D probabilistic atlas maps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_stat_map.html">9.4.4.2.15. Seed-based connectivity on the surface</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_surf_atlas.html">9.4.4.2.16. Loading and plotting of a cortical surface atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_3d_map_to_surface_projection.html">9.4.4.2.17. Making a surface plot of a 3D statistical map</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_glass_brain_extensive.html">9.4.4.2.18. Glass brain plotting in nilearn (all options)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../01_plotting/plot_demo_more_plotting.html">9.4.4.2.19. More plotting tools from nilearn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../02_decoding/index.html">9.4.4.3. Decoding and predicting from brain images</a><input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" role="switch" type="checkbox"/><label for="toctree-checkbox-20"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_stimuli.html">9.4.4.3.1. Show stimuli of Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_mixed_gambles_frem.html">9.4.4.3.2. FREM on Jimura et al “mixed gambles” dataset.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_frem.html">9.4.4.3.3. Decoding with FREM: face vs house object recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm_space_net.html">9.4.4.3.4. Voxel-Based Morphometry on Oasis dataset with Space-Net prior</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_anova_svm.html">9.4.4.3.5. Decoding with ANOVA + SVM: face vs house in the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight_surface.html">9.4.4.3.6. Cortical surface-based searchlight decoding</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_multiclass.html">9.4.4.3.7. The haxby dataset: different multi-class strategies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_searchlight.html">9.4.4.3.8. Searchlight analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_glm_decoding.html">9.4.4.3.9. Decoding of a dataset after GLM fit for signal extraction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_grid_search.html">9.4.4.3.10. Setting a parameter by cross-validation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_full_analysis.html">9.4.4.3.11. ROI-based decoding analysis in Haxby et al. dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_haxby_different_estimators.html">9.4.4.3.12. Different classifiers in decoding the Haxby dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_oasis_vbm.html">9.4.4.3.13. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_simulated_data.html">9.4.4.3.14. Example of pattern recognition on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_encoding.html">9.4.4.3.15. Encoding models for visual stimuli from Miyawaki et al. 2008</a></li>
<li class="toctree-l3"><a class="reference internal" href="../02_decoding/plot_miyawaki_reconstruction.html">9.4.4.3.16. Reconstruction of visual stimuli from Miyawaki et al. 2008</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../03_connectivity/index.html">9.4.4.4. Functional connectivity</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" role="switch" type="checkbox"/><label for="toctree-checkbox-21"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_probabilistic_atlas_extraction.html">9.4.4.4.1. Extracting signals of a probabilistic atlas of functional regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_inverse_covariance_connectome.html">9.4.4.4.2. Computing a connectome with sparse inverse covariance</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_simulated_connectome.html">9.4.4.4.3. Connectivity structure estimation on simulated data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_compare_decomposition.html">9.4.4.4.4. Deriving spatial maps from group fMRI data using ICA and Dictionary Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_seed_to_voxel_correlation.html">9.4.4.4.5. Producing single subject maps of seed-to-voxel correlation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_multi_subject_connectome.html">9.4.4.4.6. Group Sparse inverse covariance for multi-subject connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_extract_regions_dictlearning_maps.html">9.4.4.4.7. Regions extraction using <span class="xref std std-term">Dictionary learning</span> and functional connectomes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_atlas_comparison.html">9.4.4.4.8. Comparing connectomes on different reference atlases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_group_level_connectivity.html">9.4.4.4.9. Classification of age groups using functional connectivity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_signal_extraction.html">9.4.4.4.10. Extracting signals from a brain parcellation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_sphere_based_connectome.html">9.4.4.4.11. Extract signals on spheres and plot a connectome</a></li>
<li class="toctree-l3"><a class="reference internal" href="../03_connectivity/plot_data_driven_parcellations.html">9.4.4.4.12. Clustering methods to learn a brain parcellation from fMRI</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../04_glm_first_level/index.html">9.4.4.5. GLM: First level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" role="switch" type="checkbox"/><label for="toctree-checkbox-22"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_write_events_file.html">9.4.4.5.1. Generate an events.tsv file for the NeuroSpin localizer task</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_fixed_effects.html">9.4.4.5.2. Example of explicit fixed effects fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_adhd_dmn.html">9.4.4.5.3. Default Mode Network extraction of AHDH dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_design_matrix.html">9.4.4.5.4. Examples of design matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_fir_model.html">9.4.4.5.5. Analysis of an fMRI dataset with a Finite Impule Response (FIR) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_spm_multimodal_faces.html">9.4.4.5.6. Single-subject data (two sessions) in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_hrf.html">9.4.4.5.7. Example of MRI response functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_fiac_analysis.html">9.4.4.5.8. Simple example of two-session fMRI model fitting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_bids_features.html">9.4.4.5.9. First level analysis of a complete BIDS dataset from openneuro</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_predictions_residuals.html">9.4.4.5.10. Predicted time series and residuals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_localizer_surface_analysis.html">9.4.4.5.11. Example of surface-based first-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../04_glm_first_level/plot_first_level_details.html">9.4.4.5.12. Understanding parameters of the first-level model</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../05_glm_second_level/index.html">9.4.4.6. GLM : Second level analysis examples</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" role="switch" type="checkbox"/><label for="toctree-checkbox-23"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_second_level_design_matrix.html">9.4.4.6.1. Example of second level design matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_proportion_activated_voxels.html">9.4.4.6.2. Second-level fMRI model: true positive proportion in clusters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_thresholding.html">9.4.4.6.3. Statistical testing of a second-level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_oasis.html">9.4.4.6.4. Voxel-Based Morphometry on Oasis dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_second_level_two_sample_test.html">9.4.4.6.5. Second-level fMRI model: two-sample test, unpaired and paired</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_second_level_one_sample_test.html">9.4.4.6.6. Second-level fMRI model: one sample test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../05_glm_second_level/plot_second_level_association_test.html">9.4.4.6.7. Example of generic design in second-level models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../06_manipulating_images/index.html">9.4.4.7. Manipulating brain image volumes</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" role="switch" type="checkbox"/><label for="toctree-checkbox-24"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_negate_image.html">9.4.4.7.1. Negating an image with math_img</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_compare_mean_image.html">9.4.4.7.2. Comparing the means of 2 images</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_smooth_mean_image.html">9.4.4.7.3. Smoothing an image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_smith_atlas.html">9.4.4.7.4. Regions Extraction of Default Mode Networks using Smith Atlas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_regions_labels_image.html">9.4.4.7.5. Breaking an atlas of labels in separated regions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_resample_to_template.html">9.4.4.7.6. Resample an image to a template</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_simple.html">9.4.4.7.7. Simple example of NiftiMasker use</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_nifti_labels_simple.html">9.4.4.7.8. Extracting signals from brain regions using the NiftiLabelsMasker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_extract_rois_statistical_maps.html">9.4.4.7.9. Region Extraction using a t-statistical map (3D)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_mask_computation.html">9.4.4.7.10. Understanding NiftiMasker and mask computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_affine_transformation.html">9.4.4.7.11. Visualization of affine resamplings</a></li>
<li class="toctree-l3"><a class="reference internal" href="../06_manipulating_images/plot_roi_extraction.html">9.4.4.7.12. Computing a Region of Interest (ROI) mask manually</a></li>
</ul>
</li>
<li class="toctree-l2 current has-children"><a class="reference internal" href="index.html">9.4.4.8. Advanced statistical analysis of brain images</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" role="switch" type="checkbox"/><label for="toctree-checkbox-25"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="plot_ica_resting_state.html">9.4.4.8.1. Multivariate decompositions: Independent component analysis of fMRI</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_localizer_simple_analysis.html">9.4.4.8.2. Massively univariate analysis of a calculation task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_bids_analysis.html">9.4.4.8.3. BIDS dataset first and second level analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_age_group_prediction_cross_val.html">9.4.4.8.4. Functional connectivity predicts age group</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_neurovault_meta_analysis.html">9.4.4.8.5. NeuroVault meta-analysis of stop-go paradigm studies.</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_surface_bids_analysis.html">9.4.4.8.6. Surface-based dataset first and second level analysis of a dataset</a></li>
<li class="toctree-l3 current current-page"><a class="current reference internal" href="#">9.4.4.8.7. Massively univariate analysis of a motor task from the Localizer dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_ica_neurovault.html">9.4.4.8.8. NeuroVault cross-study ICA maps.</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_haxby_mass_univariate.html">9.4.4.8.9. Massively univariate analysis of face vs house recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="plot_advanced_decoding_scikit.html">9.4.4.8.10. Advanced decoding using scikit learn</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html">What’s new</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#dev">0.9.1.dev</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id100">0.9.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id204">0.8.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id309">0.8.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id414">0.7.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id518">0.7.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id623">0.6.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id726">0.6.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id829">0.6.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#rc">0.6.0rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#b0">0.6.0b0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#a0">0.6.0a0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id948">0.5.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1051">0.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1155">0.5.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1159">0.5.0 rc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#beta">0.5.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#alpha">0.5.0 alpha</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1272">0.4.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1374">0.4.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1476">0.4.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1581">0.3.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1685">0.3.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1689">0.3.0 beta</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1793">0.2.6</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1896">0.2.5.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id1900">0.2.5</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2002">0.2.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2104">0.2.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2205">0.2.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#v0-2-1">0.2.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2312">0.2.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2417">0.1.4</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2518">0.1.3</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2620">0.1.2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2721">0.1.1</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changes/whats_new.html#id2822">0.1.0</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../development.html">Nilearn development process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../maintenance.html">Nilearn maintenance process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../glossary.html">Glossary</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container"><div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py"><span class="std std-ref">here</span></a>
to download the full example code or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="massively-univariate-analysis-of-a-motor-task-from-the-localizer-dataset">
<span id="sphx-glr-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py"></span><h1><span class="section-number">9.4.4.8.7. </span>Massively univariate analysis of a motor task from the Localizer dataset<a class="headerlink" href="#massively-univariate-analysis-of-a-motor-task-from-the-localizer-dataset" title="Permalink to this headline">#</a></h1>
<p>This example shows the results obtained in a massively univariate
analysis performed at the inter-subject level with various methods.
We use the [left button press (auditory cue)] task from the Localizer
dataset and seek association between the contrast values and a variate
that measures the speed of pseudo-word reading. No confounding variate
is included in the model.</p>
<ol class="arabic simple">
<li><p>A standard <a class="reference internal" href="../../glossary.html#term-ANOVA"><span class="xref std std-term">ANOVA</span></a> is performed. Data smoothed at 5
<a class="reference internal" href="../../glossary.html#term-voxel"><span class="xref std std-term">voxels</span></a> <a class="reference internal" href="../../glossary.html#term-FWHM"><span class="xref std std-term">FWHM</span></a> are used.</p></li>
<li><p>A permuted Ordinary Least Squares algorithm is run at each <a class="reference internal" href="../../glossary.html#term-voxel"><span class="xref std std-term">voxel</span></a>.
Data smoothed at 5 <a class="reference internal" href="../../glossary.html#term-voxel"><span class="xref std std-term">voxels</span></a> <a class="reference internal" href="../../glossary.html#term-FWHM"><span class="xref std std-term">FWHM</span></a> are used.</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Author: Virgile Fritsch, &lt;virgile.fritsch@inria.fr&gt;, May. 2014</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">nilearn.maskers</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">NiftiMasker</span></a>
<span class="kn">from</span> <span class="nn">nilearn.mass_univariate</span> <span class="kn">import</span> <span class="n">permuted_ols</span>
<span class="kn">from</span> <span class="nn">nilearn.image</span> <span class="kn">import</span> <span class="n">get_data</span>
</pre></div>
</div>
<p>Load Localizer contrast</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a> <span class="o">=</span> <span class="mi">94</span>
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch" class="sphx-glr-backref-module-sklearn-utils sphx-glr-backref-type-py-function"><span class="n">localizer_dataset</span></a> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_localizer_contrasts</span><span class="p">(</span>
    <span class="p">[</span><span class="s1">'left button press (auditory cue)'</span><span class="p">],</span>
    <span class="n">n_subjects</span><span class="o">=</span><a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a><span class="p">,</span> <span class="n">legacy_format</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="c1"># print basic information on the dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'First contrast nifti image (3D) is located at: </span><span class="si">%s</span><span class="s1">'</span> <span class="o">%</span>
      <a href="https://docs.python.org/3.8/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">cmaps</span></a><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a> <span class="o">=</span> <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="pandas.core.frame.DataFrame" class="sphx-glr-backref-module-pandas-core-frame sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">ext_vars</span></a><span class="p">[</span><span class="s1">'pseudo'</span><span class="p">]</span>
<span class="c1"># Quality check / Remove subjects with bad tested variate</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.where.html#numpy.where" title="numpy.where" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">where</span></a><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">isnan</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">))</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a> <span class="o">=</span> <a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span><span class="o">.</span><span class="n">size</span></a>
<a href="https://docs.python.org/3.8/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">contrast_map_filenames</span></a> <span class="o">=</span> <span class="p">[</span><a href="https://docs.python.org/3.8/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">localizer_dataset</span><span class="o">.</span><span class="n">cmaps</span></a><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                          <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a><span class="p">]</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">mask_quality_check</span></a><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Actual number of subjects after quality check: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">n_samples</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>First contrast nifti image (3D) is located at: /home/alexis/nilearn_data/brainomics_localizer/brainomics_data/S01/cmaps_LeftAuditoryClick.nii.gz
Actual number of subjects after quality check: 89
</pre></div>
</div>
<p>Mask data</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nifti_masker</span> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-class"><span class="n">NiftiMasker</span></a><span class="p">(</span>
    <span class="n">smoothing_fwhm</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">memory</span><span class="o">=</span><span class="s1">'nilearn_cache'</span><span class="p">,</span> <span class="n">memory_level</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># cache options</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fmri_masked</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin.fit_transform" title="sklearn.base.TransformerMixin.fit_transform" class="sphx-glr-backref-module-sklearn-base sphx-glr-backref-type-py-method"><span class="n">nifti_masker</span><span class="o">.</span><span class="n">fit_transform</span></a><span class="p">(</span><a href="https://docs.python.org/3.8/library/stdtypes.html#list" title="builtins.list" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">contrast_map_filenames</span></a><span class="p">)</span>
</pre></div>
</div>
<p>Anova (parametric F-scores)</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression" title="sklearn.feature_selection.f_regression" class="sphx-glr-backref-module-sklearn-feature_selection sphx-glr-backref-type-py-function"><span class="n">f_regression</span></a>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a> <span class="o">=</span> <a href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#sklearn.feature_selection.f_regression" title="sklearn.feature_selection.f_regression" class="sphx-glr-backref-module-sklearn-feature_selection sphx-glr-backref-type-py-function"><span class="n">f_regression</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fmri_masked</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a> <span class="o">*=</span> <a href="https://docs.python.org/3.8/library/stdtypes.html#tuple" title="builtins.tuple" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fmri_masked</span><span class="o">.</span><span class="n">shape</span></a><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">isnan</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a><span class="p">[</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova</span></a> <span class="o">=</span> <span class="o">-</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">log10</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">pvals_anova</span></a><span class="p">)</span>
<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova_unmasked</span></a> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova</span></a><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/alexis/anaconda3/envs/nilearn/lib/python3.10/site-packages/sklearn/utils/validation.py:993: DataConversionWarning:

A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
</pre></div>
</div>
<p>Perform massively univariate analysis with permuted OLS</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">_</span></a> <span class="o">=</span> <span class="n">permuted_ols</span><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">tested_var</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fmri_masked</span></a><span class="p">,</span>
    <span class="n">model_intercept</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">n_perm</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>  <span class="c1"># 5,000 for the sake of time. Idealy, this should be 10,000</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="c1"># display progress bar</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># can be changed to use more CPUs</span>
<a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols_unmasked</span></a> <span class="o">=</span> <span class="n">nifti_masker</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span>
    <a href="https://numpy.org/doc/stable/reference/generated/numpy.ravel.html#numpy.ravel" title="numpy.ravel" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">ravel</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols</span></a><span class="p">))</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.
Job #1, processed 0/5000 permutations (0.00%, 139 seconds remaining)
Job #1, processed 10/5000 permutations (0.20%, 79 seconds remaining)
Job #1, processed 20/5000 permutations (0.40%, 71 seconds remaining)
Job #1, processed 30/5000 permutations (0.60%, 68 seconds remaining)
Job #1, processed 40/5000 permutations (0.80%, 62 seconds remaining)
Job #1, processed 50/5000 permutations (1.00%, 59 seconds remaining)
Job #1, processed 60/5000 permutations (1.20%, 61 seconds remaining)
Job #1, processed 70/5000 permutations (1.40%, 58 seconds remaining)
Job #1, processed 80/5000 permutations (1.60%, 58 seconds remaining)
Job #1, processed 90/5000 permutations (1.80%, 58 seconds remaining)
Job #1, processed 100/5000 permutations (2.00%, 57 seconds remaining)
Job #1, processed 110/5000 permutations (2.20%, 54 seconds remaining)
Job #1, processed 120/5000 permutations (2.40%, 53 seconds remaining)
Job #1, processed 130/5000 permutations (2.60%, 51 seconds remaining)
Job #1, processed 140/5000 permutations (2.80%, 50 seconds remaining)
Job #1, processed 150/5000 permutations (3.00%, 48 seconds remaining)
Job #1, processed 160/5000 permutations (3.20%, 47 seconds remaining)
Job #1, processed 170/5000 permutations (3.40%, 46 seconds remaining)
Job #1, processed 180/5000 permutations (3.60%, 46 seconds remaining)
Job #1, processed 190/5000 permutations (3.80%, 46 seconds remaining)
Job #1, processed 200/5000 permutations (4.00%, 46 seconds remaining)
Job #1, processed 210/5000 permutations (4.20%, 45 seconds remaining)
Job #1, processed 220/5000 permutations (4.40%, 45 seconds remaining)
Job #1, processed 230/5000 permutations (4.60%, 47 seconds remaining)
Job #1, processed 240/5000 permutations (4.80%, 47 seconds remaining)
Job #1, processed 250/5000 permutations (5.00%, 46 seconds remaining)
Job #1, processed 260/5000 permutations (5.20%, 45 seconds remaining)
Job #1, processed 270/5000 permutations (5.40%, 45 seconds remaining)
Job #1, processed 280/5000 permutations (5.60%, 44 seconds remaining)
Job #1, processed 290/5000 permutations (5.80%, 44 seconds remaining)
Job #1, processed 300/5000 permutations (6.00%, 43 seconds remaining)
Job #1, processed 310/5000 permutations (6.20%, 44 seconds remaining)
Job #1, processed 320/5000 permutations (6.40%, 44 seconds remaining)
Job #1, processed 330/5000 permutations (6.60%, 44 seconds remaining)
Job #1, processed 340/5000 permutations (6.80%, 43 seconds remaining)
Job #1, processed 350/5000 permutations (7.00%, 43 seconds remaining)
Job #1, processed 360/5000 permutations (7.20%, 43 seconds remaining)
Job #1, processed 370/5000 permutations (7.40%, 42 seconds remaining)
Job #1, processed 380/5000 permutations (7.60%, 42 seconds remaining)
Job #1, processed 390/5000 permutations (7.80%, 42 seconds remaining)
Job #1, processed 400/5000 permutations (8.00%, 42 seconds remaining)
Job #1, processed 410/5000 permutations (8.20%, 42 seconds remaining)
Job #1, processed 420/5000 permutations (8.40%, 42 seconds remaining)
Job #1, processed 430/5000 permutations (8.60%, 41 seconds remaining)
Job #1, processed 440/5000 permutations (8.80%, 41 seconds remaining)
Job #1, processed 450/5000 permutations (9.00%, 41 seconds remaining)
Job #1, processed 460/5000 permutations (9.20%, 41 seconds remaining)
Job #1, processed 470/5000 permutations (9.40%, 40 seconds remaining)
Job #1, processed 480/5000 permutations (9.60%, 40 seconds remaining)
Job #1, processed 490/5000 permutations (9.80%, 40 seconds remaining)
Job #1, processed 500/5000 permutations (10.00%, 39 seconds remaining)
Job #1, processed 510/5000 permutations (10.20%, 39 seconds remaining)
Job #1, processed 520/5000 permutations (10.40%, 39 seconds remaining)
Job #1, processed 530/5000 permutations (10.60%, 39 seconds remaining)
Job #1, processed 540/5000 permutations (10.80%, 38 seconds remaining)
Job #1, processed 550/5000 permutations (11.00%, 38 seconds remaining)
Job #1, processed 560/5000 permutations (11.20%, 38 seconds remaining)
Job #1, processed 570/5000 permutations (11.40%, 37 seconds remaining)
Job #1, processed 580/5000 permutations (11.60%, 37 seconds remaining)
Job #1, processed 590/5000 permutations (11.80%, 37 seconds remaining)
Job #1, processed 600/5000 permutations (12.00%, 37 seconds remaining)
Job #1, processed 610/5000 permutations (12.20%, 37 seconds remaining)
Job #1, processed 620/5000 permutations (12.40%, 36 seconds remaining)
Job #1, processed 630/5000 permutations (12.60%, 36 seconds remaining)
Job #1, processed 640/5000 permutations (12.80%, 36 seconds remaining)
Job #1, processed 650/5000 permutations (13.00%, 36 seconds remaining)
Job #1, processed 660/5000 permutations (13.20%, 36 seconds remaining)
Job #1, processed 670/5000 permutations (13.40%, 36 seconds remaining)
Job #1, processed 680/5000 permutations (13.60%, 36 seconds remaining)
Job #1, processed 690/5000 permutations (13.80%, 35 seconds remaining)
Job #1, processed 700/5000 permutations (14.00%, 35 seconds remaining)
Job #1, processed 710/5000 permutations (14.20%, 35 seconds remaining)
Job #1, processed 720/5000 permutations (14.40%, 35 seconds remaining)
Job #1, processed 730/5000 permutations (14.60%, 35 seconds remaining)
Job #1, processed 740/5000 permutations (14.80%, 34 seconds remaining)
Job #1, processed 750/5000 permutations (15.00%, 35 seconds remaining)
Job #1, processed 760/5000 permutations (15.20%, 34 seconds remaining)
Job #1, processed 770/5000 permutations (15.40%, 34 seconds remaining)
Job #1, processed 780/5000 permutations (15.60%, 34 seconds remaining)
Job #1, processed 790/5000 permutations (15.80%, 34 seconds remaining)
Job #1, processed 800/5000 permutations (16.00%, 34 seconds remaining)
Job #1, processed 810/5000 permutations (16.20%, 33 seconds remaining)
Job #1, processed 820/5000 permutations (16.40%, 33 seconds remaining)
Job #1, processed 830/5000 permutations (16.60%, 33 seconds remaining)
Job #1, processed 840/5000 permutations (16.80%, 33 seconds remaining)
Job #1, processed 850/5000 permutations (17.00%, 33 seconds remaining)
Job #1, processed 860/5000 permutations (17.20%, 33 seconds remaining)
Job #1, processed 870/5000 permutations (17.40%, 32 seconds remaining)
Job #1, processed 880/5000 permutations (17.60%, 32 seconds remaining)
Job #1, processed 890/5000 permutations (17.80%, 32 seconds remaining)
Job #1, processed 900/5000 permutations (18.00%, 32 seconds remaining)
Job #1, processed 910/5000 permutations (18.20%, 32 seconds remaining)
Job #1, processed 920/5000 permutations (18.40%, 32 seconds remaining)
Job #1, processed 930/5000 permutations (18.60%, 32 seconds remaining)
Job #1, processed 940/5000 permutations (18.80%, 31 seconds remaining)
Job #1, processed 950/5000 permutations (19.00%, 31 seconds remaining)
Job #1, processed 960/5000 permutations (19.20%, 31 seconds remaining)
Job #1, processed 970/5000 permutations (19.40%, 31 seconds remaining)
Job #1, processed 980/5000 permutations (19.60%, 31 seconds remaining)
Job #1, processed 990/5000 permutations (19.80%, 31 seconds remaining)
Job #1, processed 1000/5000 permutations (20.00%, 31 seconds remaining)
Job #1, processed 1010/5000 permutations (20.20%, 31 seconds remaining)
Job #1, processed 1020/5000 permutations (20.40%, 31 seconds remaining)
Job #1, processed 1030/5000 permutations (20.60%, 30 seconds remaining)
Job #1, processed 1040/5000 permutations (20.80%, 30 seconds remaining)
Job #1, processed 1050/5000 permutations (21.00%, 30 seconds remaining)
Job #1, processed 1060/5000 permutations (21.20%, 30 seconds remaining)
Job #1, processed 1070/5000 permutations (21.40%, 30 seconds remaining)
Job #1, processed 1080/5000 permutations (21.60%, 30 seconds remaining)
Job #1, processed 1090/5000 permutations (21.80%, 30 seconds remaining)
Job #1, processed 1100/5000 permutations (22.00%, 30 seconds remaining)
Job #1, processed 1110/5000 permutations (22.20%, 30 seconds remaining)
Job #1, processed 1120/5000 permutations (22.40%, 29 seconds remaining)
Job #1, processed 1130/5000 permutations (22.60%, 29 seconds remaining)
Job #1, processed 1140/5000 permutations (22.80%, 29 seconds remaining)
Job #1, processed 1150/5000 permutations (23.00%, 29 seconds remaining)
Job #1, processed 1160/5000 permutations (23.20%, 29 seconds remaining)
Job #1, processed 1170/5000 permutations (23.40%, 29 seconds remaining)
Job #1, processed 1180/5000 permutations (23.60%, 29 seconds remaining)
Job #1, processed 1190/5000 permutations (23.80%, 29 seconds remaining)
Job #1, processed 1200/5000 permutations (24.00%, 29 seconds remaining)
Job #1, processed 1210/5000 permutations (24.20%, 29 seconds remaining)
Job #1, processed 1220/5000 permutations (24.40%, 29 seconds remaining)
Job #1, processed 1230/5000 permutations (24.60%, 28 seconds remaining)
Job #1, processed 1240/5000 permutations (24.80%, 28 seconds remaining)
Job #1, processed 1250/5000 permutations (25.00%, 28 seconds remaining)
Job #1, processed 1260/5000 permutations (25.20%, 28 seconds remaining)
Job #1, processed 1270/5000 permutations (25.40%, 28 seconds remaining)
Job #1, processed 1280/5000 permutations (25.60%, 28 seconds remaining)
Job #1, processed 1290/5000 permutations (25.80%, 28 seconds remaining)
Job #1, processed 1300/5000 permutations (26.00%, 28 seconds remaining)
Job #1, processed 1310/5000 permutations (26.20%, 28 seconds remaining)
Job #1, processed 1320/5000 permutations (26.40%, 28 seconds remaining)
Job #1, processed 1330/5000 permutations (26.60%, 28 seconds remaining)
Job #1, processed 1340/5000 permutations (26.80%, 28 seconds remaining)
Job #1, processed 1350/5000 permutations (27.00%, 28 seconds remaining)
Job #1, processed 1360/5000 permutations (27.20%, 28 seconds remaining)
Job #1, processed 1370/5000 permutations (27.40%, 28 seconds remaining)
Job #1, processed 1380/5000 permutations (27.60%, 28 seconds remaining)
Job #1, processed 1390/5000 permutations (27.80%, 27 seconds remaining)
Job #1, processed 1400/5000 permutations (28.00%, 27 seconds remaining)
Job #1, processed 1410/5000 permutations (28.20%, 27 seconds remaining)
Job #1, processed 1420/5000 permutations (28.40%, 27 seconds remaining)
Job #1, processed 1430/5000 permutations (28.60%, 27 seconds remaining)
Job #1, processed 1440/5000 permutations (28.80%, 27 seconds remaining)
Job #1, processed 1450/5000 permutations (29.00%, 27 seconds remaining)
Job #1, processed 1460/5000 permutations (29.20%, 27 seconds remaining)
Job #1, processed 1470/5000 permutations (29.40%, 27 seconds remaining)
Job #1, processed 1480/5000 permutations (29.60%, 27 seconds remaining)
Job #1, processed 1490/5000 permutations (29.80%, 27 seconds remaining)
Job #1, processed 1500/5000 permutations (30.00%, 27 seconds remaining)
Job #1, processed 1510/5000 permutations (30.20%, 27 seconds remaining)
Job #1, processed 1520/5000 permutations (30.40%, 27 seconds remaining)
Job #1, processed 1530/5000 permutations (30.60%, 26 seconds remaining)
Job #1, processed 1540/5000 permutations (30.80%, 26 seconds remaining)
Job #1, processed 1550/5000 permutations (31.00%, 26 seconds remaining)
Job #1, processed 1560/5000 permutations (31.20%, 26 seconds remaining)
Job #1, processed 1570/5000 permutations (31.40%, 26 seconds remaining)
Job #1, processed 1580/5000 permutations (31.60%, 26 seconds remaining)
Job #1, processed 1590/5000 permutations (31.80%, 26 seconds remaining)
Job #1, processed 1600/5000 permutations (32.00%, 26 seconds remaining)
Job #1, processed 1610/5000 permutations (32.20%, 26 seconds remaining)
Job #1, processed 1620/5000 permutations (32.40%, 26 seconds remaining)
Job #1, processed 1630/5000 permutations (32.60%, 26 seconds remaining)
Job #1, processed 1640/5000 permutations (32.80%, 25 seconds remaining)
Job #1, processed 1650/5000 permutations (33.00%, 25 seconds remaining)
Job #1, processed 1660/5000 permutations (33.20%, 25 seconds remaining)
Job #1, processed 1670/5000 permutations (33.40%, 25 seconds remaining)
Job #1, processed 1680/5000 permutations (33.60%, 25 seconds remaining)
Job #1, processed 1690/5000 permutations (33.80%, 25 seconds remaining)
Job #1, processed 1700/5000 permutations (34.00%, 25 seconds remaining)
Job #1, processed 1710/5000 permutations (34.20%, 25 seconds remaining)
Job #1, processed 1720/5000 permutations (34.40%, 25 seconds remaining)
Job #1, processed 1730/5000 permutations (34.60%, 25 seconds remaining)
Job #1, processed 1740/5000 permutations (34.80%, 24 seconds remaining)
Job #1, processed 1750/5000 permutations (35.00%, 24 seconds remaining)
Job #1, processed 1760/5000 permutations (35.20%, 24 seconds remaining)
Job #1, processed 1770/5000 permutations (35.40%, 24 seconds remaining)
Job #1, processed 1780/5000 permutations (35.60%, 24 seconds remaining)
Job #1, processed 1790/5000 permutations (35.80%, 24 seconds remaining)
Job #1, processed 1800/5000 permutations (36.00%, 24 seconds remaining)
Job #1, processed 1810/5000 permutations (36.20%, 24 seconds remaining)
Job #1, processed 1820/5000 permutations (36.40%, 24 seconds remaining)
Job #1, processed 1830/5000 permutations (36.60%, 24 seconds remaining)
Job #1, processed 1840/5000 permutations (36.80%, 24 seconds remaining)
Job #1, processed 1850/5000 permutations (37.00%, 24 seconds remaining)
Job #1, processed 1860/5000 permutations (37.20%, 24 seconds remaining)
Job #1, processed 1870/5000 permutations (37.40%, 24 seconds remaining)
Job #1, processed 1880/5000 permutations (37.60%, 24 seconds remaining)
Job #1, processed 1890/5000 permutations (37.80%, 24 seconds remaining)
Job #1, processed 1900/5000 permutations (38.00%, 24 seconds remaining)
Job #1, processed 1910/5000 permutations (38.20%, 24 seconds remaining)
Job #1, processed 1920/5000 permutations (38.40%, 24 seconds remaining)
Job #1, processed 1930/5000 permutations (38.60%, 24 seconds remaining)
Job #1, processed 1940/5000 permutations (38.80%, 24 seconds remaining)
Job #1, processed 1950/5000 permutations (39.00%, 24 seconds remaining)
Job #1, processed 1960/5000 permutations (39.20%, 24 seconds remaining)
Job #1, processed 1970/5000 permutations (39.40%, 24 seconds remaining)
Job #1, processed 1980/5000 permutations (39.60%, 23 seconds remaining)
Job #1, processed 1990/5000 permutations (39.80%, 23 seconds remaining)
Job #1, processed 2000/5000 permutations (40.00%, 23 seconds remaining)
Job #1, processed 2010/5000 permutations (40.20%, 23 seconds remaining)
Job #1, processed 2020/5000 permutations (40.40%, 23 seconds remaining)
Job #1, processed 2030/5000 permutations (40.60%, 23 seconds remaining)
Job #1, processed 2040/5000 permutations (40.80%, 23 seconds remaining)
Job #1, processed 2050/5000 permutations (41.00%, 23 seconds remaining)
Job #1, processed 2060/5000 permutations (41.20%, 23 seconds remaining)
Job #1, processed 2070/5000 permutations (41.40%, 23 seconds remaining)
Job #1, processed 2080/5000 permutations (41.60%, 23 seconds remaining)
Job #1, processed 2090/5000 permutations (41.80%, 23 seconds remaining)
Job #1, processed 2100/5000 permutations (42.00%, 22 seconds remaining)
Job #1, processed 2110/5000 permutations (42.20%, 22 seconds remaining)
Job #1, processed 2120/5000 permutations (42.40%, 22 seconds remaining)
Job #1, processed 2130/5000 permutations (42.60%, 22 seconds remaining)
Job #1, processed 2140/5000 permutations (42.80%, 22 seconds remaining)
Job #1, processed 2150/5000 permutations (43.00%, 22 seconds remaining)
Job #1, processed 2160/5000 permutations (43.20%, 22 seconds remaining)
Job #1, processed 2170/5000 permutations (43.40%, 22 seconds remaining)
Job #1, processed 2180/5000 permutations (43.60%, 22 seconds remaining)
Job #1, processed 2190/5000 permutations (43.80%, 22 seconds remaining)
Job #1, processed 2200/5000 permutations (44.00%, 22 seconds remaining)
Job #1, processed 2210/5000 permutations (44.20%, 21 seconds remaining)
Job #1, processed 2220/5000 permutations (44.40%, 21 seconds remaining)
Job #1, processed 2230/5000 permutations (44.60%, 21 seconds remaining)
Job #1, processed 2240/5000 permutations (44.80%, 21 seconds remaining)
Job #1, processed 2250/5000 permutations (45.00%, 21 seconds remaining)
Job #1, processed 2260/5000 permutations (45.20%, 21 seconds remaining)
Job #1, processed 2270/5000 permutations (45.40%, 21 seconds remaining)
Job #1, processed 2280/5000 permutations (45.60%, 21 seconds remaining)
Job #1, processed 2290/5000 permutations (45.80%, 21 seconds remaining)
Job #1, processed 2300/5000 permutations (46.00%, 21 seconds remaining)
Job #1, processed 2310/5000 permutations (46.20%, 21 seconds remaining)
Job #1, processed 2320/5000 permutations (46.40%, 21 seconds remaining)
Job #1, processed 2330/5000 permutations (46.60%, 21 seconds remaining)
Job #1, processed 2340/5000 permutations (46.80%, 21 seconds remaining)
Job #1, processed 2350/5000 permutations (47.00%, 21 seconds remaining)
Job #1, processed 2360/5000 permutations (47.20%, 21 seconds remaining)
Job #1, processed 2370/5000 permutations (47.40%, 20 seconds remaining)
Job #1, processed 2380/5000 permutations (47.60%, 20 seconds remaining)
Job #1, processed 2390/5000 permutations (47.80%, 20 seconds remaining)
Job #1, processed 2400/5000 permutations (48.00%, 20 seconds remaining)
Job #1, processed 2410/5000 permutations (48.20%, 20 seconds remaining)
Job #1, processed 2420/5000 permutations (48.40%, 20 seconds remaining)
Job #1, processed 2430/5000 permutations (48.60%, 20 seconds remaining)
Job #1, processed 2440/5000 permutations (48.80%, 20 seconds remaining)
Job #1, processed 2450/5000 permutations (49.00%, 20 seconds remaining)
Job #1, processed 2460/5000 permutations (49.20%, 20 seconds remaining)
Job #1, processed 2470/5000 permutations (49.40%, 20 seconds remaining)
Job #1, processed 2480/5000 permutations (49.60%, 20 seconds remaining)
Job #1, processed 2490/5000 permutations (49.80%, 20 seconds remaining)
Job #1, processed 2500/5000 permutations (50.00%, 20 seconds remaining)
Job #1, processed 2510/5000 permutations (50.20%, 20 seconds remaining)
Job #1, processed 2520/5000 permutations (50.40%, 20 seconds remaining)
Job #1, processed 2530/5000 permutations (50.60%, 20 seconds remaining)
Job #1, processed 2540/5000 permutations (50.80%, 19 seconds remaining)
Job #1, processed 2550/5000 permutations (51.00%, 19 seconds remaining)
Job #1, processed 2560/5000 permutations (51.20%, 19 seconds remaining)
Job #1, processed 2570/5000 permutations (51.40%, 19 seconds remaining)
Job #1, processed 2580/5000 permutations (51.60%, 19 seconds remaining)
Job #1, processed 2590/5000 permutations (51.80%, 19 seconds remaining)
Job #1, processed 2600/5000 permutations (52.00%, 19 seconds remaining)
Job #1, processed 2610/5000 permutations (52.20%, 19 seconds remaining)
Job #1, processed 2620/5000 permutations (52.40%, 19 seconds remaining)
Job #1, processed 2630/5000 permutations (52.60%, 19 seconds remaining)
Job #1, processed 2640/5000 permutations (52.80%, 19 seconds remaining)
Job #1, processed 2650/5000 permutations (53.00%, 19 seconds remaining)
Job #1, processed 2660/5000 permutations (53.20%, 18 seconds remaining)
Job #1, processed 2670/5000 permutations (53.40%, 18 seconds remaining)
Job #1, processed 2680/5000 permutations (53.60%, 18 seconds remaining)
Job #1, processed 2690/5000 permutations (53.80%, 18 seconds remaining)
Job #1, processed 2700/5000 permutations (54.00%, 18 seconds remaining)
Job #1, processed 2710/5000 permutations (54.20%, 18 seconds remaining)
Job #1, processed 2720/5000 permutations (54.40%, 18 seconds remaining)
Job #1, processed 2730/5000 permutations (54.60%, 18 seconds remaining)
Job #1, processed 2740/5000 permutations (54.80%, 18 seconds remaining)
Job #1, processed 2750/5000 permutations (55.00%, 18 seconds remaining)
Job #1, processed 2760/5000 permutations (55.20%, 18 seconds remaining)
Job #1, processed 2770/5000 permutations (55.40%, 18 seconds remaining)
Job #1, processed 2780/5000 permutations (55.60%, 18 seconds remaining)
Job #1, processed 2790/5000 permutations (55.80%, 18 seconds remaining)
Job #1, processed 2800/5000 permutations (56.00%, 17 seconds remaining)
Job #1, processed 2810/5000 permutations (56.20%, 17 seconds remaining)
Job #1, processed 2820/5000 permutations (56.40%, 17 seconds remaining)
Job #1, processed 2830/5000 permutations (56.60%, 17 seconds remaining)
Job #1, processed 2840/5000 permutations (56.80%, 17 seconds remaining)
Job #1, processed 2850/5000 permutations (57.00%, 17 seconds remaining)
Job #1, processed 2860/5000 permutations (57.20%, 17 seconds remaining)
Job #1, processed 2870/5000 permutations (57.40%, 17 seconds remaining)
Job #1, processed 2880/5000 permutations (57.60%, 17 seconds remaining)
Job #1, processed 2890/5000 permutations (57.80%, 17 seconds remaining)
Job #1, processed 2900/5000 permutations (58.00%, 17 seconds remaining)
Job #1, processed 2910/5000 permutations (58.20%, 17 seconds remaining)
Job #1, processed 2920/5000 permutations (58.40%, 17 seconds remaining)
Job #1, processed 2930/5000 permutations (58.60%, 16 seconds remaining)
Job #1, processed 2940/5000 permutations (58.80%, 16 seconds remaining)
Job #1, processed 2950/5000 permutations (59.00%, 16 seconds remaining)
Job #1, processed 2960/5000 permutations (59.20%, 16 seconds remaining)
Job #1, processed 2970/5000 permutations (59.40%, 16 seconds remaining)
Job #1, processed 2980/5000 permutations (59.60%, 16 seconds remaining)
Job #1, processed 2990/5000 permutations (59.80%, 16 seconds remaining)
Job #1, processed 3000/5000 permutations (60.00%, 16 seconds remaining)
Job #1, processed 3010/5000 permutations (60.20%, 16 seconds remaining)
Job #1, processed 3020/5000 permutations (60.40%, 16 seconds remaining)
Job #1, processed 3030/5000 permutations (60.60%, 16 seconds remaining)
Job #1, processed 3040/5000 permutations (60.80%, 16 seconds remaining)
Job #1, processed 3050/5000 permutations (61.00%, 15 seconds remaining)
Job #1, processed 3060/5000 permutations (61.20%, 15 seconds remaining)
Job #1, processed 3070/5000 permutations (61.40%, 15 seconds remaining)
Job #1, processed 3080/5000 permutations (61.60%, 15 seconds remaining)
Job #1, processed 3090/5000 permutations (61.80%, 15 seconds remaining)
Job #1, processed 3100/5000 permutations (62.00%, 15 seconds remaining)
Job #1, processed 3110/5000 permutations (62.20%, 15 seconds remaining)
Job #1, processed 3120/5000 permutations (62.40%, 15 seconds remaining)
Job #1, processed 3130/5000 permutations (62.60%, 15 seconds remaining)
Job #1, processed 3140/5000 permutations (62.80%, 15 seconds remaining)
Job #1, processed 3150/5000 permutations (63.00%, 15 seconds remaining)
Job #1, processed 3160/5000 permutations (63.20%, 14 seconds remaining)
Job #1, processed 3170/5000 permutations (63.40%, 14 seconds remaining)
Job #1, processed 3180/5000 permutations (63.60%, 14 seconds remaining)
Job #1, processed 3190/5000 permutations (63.80%, 14 seconds remaining)
Job #1, processed 3200/5000 permutations (64.00%, 14 seconds remaining)
Job #1, processed 3210/5000 permutations (64.20%, 14 seconds remaining)
Job #1, processed 3220/5000 permutations (64.40%, 14 seconds remaining)
Job #1, processed 3230/5000 permutations (64.60%, 14 seconds remaining)
Job #1, processed 3240/5000 permutations (64.80%, 14 seconds remaining)
Job #1, processed 3250/5000 permutations (65.00%, 14 seconds remaining)
Job #1, processed 3260/5000 permutations (65.20%, 14 seconds remaining)
Job #1, processed 3270/5000 permutations (65.40%, 14 seconds remaining)
Job #1, processed 3280/5000 permutations (65.60%, 13 seconds remaining)
Job #1, processed 3290/5000 permutations (65.80%, 13 seconds remaining)
Job #1, processed 3300/5000 permutations (66.00%, 13 seconds remaining)
Job #1, processed 3310/5000 permutations (66.20%, 13 seconds remaining)
Job #1, processed 3320/5000 permutations (66.40%, 13 seconds remaining)
Job #1, processed 3330/5000 permutations (66.60%, 13 seconds remaining)
Job #1, processed 3340/5000 permutations (66.80%, 13 seconds remaining)
Job #1, processed 3350/5000 permutations (67.00%, 13 seconds remaining)
Job #1, processed 3360/5000 permutations (67.20%, 13 seconds remaining)
Job #1, processed 3370/5000 permutations (67.40%, 13 seconds remaining)
Job #1, processed 3380/5000 permutations (67.60%, 13 seconds remaining)
Job #1, processed 3390/5000 permutations (67.80%, 12 seconds remaining)
Job #1, processed 3400/5000 permutations (68.00%, 12 seconds remaining)
Job #1, processed 3410/5000 permutations (68.20%, 12 seconds remaining)
Job #1, processed 3420/5000 permutations (68.40%, 12 seconds remaining)
Job #1, processed 3430/5000 permutations (68.60%, 12 seconds remaining)
Job #1, processed 3440/5000 permutations (68.80%, 12 seconds remaining)
Job #1, processed 3450/5000 permutations (69.00%, 12 seconds remaining)
Job #1, processed 3460/5000 permutations (69.20%, 12 seconds remaining)
Job #1, processed 3470/5000 permutations (69.40%, 12 seconds remaining)
Job #1, processed 3480/5000 permutations (69.60%, 12 seconds remaining)
Job #1, processed 3490/5000 permutations (69.80%, 12 seconds remaining)
Job #1, processed 3500/5000 permutations (70.00%, 12 seconds remaining)
Job #1, processed 3510/5000 permutations (70.20%, 12 seconds remaining)
Job #1, processed 3520/5000 permutations (70.40%, 12 seconds remaining)
Job #1, processed 3530/5000 permutations (70.60%, 11 seconds remaining)
Job #1, processed 3540/5000 permutations (70.80%, 11 seconds remaining)
Job #1, processed 3550/5000 permutations (71.00%, 11 seconds remaining)
Job #1, processed 3560/5000 permutations (71.20%, 11 seconds remaining)
Job #1, processed 3570/5000 permutations (71.40%, 11 seconds remaining)
Job #1, processed 3580/5000 permutations (71.60%, 11 seconds remaining)
Job #1, processed 3590/5000 permutations (71.80%, 11 seconds remaining)
Job #1, processed 3600/5000 permutations (72.00%, 11 seconds remaining)
Job #1, processed 3610/5000 permutations (72.20%, 11 seconds remaining)
Job #1, processed 3620/5000 permutations (72.40%, 11 seconds remaining)
Job #1, processed 3630/5000 permutations (72.60%, 11 seconds remaining)
Job #1, processed 3640/5000 permutations (72.80%, 11 seconds remaining)
Job #1, processed 3650/5000 permutations (73.00%, 10 seconds remaining)
Job #1, processed 3660/5000 permutations (73.20%, 10 seconds remaining)
Job #1, processed 3670/5000 permutations (73.40%, 10 seconds remaining)
Job #1, processed 3680/5000 permutations (73.60%, 10 seconds remaining)
Job #1, processed 3690/5000 permutations (73.80%, 10 seconds remaining)
Job #1, processed 3700/5000 permutations (74.00%, 10 seconds remaining)
Job #1, processed 3710/5000 permutations (74.20%, 10 seconds remaining)
Job #1, processed 3720/5000 permutations (74.40%, 10 seconds remaining)
Job #1, processed 3730/5000 permutations (74.60%, 10 seconds remaining)
Job #1, processed 3740/5000 permutations (74.80%, 10 seconds remaining)
Job #1, processed 3750/5000 permutations (75.00%, 10 seconds remaining)
Job #1, processed 3760/5000 permutations (75.20%, 10 seconds remaining)
Job #1, processed 3770/5000 permutations (75.40%, 10 seconds remaining)
Job #1, processed 3780/5000 permutations (75.60%, 10 seconds remaining)
Job #1, processed 3790/5000 permutations (75.80%, 9 seconds remaining)
Job #1, processed 3800/5000 permutations (76.00%, 9 seconds remaining)
Job #1, processed 3810/5000 permutations (76.20%, 9 seconds remaining)
Job #1, processed 3820/5000 permutations (76.40%, 9 seconds remaining)
Job #1, processed 3830/5000 permutations (76.60%, 9 seconds remaining)
Job #1, processed 3840/5000 permutations (76.80%, 9 seconds remaining)
Job #1, processed 3850/5000 permutations (77.00%, 9 seconds remaining)
Job #1, processed 3860/5000 permutations (77.20%, 9 seconds remaining)
Job #1, processed 3870/5000 permutations (77.40%, 9 seconds remaining)
Job #1, processed 3880/5000 permutations (77.60%, 9 seconds remaining)
Job #1, processed 3890/5000 permutations (77.80%, 9 seconds remaining)
Job #1, processed 3900/5000 permutations (78.00%, 9 seconds remaining)
Job #1, processed 3910/5000 permutations (78.20%, 8 seconds remaining)
Job #1, processed 3920/5000 permutations (78.40%, 8 seconds remaining)
Job #1, processed 3930/5000 permutations (78.60%, 8 seconds remaining)
Job #1, processed 3940/5000 permutations (78.80%, 8 seconds remaining)
Job #1, processed 3950/5000 permutations (79.00%, 8 seconds remaining)
Job #1, processed 3960/5000 permutations (79.20%, 8 seconds remaining)
Job #1, processed 3970/5000 permutations (79.40%, 8 seconds remaining)
Job #1, processed 3980/5000 permutations (79.60%, 8 seconds remaining)
Job #1, processed 3990/5000 permutations (79.80%, 8 seconds remaining)
Job #1, processed 4000/5000 permutations (80.00%, 8 seconds remaining)
Job #1, processed 4010/5000 permutations (80.20%, 8 seconds remaining)
Job #1, processed 4020/5000 permutations (80.40%, 8 seconds remaining)
Job #1, processed 4030/5000 permutations (80.60%, 8 seconds remaining)
Job #1, processed 4040/5000 permutations (80.80%, 7 seconds remaining)
Job #1, processed 4050/5000 permutations (81.00%, 7 seconds remaining)
Job #1, processed 4060/5000 permutations (81.20%, 7 seconds remaining)
Job #1, processed 4070/5000 permutations (81.40%, 7 seconds remaining)
Job #1, processed 4080/5000 permutations (81.60%, 7 seconds remaining)
Job #1, processed 4090/5000 permutations (81.80%, 7 seconds remaining)
Job #1, processed 4100/5000 permutations (82.00%, 7 seconds remaining)
Job #1, processed 4110/5000 permutations (82.20%, 7 seconds remaining)
Job #1, processed 4120/5000 permutations (82.40%, 7 seconds remaining)
Job #1, processed 4130/5000 permutations (82.60%, 7 seconds remaining)
Job #1, processed 4140/5000 permutations (82.80%, 7 seconds remaining)
Job #1, processed 4150/5000 permutations (83.00%, 7 seconds remaining)
Job #1, processed 4160/5000 permutations (83.20%, 7 seconds remaining)
Job #1, processed 4170/5000 permutations (83.40%, 6 seconds remaining)
Job #1, processed 4180/5000 permutations (83.60%, 6 seconds remaining)
Job #1, processed 4190/5000 permutations (83.80%, 6 seconds remaining)
Job #1, processed 4200/5000 permutations (84.00%, 6 seconds remaining)
Job #1, processed 4210/5000 permutations (84.20%, 6 seconds remaining)
Job #1, processed 4220/5000 permutations (84.40%, 6 seconds remaining)
Job #1, processed 4230/5000 permutations (84.60%, 6 seconds remaining)
Job #1, processed 4240/5000 permutations (84.80%, 6 seconds remaining)
Job #1, processed 4250/5000 permutations (85.00%, 6 seconds remaining)
Job #1, processed 4260/5000 permutations (85.20%, 6 seconds remaining)
Job #1, processed 4270/5000 permutations (85.40%, 6 seconds remaining)
Job #1, processed 4280/5000 permutations (85.60%, 6 seconds remaining)
Job #1, processed 4290/5000 permutations (85.80%, 6 seconds remaining)
Job #1, processed 4300/5000 permutations (86.00%, 5 seconds remaining)
Job #1, processed 4310/5000 permutations (86.20%, 5 seconds remaining)
Job #1, processed 4320/5000 permutations (86.40%, 5 seconds remaining)
Job #1, processed 4330/5000 permutations (86.60%, 5 seconds remaining)
Job #1, processed 4340/5000 permutations (86.80%, 5 seconds remaining)
Job #1, processed 4350/5000 permutations (87.00%, 5 seconds remaining)
Job #1, processed 4360/5000 permutations (87.20%, 5 seconds remaining)
Job #1, processed 4370/5000 permutations (87.40%, 5 seconds remaining)
Job #1, processed 4380/5000 permutations (87.60%, 5 seconds remaining)
Job #1, processed 4390/5000 permutations (87.80%, 5 seconds remaining)
Job #1, processed 4400/5000 permutations (88.00%, 5 seconds remaining)
Job #1, processed 4410/5000 permutations (88.20%, 5 seconds remaining)
Job #1, processed 4420/5000 permutations (88.40%, 4 seconds remaining)
Job #1, processed 4430/5000 permutations (88.60%, 4 seconds remaining)
Job #1, processed 4440/5000 permutations (88.80%, 4 seconds remaining)
Job #1, processed 4450/5000 permutations (89.00%, 4 seconds remaining)
Job #1, processed 4460/5000 permutations (89.20%, 4 seconds remaining)
Job #1, processed 4470/5000 permutations (89.40%, 4 seconds remaining)
Job #1, processed 4480/5000 permutations (89.60%, 4 seconds remaining)
Job #1, processed 4490/5000 permutations (89.80%, 4 seconds remaining)
Job #1, processed 4500/5000 permutations (90.00%, 4 seconds remaining)
Job #1, processed 4510/5000 permutations (90.20%, 4 seconds remaining)
Job #1, processed 4520/5000 permutations (90.40%, 4 seconds remaining)
Job #1, processed 4530/5000 permutations (90.60%, 4 seconds remaining)
Job #1, processed 4540/5000 permutations (90.80%, 3 seconds remaining)
Job #1, processed 4550/5000 permutations (91.00%, 3 seconds remaining)
Job #1, processed 4560/5000 permutations (91.20%, 3 seconds remaining)
Job #1, processed 4570/5000 permutations (91.40%, 3 seconds remaining)
Job #1, processed 4580/5000 permutations (91.60%, 3 seconds remaining)
Job #1, processed 4590/5000 permutations (91.80%, 3 seconds remaining)
Job #1, processed 4600/5000 permutations (92.00%, 3 seconds remaining)
Job #1, processed 4610/5000 permutations (92.20%, 3 seconds remaining)
Job #1, processed 4620/5000 permutations (92.40%, 3 seconds remaining)
Job #1, processed 4630/5000 permutations (92.60%, 3 seconds remaining)
Job #1, processed 4640/5000 permutations (92.80%, 3 seconds remaining)
Job #1, processed 4650/5000 permutations (93.00%, 3 seconds remaining)
Job #1, processed 4660/5000 permutations (93.20%, 2 seconds remaining)
Job #1, processed 4670/5000 permutations (93.40%, 2 seconds remaining)
Job #1, processed 4680/5000 permutations (93.60%, 2 seconds remaining)
Job #1, processed 4690/5000 permutations (93.80%, 2 seconds remaining)
Job #1, processed 4700/5000 permutations (94.00%, 2 seconds remaining)
Job #1, processed 4710/5000 permutations (94.20%, 2 seconds remaining)
Job #1, processed 4720/5000 permutations (94.40%, 2 seconds remaining)
Job #1, processed 4730/5000 permutations (94.60%, 2 seconds remaining)
Job #1, processed 4740/5000 permutations (94.80%, 2 seconds remaining)
Job #1, processed 4750/5000 permutations (95.00%, 2 seconds remaining)
Job #1, processed 4760/5000 permutations (95.20%, 2 seconds remaining)
Job #1, processed 4770/5000 permutations (95.40%, 1 seconds remaining)
Job #1, processed 4780/5000 permutations (95.60%, 1 seconds remaining)
Job #1, processed 4790/5000 permutations (95.80%, 1 seconds remaining)
Job #1, processed 4800/5000 permutations (96.00%, 1 seconds remaining)
Job #1, processed 4810/5000 permutations (96.20%, 1 seconds remaining)
Job #1, processed 4820/5000 permutations (96.40%, 1 seconds remaining)
Job #1, processed 4830/5000 permutations (96.60%, 1 seconds remaining)
Job #1, processed 4840/5000 permutations (96.80%, 1 seconds remaining)
Job #1, processed 4850/5000 permutations (97.00%, 1 seconds remaining)
Job #1, processed 4860/5000 permutations (97.20%, 1 seconds remaining)
Job #1, processed 4870/5000 permutations (97.40%, 1 seconds remaining)
Job #1, processed 4880/5000 permutations (97.60%, 1 seconds remaining)
Job #1, processed 4890/5000 permutations (97.80%, 0 seconds remaining)
Job #1, processed 4900/5000 permutations (98.00%, 0 seconds remaining)
Job #1, processed 4910/5000 permutations (98.20%, 0 seconds remaining)
Job #1, processed 4920/5000 permutations (98.40%, 0 seconds remaining)
Job #1, processed 4930/5000 permutations (98.60%, 0 seconds remaining)
Job #1, processed 4940/5000 permutations (98.80%, 0 seconds remaining)
Job #1, processed 4950/5000 permutations (99.00%, 0 seconds remaining)
Job #1, processed 4960/5000 permutations (99.20%, 0 seconds remaining)
Job #1, processed 4970/5000 permutations (99.40%, 0 seconds remaining)
Job #1, processed 4980/5000 permutations (99.60%, 0 seconds remaining)
Job #1, processed 4990/5000 permutations (99.80%, 0 seconds remaining)
[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   43.9s finished
</pre></div>
</div>
<p>Visualization</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.plotting</span> <span class="kn">import</span> <span class="n">plot_stat_map</span><span class="p">,</span> <span class="n">show</span>

<span class="c1"># Various plotting parameters</span>
<a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_slice</span></a> <span class="o">=</span> <span class="mi">12</span>  <span class="c1"># plotted slice</span>

<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a> <span class="o">=</span> <span class="o">-</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.ufunc.html#numpy.ufunc" title="numpy.ufunc" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">np</span><span class="o">.</span><span class="n">log10</span></a><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>  <span class="c1"># 10% corrected</span>
<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">vmax</span></a> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.amax.html#numpy.amax" title="numpy.amax" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">amax</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols</span></a><span class="p">),</span>
           <a href="https://numpy.org/doc/stable/reference/generated/numpy.amax.html#numpy.amax" title="numpy.amax" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">amax</span></a><span class="p">(</span><a href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="numpy.ndarray" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova</span></a><span class="p">))</span>

<span class="c1"># Plot Anova p-values</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>

<span class="n">display</span> <span class="o">=</span> <span class="n">plot_stat_map</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova_unmasked</span></a><span class="p">,</span>
                        <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">,</span>
                        <span class="n">display_mode</span><span class="o">=</span><span class="s1">'z'</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_slice</span></a><span class="p">],</span>
                        <span class="n">figure</span><span class="o">=</span><a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">vmax</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">vmax</span></a><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_detections</span></a> <span class="o">=</span> <span class="p">(</span><span class="n">get_data</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_anova_unmasked</span></a><span class="p">)</span> <span class="o">&gt;</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a> <span class="o">=</span> <span class="p">(</span><span class="s1">'Negative $</span><span class="se">\\</span><span class="s1">log_</span><span class="si">{10}</span><span class="s1">$ p-values'</span>
         <span class="s1">'</span><span class="se">\n</span><span class="s1">(Parametric + Bonferroni correction)'</span>
         <span class="s1">'</span><span class="se">\n</span><span class="si">%d</span><span class="s1"> detections'</span><span class="p">)</span> <span class="o">%</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_detections</span></a>

<span class="n">display</span><span class="o">.</span><a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">(</span><a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>

<span class="c1"># Plot permuted OLS p-values</span>
<a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a> <span class="o">=</span> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure" title="matplotlib.pyplot.figure" class="sphx-glr-backref-module-matplotlib-pyplot sphx-glr-backref-type-py-function"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span></a><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>

<span class="n">display</span> <span class="o">=</span> <span class="n">plot_stat_map</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols_unmasked</span></a><span class="p">,</span>
                        <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">,</span>
                        <span class="n">display_mode</span><span class="o">=</span><span class="s1">'z'</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">[</span><a href="https://docs.python.org/3.8/library/functions.html#int" title="builtins.int" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">z_slice</span></a><span class="p">],</span>
                        <span class="n">figure</span><span class="o">=</span><a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure" title="matplotlib.figure.Figure" class="sphx-glr-backref-module-matplotlib-figure sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">fig</span></a><span class="p">,</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">vmax</span></a><span class="o">=</span><a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">vmax</span></a><span class="p">,</span> <span class="n">black_bg</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_detections</span></a> <span class="o">=</span> <span class="p">(</span><span class="n">get_data</span><span class="p">(</span><a href="https://nipy.org/nibabel/reference/nibabel.nifti1.html#nibabel.nifti1.Nifti1Image" title="nibabel.nifti1.Nifti1Image" class="sphx-glr-backref-module-nibabel-nifti1 sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">neg_log_pvals_permuted_ols_unmasked</span></a><span class="p">)</span>
                <span class="o">&gt;</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.float64" title="numpy.float64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">threshold</span></a><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a> <span class="o">=</span> <span class="p">(</span><span class="s1">'Negative $</span><span class="se">\\</span><span class="s1">log_</span><span class="si">{10}</span><span class="s1">$ p-values'</span>
         <span class="s1">'</span><span class="se">\n</span><span class="s1">(Non-parametric + max-type correction)'</span>
         <span class="s1">'</span><span class="se">\n</span><span class="si">%d</span><span class="s1"> detections'</span><span class="p">)</span> <span class="o">%</span> <a href="https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.int64" title="numpy.int64" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-attribute"><span class="n">n_detections</span></a>

<span class="n">display</span><span class="o">.</span><a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">(</span><a href="https://docs.python.org/3.8/library/stdtypes.html#str" title="builtins.str" class="sphx-glr-backref-module-builtins sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">title</span></a><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.2</span><span class="p">)</span>

<span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<ul class="sphx-glr-horizontal">
<li><img alt="plot localizer mass univariate methods" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_001.png" srcset="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_001.png"/></li>
<li><img alt="plot localizer mass univariate methods" class="sphx-glr-multi-img" src="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_002.png" srcset="../../_images/sphx_glr_plot_localizer_mass_univariate_methods_002.png"/></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  56.781 seconds)</p>
<p><strong>Estimated memory usage:</strong>  11 MB</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-07-advanced-plot-localizer-mass-univariate-methods-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/nilearn/nilearn.github.io/main?filepath=examples/auto_examples/07_advanced/plot_localizer_mass_univariate_methods.ipynb"><img alt="Launch binder" src="../../_images/binder_badge_logo7.svg" width="150px"/></a>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/97d9e7d9f43c9d823ae94a8799054e2e/plot_localizer_mass_univariate_methods.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">plot_localizer_mass_univariate_methods.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/df968f8dc0ed21a91ed0515280d41a82/plot_localizer_mass_univariate_methods.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">plot_localizer_mass_univariate_methods.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="plot_ica_neurovault.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title"><span class="section-number">9.4.4.8.8. </span>NeuroVault cross-study ICA maps.</div>
              </div>
              <svg><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="plot_surface_bids_analysis.html">
              <svg><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title"><span class="section-number">9.4.4.8.6. </span>Surface-based dataset first and second level analysis of a dataset</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; The nilearn developers 2010-2022
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/scripts/furo.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/design-tabs.js"></script>
    </body>
</html>